{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate event detection task\n",
    "Sandbox for preprocessing and first learning test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # change to chosen GPU to use, nothing if work on CPU\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import healpy as hp\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepsphere import models, experiment_helper, plot, utils\n",
    "from deepsphere.data import LabeledDatasetWithNoise, LabeledDataset\n",
    "import hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of parameters:\n",
    "* PRECT: Total (convective and large-scale) precipitation rate (liq + ice)\n",
    "* PS: Surface pressure\n",
    "* PSL: sea level pressure\n",
    "* QREFHT: Reference height humidity\n",
    "* T200: temp at 200 mbar pressure surface\n",
    "* T500: temp at 500 mbar pressure surface\n",
    "* TMQ: Total (vertically integrated) precipitatable water\n",
    "* TS: Surface temperature (radiative)\n",
    "* U850: Zonal wind at 850 mbar pressure surface\n",
    "* UBOT: Lowest model level zonal wind\n",
    "* V850: Meridional wind at 850 mbar pressure surface\n",
    "* VBOT: Lowest model level meridional wind\n",
    "* Z100: Geopotential Z at 100 mbar pressure surface\n",
    "* Z200: Geopotential Z at 200 mbar pressure surface\n",
    "* ZBOT: Lowest model level height\n",
    "\n",
    "4 measures per day, 365 days a year\n",
    "resolution of 768 x 1152 equirectangular grid (25-km at equator)\n",
    "\n",
    "boxes:\n",
    "* ymin\n",
    "* xmin\n",
    "* ymax\n",
    "* xmax\n",
    "* class:\n",
    "    * 0: Tropical Depression\n",
    "    * 1: Tropical Cyclone\n",
    "    * 2: Extratropical Cyclone\n",
    "    * 3: Atmospheric River"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2005\n",
    "datapath = '../../../data/ExtremeWeather/climo_{}.h5'.format(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File(datapath)\n",
    "images = h5f[\"images\"] # (1460,16,768,1152) numpy array\n",
    "boxes = h5f[\"boxes\"] # (1460,15,5) numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_ = np.arange(1152)/1152*360\n",
    "lat_ = np.arange(768)/768*180-90\n",
    "lon, lat = np.meshgrid(lon_, lat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_global()\n",
    "# ax.stock_img()\n",
    "ax.coastlines()\n",
    "\n",
    "plt.scatter(lon, lat, s=1,\n",
    "            c=data[0,:,:], cmap=plt.get_cmap('RdYlBu_r'), alpha=1)\n",
    "\n",
    "color = ['r', 'y', 'c', 'g']\n",
    "\n",
    "for i in range(15):\n",
    "    ymin, xmin, ymax, xmax, clas = boxes[0,i]\n",
    "    if ymin==-1:\n",
    "        print(\"no box\")\n",
    "        continue\n",
    "    ymin, ymax = lat_[ymin], lat_[ymax]\n",
    "    xmin, xmax = lon_[xmin], lon_[xmax]\n",
    "    plt.scatter(np.array([xmin, xmin, xmax, xmax]),np.array([ymin, ymax, ymin, ymax]), c=color[clas])\n",
    "    rect = patches.Rectangle((xmin,ymin),xmax-xmin,ymax-ymin,linewidth=2,edgecolor=color[clas],facecolor='none')\n",
    "    ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata, RectBivariateSpline, RegularGridInterpolator, LinearNDInterpolator, interp2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata#, RectBivariateSpline, RegularGridInterpolator\n",
    "Nside = 64\n",
    "pix = np.arange(12*Nside**2)\n",
    "coords_hp = hp.pix2ang(Nside, pix, nest=True, lonlat=True)\n",
    "coords_hp = np.asarray(coords_hp).T\n",
    "# lon_rad, lat_rad = np.deg2rad(lon), np.deg2rad(lat)\n",
    "coords_map = hp.ang2vec(lon, lat, lonlat=True).reshape((-1, 3))\n",
    "coords_map = np.stack([lon, lat], axis=-1).reshape((-1, 2))\n",
    "# map_hp = griddata(coords_map, images[0,0].flatten(), coords_hp, 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "map_hp1 = griddata(coords_map, data[0].flatten(), coords_hp, 'linear')\n",
    "print(\"time taken:\", time.time()-t)\n",
    "\n",
    "# t = time.time()\n",
    "# map_hp2 = griddata(coords_map, images[0,0].flatten(), np.asarray(coords_hp).T, 'linear')\n",
    "# print(\"time taken:\", time.time()-t)\n",
    "\n",
    "# t = time.time()\n",
    "# f = interp2d(lon_, lat_, images[0,0])\n",
    "# map_hp3 = np.diag(f(*coords_hp))  # False result???\n",
    "# print(\"time taken:\", time.time()-t)\n",
    "\n",
    "t = time.time()\n",
    "f = RegularGridInterpolator((lon_, lat_), data[0].T)\n",
    "map_hp3 = f(coords_hp)\n",
    "print(\"time taken:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_global()\n",
    "# ax.stock_img()\n",
    "ax.coastlines()\n",
    "\n",
    "plt.scatter(coords_hp[:,0], coords_hp[:,1], s=10,\n",
    "            c=map_hp1, cmap=plt.get_cmap('RdYlBu_r'), alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_global()\n",
    "# ax.stock_img()\n",
    "ax.coastlines()\n",
    "\n",
    "plt.scatter(coords_hp[:,0], coords_hp[:,1], s=10,\n",
    "            c=map_hp3, cmap=plt.get_cmap('RdYlBu_r'), alpha=1)\n",
    "# indic = np.where(~np.isclose(map_hp1, map_hp3, atol=1e-6))\n",
    "# plt.scatter(coords_hp[indic,0], coords_hp[indic,1], s=10,\n",
    "#             c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../../data/ExtremeWeather/'\n",
    "measures, channels, lat_x, lon_x = images.shape\n",
    "nfeat = 5\n",
    "Nside = [32, 64]\n",
    "for nside in Nside:\n",
    "    npix = hp.nside2npix(nside)\n",
    "    data = np.empty((measures, npix, channels))\n",
    "    labels = np.zeros((measures, npix))\n",
    "    pix = np.arange(npix)\n",
    "    coords_hp = hp.pix2ang(nside, pix, nest=True, lonlat=True)\n",
    "    coords_hp = np.asarray(coords_hp).T\n",
    "    for measure in tqdm(range(measures)):\n",
    "        for channel in tqdm(range(channels)):\n",
    "#             data[measure,:,channel] = griddata(coords_map, images[measure,channel].flatten(), coords_hp, 'linear')\n",
    "            f = RegularGridInterpolator((lon_, lat_), images[measure,channel].T)\n",
    "            data[measure,:,channel] = f(coords_hp)\n",
    "        for box in range(boxes.shape[1]):\n",
    "            ymin, xmin, ymax, xmax, clas = boxes[measure,box]\n",
    "            if ymin==-1:\n",
    "#                 print(\"no box\")\n",
    "                continue\n",
    "            ymin, ymax = lat_[ymin%lat_x], lat_[ymax%lat_x]\n",
    "            xmin, xmax = lon_[xmin%lon_x], lon_[xmax%lon_x]\n",
    "            if xmax>xmin and ymax>ymin:\n",
    "                indexes = np.where(np.logical_and(np.logical_and(coords_hp[:,0]>=xmin, coords_hp[:,0]<=xmax), \n",
    "                                        np.logical_and(coords_hp[:,1]>=ymin, coords_hp[:,1]<=ymax)))\n",
    "            else:\n",
    "                indexes = np.where(np.logical_and(np.logical_or(coords_hp[:,0]>=xmin, coords_hp[:,0]<=xmax), \n",
    "                                        np.logical_and(coords_hp[:,1]>=ymin, coords_hp[:,1]<=ymax)))\n",
    "            labels[measure, indexes] = clas + 1\n",
    "#             if xmax<=xmin or ymax<=ymin:\n",
    "#                 print(xmin, ymin, xmax, ymax)\n",
    "#                 print(labels[measure, indexes])\n",
    "#                 fig = plt.figure(figsize=(25, 50))\n",
    "#                 ax = fig.add_subplot(211)\n",
    "#                 ax.scatter(coords_hp[:,0], coords_hp[:,1], \n",
    "#                            c=labels[measure,:], cmap=plt.get_cmap('RdYlBu_r'), alpha=1)\n",
    "#                 ax2 = fig.add_subplot(212, projection=ccrs.PlateCarree())\n",
    "#                 ax2.set_global()\n",
    "#                 plt.scatter(coords_hp[:,0], coords_hp[:,1], s=10,\n",
    "#                     c=labels[measure,:], cmap=plt.get_cmap('RdYlBu_r'), alpha=1)\n",
    "#                 break\n",
    "#         if (xmax<=xmin or ymax<=ymin) and ymin!=-1:\n",
    "#             break\n",
    "#     break\n",
    "    file = data_path + 'EW_{}nside_{}'.format(nside, year)\n",
    "    np.savez(file, data=data, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = data_path + 'EW_{}nside_{}'.format(Nside, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_global()\n",
    "# ax.stock_img()\n",
    "ax.coastlines()\n",
    "\n",
    "plt.scatter(coords_hp[:,0], coords_hp[:,1], s=10,\n",
    "            c=data[0,:,1], cmap=plt.get_cmap('RdYlBu_r'), alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_global()\n",
    "# ax.stock_img()\n",
    "ax.coastlines()\n",
    "\n",
    "plt.scatter(coords_hp[:,0], coords_hp[:,1], s=10,\n",
    "            c=labels[0,:], cmap=plt.get_cmap('RdYlBu_r'), alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 25))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.Orthographic(0, 0))\n",
    "ax.set_global()\n",
    "ax.coastlines(linewidth=2)\n",
    "\n",
    "# zmin, zmax = -20, 40\n",
    "\n",
    "plt.scatter(coords_hp[:,0], coords_hp[:,1], s=100,\n",
    "            c=map_hp3, cmap=plt.get_cmap('RdYlBu_r'), alpha=1, transform=ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_labels(predictions):\n",
    "    # modify predictions to have bounding box\n",
    "    return predictions\n",
    "\n",
    "def iou_score(labels, predictions, nclass):\n",
    "    iou = []\n",
    "    for i in range(nclass):\n",
    "        intersect = ((labels==i) + (predictions==i)).eq(2).sum().item()\n",
    "        union = ((labels==i) + (predictions==i)).sum()\n",
    "        iou.append(intersect/union)\n",
    "    return np.asarray(iou)\n",
    "\n",
    "# def average_precision():\n",
    "#     pass\n",
    "\n",
    "# def accuracy():\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [1979, 1981, 1984, 2005]\n",
    "path = '../../../data/ExtremeWeather/EW_{}nside_{}.npz'\n",
    "Nside = 32\n",
    "datas = []\n",
    "labels = []\n",
    "for year in years:\n",
    "    datapath = path.format(Nside, year)\n",
    "    file = np.load(datapath)\n",
    "    data = file['data']  # N x M x F\n",
    "    label = file['labels']  # N x M\n",
    "    datas.append(data)\n",
    "    labels.append(label)\n",
    "datas = np.stack(datas)\n",
    "labels = np.stack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=1200\n",
    "x_train = data[:limit,:,:]\n",
    "labels_train = labels[:limit,:]\n",
    "x_val = data[limit:,:,:]\n",
    "labels_val = labels[limit:,:]\n",
    "\n",
    "training = LabeledDataset(x_train, labels_train)\n",
    "validation = LabeledDataset(x_val, labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = 'TestExtremeWeather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "params = {'nsides': [nside, nside,nside//2,nside//4,nside//8,nside//16,nside//32, nside//32],\n",
    "          'F': [20, 20, 50, 80, 100, 200, 400],#np.max(labels_train).astype(int)+1],\n",
    "          'K': [4]*7,\n",
    "          'batch_norm': [True]*7}\n",
    "params['dir_name'] = EXP_NAME\n",
    "params['num_feat_in'] = x_train.shape[-1] # 2*days_pred+3\n",
    "params['conv'] = 'chebyshev5'\n",
    "params['pool'] = 'average'\n",
    "params['activation'] = 'relu'\n",
    "params['statistics'] = None#'mean'\n",
    "params['regularization'] = 0\n",
    "params['dropout'] = 1\n",
    "params['num_epochs'] = 1000  # Number of passes through the training data.\n",
    "params['batch_size'] = 32\n",
    "params['scheduler'] = lambda step: tf.train.exponential_decay(1e-3, step, decay_steps=2000, decay_rate=1)\n",
    "#params['optimizer'] = lambda lr: tf.train.GradientDescentOptimizer(lr)\n",
    "params['optimizer'] = lambda lr: tf.train.RMSPropOptimizer(lr, decay=0.9, momentum=0.)\n",
    "n_evaluations = 1000\n",
    "params['eval_frequency'] = int(params['num_epochs'] * (training.N) / params['batch_size'] / n_evaluations)\n",
    "params['M'] = []\n",
    "params['Fseg'] = np.max(labels_train).astype(int)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([12*nside**2 for nside in params['nsides']])\n",
    "model = models.deepsphere(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(training, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_global()\n",
    "# ax.stock_img()\n",
    "ax.coastlines()\n",
    "\n",
    "plt.scatter(coords_hp[:,0], coords_hp[:,1], s=10,\n",
    "            c=predictions[0,:], cmap=plt.get_cmap('RdYlBu_r'), alpha=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
