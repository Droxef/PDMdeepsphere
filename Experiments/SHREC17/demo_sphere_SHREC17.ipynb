{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSphere using SHREC17 dataset\n",
    "## Benchmark with Cohen method S2CNN[[1]](http://arxiv.org/abs/1801.10130) and Esteves method[[2]](http://arxiv.org/abs/1711.06721)\n",
    "Multi-class classification of 3D objects, using the interesting property of rotation equivariance.\n",
    "\n",
    "The 3D objects are projected on a unit sphere.\n",
    "Cohen and Esteves use equiangular sampling, while our method use a HEAlpix sampling\n",
    "\n",
    "Several features are collected:\n",
    "* projection ray length (from sphere border to intersection [0, 2])\n",
    "* cos/sin with surface normal\n",
    "* same features using the convex hull of the 3D object\n",
    "\n",
    "### Using HEALPix - Dataset loaded on RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # change to chosen GPU to use, nothing if work on CPU\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import healpy as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepsphere import models, experiment_helper, plot, utils\n",
    "from deepsphere.data import LabeledDatasetWithNoise, LabeledDataset\n",
    "import hyperparameters\n",
    "\n",
    "from load_shrec import fix_dataset, Shrec17Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_shrec import plot_healpix_projection, cache_healpix_projection\n",
    "pathfig = './figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1=plot_healpix_projection('../data/shrec17/train_perturbed/000003.obj',128, outside=False, rotp=False, rot=(30,330,40))\n",
    "plt.savefig(pathfig+\"plane_000003.svg\", bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nside = 32\n",
    "experiment_type = 'FCN' # 'CNN'\n",
    "ename = '_'+experiment_type\n",
    "datapath = '../../../data/shrec17/' # localisation of the .obj files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dataset = True    # use perturbed dataset (Cohen and Esteves do the same)\n",
    "augmentation = 1        # number of element per file (1 = no augmentation of dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if datasets are already downloaded but not preprocessed\n",
    "fix = False\n",
    "download = False\n",
    "if fix:\n",
    "    fix_dataset(datapath+'val_perturbed')\n",
    "    fix_dataset(datapath+'test_perturbed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download dataset if True, preprocess data and store it in npy files, and load it in a dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Shrec17Dataset(datapath, 'train', perturbed=noise_dataset, download=download, nside=Nside, augmentation=augmentation, nfile=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better to keep validation and testing set in RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Shrec17Dataset(datapath, 'val', perturbed=noise_dataset, download=download, nside=Nside, augmentation=augmentation, nfile=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the training dataset and print the classes distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, labels_train, ids_train = train_dataset.return_data(train=True, train_ratio=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nclass = train_dataset.nclass\n",
    "num_elem = train_dataset.N\n",
    "#ids = train_dataset.retrieve_ids()\n",
    "print('number of class:',nclass,'\\nnumber of elements:',num_elem,'\\nfirst id:',ids_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, labels_val, ids_val = val_dataset.return_data(train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot sphere images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show what the projection looks like for the first two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = x_train[0,:,0]\n",
    "im0003 = train_dataset.data[0,:,0]\n",
    "im1_norm = x_train[0,:,1]\n",
    "im0003_norm = train_dataset.data[0,:,1]\n",
    "cm = plt.cm.RdBu_r\n",
    "cm.set_under('w')\n",
    "cmin = np.min(x_train[:,:,0])\n",
    "cmax = np.max(x_train[:,:,0])\n",
    "cmin_norm = np.min(x_train[:,:,1])\n",
    "cmax_norm = np.max(x_train[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.orthview(im1, title=ids_train[0]+\" ray length\", nest=True, cmap=cm, min=cmin, max=cmax)\n",
    "hp.orthview(im0003, rot=(30,330,40), title='00003 ray length', nest=True, flip='geo', cmap=cm, min=cmin, max=cmax)\n",
    "hp.orthview(im1_norm, title=ids_train[0]+\" normal\", nest=True, cmap=cm, min=cmin_norm, max=cmax_norm)\n",
    "hp.orthview(im0003_norm, rot=(30,330,40), title='00003 normal', nest=True, flip='geo', cmap=cm, min=cmin_norm, max=cmax_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Classification using DeepSphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of the Dataset object used for other DeepSphere experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = LabeledDataset(x_train, labels_train)\n",
    "validation = LabeledDataset(x_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = 'shrec17_best_{}feat_{}aug__{}sides{}'.format(nfeat, augmentation, Nside, ename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model with hyperparameters chosen.\n",
    "For each experiment, a new EXP_NAME is chosen, and new hyperparameters are store.\n",
    "All informations are present 'DeepSphere/Shrec17/experiments.md'\n",
    "The fastest way to reproduce an experiment is to revert to the commit of the experiment to load the correct files and notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a layer in the fully connected can be beneficial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find best parameters, loop over:\n",
    "- K: 2, 3, 5\n",
    "- depth: 3, 5, 8 gconv\n",
    "- Nside: 32, 64, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = hyperparameters.get_params_shrec17_optim(num_elem, EXP_NAME, Nside, nclass, architecture=experiment_type)\n",
    "model = models.deepsphere(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('summaries/{}/'.format(EXP_NAME), ignore_errors=True)\n",
    "shutil.rmtree('checkpoints/{}/'.format(EXP_NAME), ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a correct learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup = params.copy()\n",
    "\n",
    "# params, learning_rate = utils.test_learning_rates(params, training.N, 1e-6, 1e-1, num_epochs=20)\n",
    "\n",
    "# shutil.rmtree('summaries/{}/'.format(params['dir_name']), ignore_errors=True)\n",
    "# shutil.rmtree('checkpoints/{}/'.format(params['dir_name']), ignore_errors=True)\n",
    "\n",
    "# model = models.deepsphere(**params)\n",
    "# _, loss_validation, _, _ = model.fit(training, validation)\n",
    "\n",
    "# params.update(backup)\n",
    "\n",
    "# plt.semilogx(learning_rate, loss_validation, '.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree('summaries/lr_finder/', ignore_errors=True)\n",
    "# shutil.rmtree('checkpoints/lr_finder/', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.9 seems to be a good learning rate for SGD with current parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the number of parameters in the model is: {:,}\".format(model.get_nbr_var()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_validation, loss_validation, loss_training, t_step = model.fit(training, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_loss(loss_training, loss_validation, t_step, params['eval_frequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probabilities = model.probs(x_val, nclass)\n",
    "if augmentation>1:\n",
    "    probabilities = probabilities.reshape((-1,augmentation,nclass))\n",
    "    probabilities = repeat.mean(axis=1)\n",
    "    #ids_val = ids_val[::repeat]\n",
    "predictions = np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every file, find every object with the same class, sorted by most relevance\n",
    "os.makedirs(os.path.join(datapath,'results_deep/val_perturbed'), exist_ok=True)\n",
    "for i,_id in enumerate(ids_val):\n",
    "    idfile = os.path.join(datapath,'results_deep/val_perturbed',_id)\n",
    "    # predictions batchxclass\n",
    "    # pred_class batch == predictions\n",
    "    retrieved = [(probabilities[j, predictions[j]], ids_val[j]) for j in range(len(ids_val)) if predictions[j] == predictions[i]]\n",
    "    retrieved = sorted(retrieved, reverse=True)\n",
    "    retrieved = [i for _, i in retrieved]\n",
    "    with open(idfile, \"w\") as f:\n",
    "        f.write(\"\\n\".join(retrieved))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN appears if remove i==j case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Shrec17Dataset(datapath, 'test', perturbed=noise_dataset, download=download, nside=Nside, augmentation=augmentation, nfile=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, labels_test, ids_test = test_dataset.return_data(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.probs(x_test, nclass)\n",
    "if augmentation>1:\n",
    "    probabilities = probabilities.reshape((-1,augmentation,nclass))\n",
    "    probabilities = repeat.mean(axis=1)\n",
    "#probabilities = np.log(probabilities)\n",
    "predictions = np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every file, find every object with the same class, sorted by most relevance\n",
    "os.makedirs(os.path.join(datapath,'results_deep/test_perturbed'), exist_ok=True)\n",
    "for i, _id in enumerate(ids_test):\n",
    "    idfile = os.path.join(datapath,'results_deep/test_perturbed',_id)\n",
    "    # predictions batchxclass\n",
    "    # pred_class batch == predictions\n",
    "    retrieved = [(probabilities[j, predictions[j]], ids_test[j]) for j in range(len(ids_test)) if predictions[j] == predictions[i]]\n",
    "    retrieved = sorted(retrieved, reverse=True)\n",
    "    retrieved = [i for _, i in retrieved]\n",
    "    with open(idfile, \"w\") as f:\n",
    "        f.write(\"\\n\".join(retrieved))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why not working?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_histogram(nclass, labels_train, labels_val=None):\n",
    "    if labels_train is None:\n",
    "        return\n",
    "    import matplotlib.pyplot as plt\n",
    "    from collections import Counter\n",
    "    hist_train=Counter(labels_train)\n",
    "#         for i in range(self.nclass):\n",
    "#             hist_train.append(np.sum(labels_train == i))\n",
    "    labels, values = zip(*hist_train.items())\n",
    "    indexes = np.asarray(labels)\n",
    "#     miss = set(indexes) - set(labels)\n",
    "#     if len(miss) is not 0:\n",
    "#         hist_train.update({elem:0 for elem in miss})\n",
    "#     labels, values = zip(*hist_train.items())\n",
    "    width = 1\n",
    "    plt.bar(labels, values, width)\n",
    "    plt.title(\"labels distribution\")\n",
    "    #plt.xticks(indexes + width * 0.5, labels)\n",
    "    if labels_val is not None:\n",
    "        hist_val=Counter(labels_val)\n",
    "        plt.figure()\n",
    "        labels, values = zip(*hist_val.items())\n",
    "        indexes = np.asarray(labels)\n",
    "        width = 1\n",
    "        plt.bar(indexes, values, width)\n",
    "        plt.title(\"validation labels distribution\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_print_histogram(55, labels_test)\n",
    "_print_histogram(55, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
