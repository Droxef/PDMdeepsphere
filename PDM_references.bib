
@article{lee_spherephd:_2018,
	title = {{SpherePHD}: Applying {CNNs} on a Spherical {PolyHeDron} Representation of 360 degree Images},
	url = {http://arxiv.org/abs/1811.08196},
	shorttitle = {{SpherePHD}},
	abstract = {Omni-directional cameras have many advantages overconventional cameras in that they have a much wider field-of-view ({FOV}). Accordingly, several approaches have beenproposed recently to apply convolutional neural networks({CNNs}) to omni-directional images for various visual tasks.However, most of them use image representations defined inthe Euclidean space after transforming the omni-directionalviews originally formed in the non-Euclidean space. Thistransformation leads to shape distortion due to nonuniformspatial resolving power and the loss of continuity. Theseeffects make existing convolution kernels experience diffi-culties in extracting meaningful information.This paper presents a novel method to resolve such prob-lems of applying {CNNs} to omni-directional images. Theproposed method utilizes a spherical polyhedron to rep-resent omni-directional views. This method minimizes thevariance of the spatial resolving power on the sphere sur-face, and includes new convolution and pooling methodsfor the proposed representation. The proposed method canalso be adopted by any existing {CNN}-based methods. Thefeasibility of the proposed method is demonstrated throughclassification, detection, and semantic segmentation taskswith synthetic and real datasets.},
	journaltitle = {{arXiv}:1811.08196 [cs]},
	author = {Lee, Yeonkun and Jeong, Jaeseok and Yun, Jongseob and Cho, Wonjune and Yoon, Kuk-Jin},
	urldate = {2019-05-27},
	date = {2018-11-20},
	eprinttype = {arxiv},
	eprint = {1811.08196},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@incollection{ferrari_spherenet:_2018,
	location = {Cham},
	title = {{SphereNet}: Learning Spherical Representations for Detection and Classification in Omnidirectional Images},
	volume = {11213},
	isbn = {978-3-030-01239-7 978-3-030-01240-3},
	url = {http://link.springer.com/10.1007/978-3-030-01240-3_32},
	shorttitle = {{SphereNet}},
	abstract = {Omnidirectional cameras offer great beneﬁts over classical cameras wherever a wide ﬁeld of view is essential, such as in virtual reality applications or in autonomous robots. Unfortunately, standard convolutional neural networks are not well suited for this scenario as the natural projection surface is a sphere which cannot be unwrapped to a plane without introducing signiﬁcant distortions, particularly in the polar regions. In this work, we present {SphereNet}, a novel deep learning framework which encodes invariance against such distortions explicitly into convolutional neural networks. Towards this goal, {SphereNet} adapts the sampling locations of the convolutional ﬁlters, effectively reversing distortions, and wraps the ﬁlters around the sphere. By building on regular convolutions, {SphereNet} enables the transfer of existing perspective convolutional neural network models to the omnidirectional case. We demonstrate the effectiveness of our method on the tasks of image classiﬁcation and object detection, exploiting two newly created semi-synthetic and real-world omnidirectional datasets.},
	pages = {525--541},
	booktitle = {Computer Vision – {ECCV} 2018},
	publisher = {Springer International Publishing},
	author = {Coors, Benjamin and Condurache, Alexandru Paul and Geiger, Andreas},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	urldate = {2019-05-27},
	date = {2018},
	langid = {english},
	doi = {10.1007/978-3-030-01240-3_32}
}

@online{noauthor_healpix_nodate,
	title = {{HEALPix} - Features},
	url = {https://healpix.sourceforge.io/},
	urldate = {2019-05-27}
}

@article{gimbutas_fast_2013,
	title = {A Fast Algorithm for Spherical Grid Rotations and Its Application to Singular Quadrature},
	volume = {35},
	issn = {1064-8275, 1095-7197},
	url = {http://epubs.siam.org/doi/10.1137/120900587},
	doi = {10.1137/120900587},
	abstract = {We present a fast and accurate algorithm for evaluating singular integral operators on smooth surfaces that are globally parametrized by spherical coordinates. Problems of this type arise, for example, in simulating Stokes ﬂows with particulate suspensions and in multi-particle scattering calculations. For smooth surfaces, spherical harmonic expansions are commonly used for geometry representation and the evaluation of the singular integrals is carried out with a spectrally accurate quadrature rule on a set of rotated spherical grids. We propose a new algorithm that interpolates function values on the rotated spherical grids via hybrid nonuniform {FFTs}. The algorithm has a small complexity constant, and the cost of applying the quadrature rule is nearly-optimal O(p4 log p) for a spherical harmonic expansion of degree p.},
	pages = {A2738--A2751},
	number = {6},
	journaltitle = {{SIAM} Journal on Scientific Computing},
	shortjournal = {{SIAM} J. Sci. Comput.},
	author = {Gimbutas, Zydrunas and Veerapaneni, Shravan},
	urldate = {2019-05-27},
	date = {2013-01},
	langid = {english}
}

@article{keiner_fast_2008,
	title = {Fast evaluation of quadrature formulae on the sphere},
	volume = {77},
	issn = {0025-5718, 1088-6842},
	url = {http://www.ams.org/journal-getitem?pii=S0025-5718-07-02029-7},
	doi = {10.1090/S0025-5718-07-02029-7},
	abstract = {Recently, a fast approximate algorithm for the evaluation of expansions in terms of standard L2 S2 -orthonormal spherical harmonics at arbitrary nodes on the sphere S2 has been proposed in [S. Kunis and D. Potts. Fast spherical Fourier algorithms. J. Comput. Appl. Math., 161:75–98, 2003]. The aim of this paper is to develop a new fast algorithm for the adjoint problem which can be used to compute expansion coeﬃcients from sampled data by means of quadrature rules.},
	pages = {397--419},
	number = {261},
	journaltitle = {Mathematics of Computation},
	shortjournal = {Math. Comp.},
	author = {Keiner, Jens and Potts, Daniel},
	urldate = {2019-05-27},
	date = {2008-01-01},
	langid = {english}
}

@article{keiner_fast_2008-1,
	title = {Fast evaluation of quadrature formulae on the sphere},
	volume = {77},
	issn = {0025-5718, 1088-6842},
	url = {http://www.ams.org/journal-getitem?pii=S0025-5718-07-02029-7},
	doi = {10.1090/S0025-5718-07-02029-7},
	abstract = {Recently, a fast approximate algorithm for the evaluation of expansions in terms of standard L2 S2 -orthonormal spherical harmonics at arbitrary nodes on the sphere S2 has been proposed in [S. Kunis and D. Potts. Fast spherical Fourier algorithms. J. Comput. Appl. Math., 161:75–98, 2003]. The aim of this paper is to develop a new fast algorithm for the adjoint problem which can be used to compute expansion coeﬃcients from sampled data by means of quadrature rules.},
	pages = {397--419},
	number = {261},
	journaltitle = {Mathematics of Computation},
	shortjournal = {Math. Comp.},
	author = {Keiner, Jens and Potts, Daniel},
	urldate = {2019-05-27},
	date = {2008-01-01},
	langid = {english}
}

@article{driscoll_computing_1994,
	title = {Computing Fourier Transforms and Convolutions on the 2-Sphere},
	volume = {15},
	issn = {0196-8858},
	url = {http://www.sciencedirect.com/science/article/pii/S0196885884710086},
	doi = {10.1006/aama.1994.1008},
	abstract = {This paper considers the problem of efficient computation of the spherical harmonic expansion, or Fourier transform, of functions defined on the two dimensional sphere, S2. The resulting algorithms are applied to the efficient computation of convolutions of functions on the sphere. We begin by proving convolution theorems generalizing well known and useful results from the abelian case. These convolution theorems are then used to develop a sampling theorem on the sphere. which reduces the calculation of Fourier transforms and convolutions of band-limited functions to discrete computations. We show how to perform these efficiently, starting with an O(n(log n)2) time algorithm for computing the Legendre transform of a function defined on the interval [−1,1] sampled at n points there. Theoretical and experimental results on the effects of finite precision arithmetic are presented. The Legendre transform algorithm is then generalized to obtain an algorithm for the Fourier transform, requiring O(n(log n)2) time, and an algorithm for its inverse in O(n1.5) time, where n is the number of points on the sphere at which the function is sampled. This improves the naive O(n2) bound, which is the best previously known. These transforms give an O(n1.5) algorithm for convolving two functions on the sphere.},
	pages = {202--250},
	number = {2},
	journaltitle = {Advances in Applied Mathematics},
	shortjournal = {Advances in Applied Mathematics},
	author = {Driscoll, J. R. and Healy, D. M.},
	urldate = {2019-05-27},
	date = {1994-06-01}
}

@article{wehner_resolution_2015,
	title = {Resolution Dependence of Future Tropical Cyclone Projections of {CAM}5.1 in the U.S. {CLIVAR} Hurricane Working Group Idealized Configurations},
	volume = {28},
	issn = {0894-8755},
	url = {https://journals.ametsoc.org/doi/full/10.1175/JCLI-D-14-00311.1},
	doi = {10.1175/JCLI-D-14-00311.1},
	abstract = {The four idealized configurations of the U.S. {CLIVAR} Hurricane Working Group are integrated using the global Community Atmospheric Model version 5.1 at two different horizontal resolutions, approximately 100 and 25 km. The publicly released 0.9° × 1.3° configuration is a poor predictor of the sign of the 0.23° × 0.31° model configuration’s change in the total number of tropical storms in a warmer climate. However, it does predict the sign of the higher-resolution configuration’s change in the number of intense tropical cyclones in a warmer climate. In the 0.23° × 0.31° model configuration, both increased {CO}2 concentrations and elevated sea surface temperature ({SST}) independently lower the number of weak tropical storms and shorten their average duration. Conversely, increased {SST} causes more intense tropical cyclones and lengthens their average duration, resulting in a greater number of intense tropical cyclone days globally. Increased {SST} also increased maximum tropical storm instantaneous precipitation rates across all storm intensities. It was found that while a measure of maximum potential intensity based on climatological mean quantities adequately predicts the 0.23° × 0.31° model’s forced response in its most intense simulated tropical cyclones, a related measure of cyclogenesis potential fails to predict the model’s actual cyclogenesis response to warmer {SSTs}. These analyses lead to two broader conclusions: 1) Projections of future tropical storm activity obtained by a direct tracking of tropical storms simulated by coarse-resolution climate models must be interpreted with caution. 2) Projections of future tropical cyclogenesis obtained from metrics of model behavior that are based solely on changes in long-term climatological fields and tuned to historical records must also be interpreted with caution.},
	pages = {3905--3925},
	number = {10},
	journaltitle = {Journal of Climate},
	shortjournal = {J. Climate},
	author = {Wehner, Michael and {Prabhat} and Reed, Kevin A. and Stone, Dáithí and Collins, William D. and Bacmeister, Julio},
	urldate = {2019-05-27},
	date = {2015-02-12}
}

@article{racah_extremeweather:_2016,
	title = {{ExtremeWeather}: A large-scale climate dataset for semi-supervised detection, localization, and understanding of extreme weather events},
	url = {http://arxiv.org/abs/1612.02095},
	shorttitle = {{ExtremeWeather}},
	abstract = {Then detection and identification of extreme weather events in large-scale climate simulations is an important problem for risk management, informing governmental policy decisions and advancing our basic understanding of the climate system. Recent work has shown that fully supervised convolutional neural networks ({CNNs}) can yield acceptable accuracy for classifying well-known types of extreme weather events when large amounts of labeled data are available. However, many different types of spatially localized climate patterns are of interest including hurricanes, extra-tropical cyclones, weather fronts, and blocking events among others. Existing labeled data for these patterns can be incomplete in various ways, such as covering only certain years or geographic areas and having false negatives. This type of climate data therefore poses a number of interesting machine learning challenges. We present a multichannel spatiotemporal {CNN} architecture for semi-supervised bounding box prediction and exploratory data analysis. We demonstrate that our approach is able to leverage temporal information and unlabeled data to improve the localization of extreme weather events. Further, we explore the representations learned by our model in order to better understand this important data. We present a dataset, {ExtremeWeather}, to encourage machine learning research in this area and to help facilitate further work in understanding and mitigating the effects of climate change. The dataset is available at extremeweatherdataset.github.io and the code is available at https://github.com/eracah/hur-detect.},
	journaltitle = {{arXiv}:1612.02095 [cs, stat]},
	author = {Racah, Evan and Beckham, Christopher and Maharaj, Tegan and Kahou, Samira Ebrahimi and Prabhat and Pal, Christopher},
	urldate = {2019-05-27},
	date = {2016-12-06},
	eprinttype = {arxiv},
	eprint = {1612.02095},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning}
}

@article{jiang_spherical_2019,
	title = {Spherical {CNNs} on Unstructured Grids},
	url = {http://arxiv.org/abs/1901.02039},
	abstract = {We present an efficient convolution kernel for Convolutional Neural Networks ({CNNs}) on unstructured grids using parameterized differential operators while focusing on spherical signals such as panorama images or planetary signals. To this end, we replace conventional convolution kernels with linear combinations of differential operators that are weighted by learnable parameters. Differential operators can be efficiently estimated on unstructured grids using one-ring neighbors, and learnable parameters can be optimized through standard back-propagation. As a result, we obtain extremely efficient neural networks that match or outperform state-of-the-art network architectures in terms of performance but with a significantly lower number of network parameters. We evaluate our algorithm in an extensive series of experiments on a variety of computer vision and climate science tasks, including shape classification, climate pattern segmentation, and omnidirectional image semantic segmentation. Overall, we present (1) a novel {CNN} approach on unstructured grids using parameterized differential operators for spherical signals, and (2) we show that our unique kernel parameterization allows our model to achieve the same or higher accuracy with significantly fewer network parameters.},
	journaltitle = {{arXiv}:1901.02039 [cs]},
	author = {Jiang, Chiyu "Max" and Huang, Jingwei and Kashinath, Karthik and Prabhat and Marcus, Philip and Niessner, Matthias},
	urldate = {2019-05-25},
	date = {2019-01-07},
	eprinttype = {arxiv},
	eprint = {1901.02039},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning}
}

@article{wang_learning_2019,
	title = {{LEARNING} {GEOMETRIC} {OPERATORS} {ON} {MESHES}},
	abstract = {Applications in computer vision, simulation, and computer-aided design motivate interest in deep learning methods that operate directly on triangle meshes. As an analogy to convolutional ﬁlters on images, these methods successively apply local geometric operators like the Laplacian and the Dirac operator to per-element features; this pipeline can be interpreted as applying a ﬁlter to features written in the operators’ spectral bases. Such a technique is analogous to using convolutional ﬁlters with ﬁxed kernels on images, which severely limits representation capacity. As a ﬂexible alternative, we propose learning geometric operators from data in a task-speciﬁc fashion. Inspired by numerical algorithms operating on irregular domains, our framework learns from meshes using a parametric learnable family of linear operators, generalizing previous architectures.},
	pages = {14},
	author = {Wang, Yu and Kim, Vladimir and Bronstein, Michael M and Solomon, Justin},
	date = {2019},
	langid = {english}
}

@article{keriven_universal_2019,
	title = {Universal Invariant and Equivariant Graph Neural Networks},
	url = {http://arxiv.org/abs/1905.04943},
	abstract = {Graph Neural Networks ({GNN}) come in many flavors, but should always be either invariant (permutation of the nodes of the input graph does not affect the output) or equivariant (permutation of the input permutes the output). In this paper, we consider a specific class of invariant and equivariant networks, for which we prove new universality theorems. More precisely, we consider networks with a single hidden layer, obtained by summing channels formed by applying an equivariant linear operator, a pointwise non-linearity and either an invariant or equivariant linear operator. Recently, Maron et al. (2019) showed that by allowing higher-order tensorization inside the network, universal invariant {GNNs} can be obtained. As a first contribution, we propose an alternative proof of this result, which relies on the Stone-Weierstrass theorem for algebra of real-valued functions. Our main contribution is then an extension of this result to the equivariant case, which appears in many practical applications but has been less studied from a theoretical point of view. The proof relies on a new generalized Stone-Weierstrass theorem for algebra of equivariant functions, which is of independent interest. Finally, unlike many previous settings that consider a fixed number of nodes, our results show that a {GNN} defined by a single set of parameters can approximate uniformly well a function defined on graphs of varying size.},
	journaltitle = {{arXiv}:1905.04943 [cs, stat]},
	author = {Keriven, Nicolas and Peyré, Gabriel},
	urldate = {2019-05-25},
	date = {2019-05-13},
	eprinttype = {arxiv},
	eprint = {1905.04943},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{hanocka_meshcnn:_2018,
	title = {{MeshCNN}: A Network with an Edge},
	url = {http://arxiv.org/abs/1809.05910},
	shorttitle = {{MeshCNN}},
	abstract = {Polygonal meshes provide an efficient representation for 3D shapes. They explicitly capture both shape surface and topology, and leverage non-uniformity to represent large flat regions as well as sharp, intricate features. This non-uniformity and irregularity, however, inhibits mesh analysis efforts using neural networks that combine convolution and pooling operations. In this paper, we utilize the unique properties of the mesh for a direct analysis of 3D shapes using {MeshCNN}, a convolutional neural network designed specifically for triangular meshes. Analogous to classic {CNNs}, {MeshCNN} combines specialized convolution and pooling layers that operate on the mesh edges, by leveraging their intrinsic geodesic connections. Convolutions are applied on edges and the four edges of their incident triangles, and pooling is applied via an edge collapse operation that retains surface topology, thereby, generating new mesh connectivity for the subsequent convolutions. {MeshCNN} learns which edges to collapse, thus forming a task-driven process where the network exposes and expands the important features while discarding the redundant ones. We demonstrate the effectiveness of our task-driven pooling on various learning tasks applied to 3D meshes.},
	journaltitle = {{arXiv}:1809.05910 [cs, stat]},
	author = {Hanocka, Rana and Hertz, Amir and Fish, Noa and Giryes, Raja and Fleishman, Shachar and Cohen-Or, Daniel},
	urldate = {2019-05-25},
	date = {2018-09-16},
	eprinttype = {arxiv},
	eprint = {1809.05910},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@online{noauthor_meshcnn_nodate,
	title = {{MeshCNN}},
	url = {https://ranahanocka.github.io/MeshCNN/},
	urldate = {2019-05-25}
}

@article{chen_semi-supervised_2019,
	title = {Semi-supervised learning via Feedforward-Designed Convolutional Neural Networks},
	url = {http://arxiv.org/abs/1902.01980},
	abstract = {A semi-supervised learning framework using the feedforward-designed convolutional neural networks ({FF}-{CNNs}) is proposed for image classification in this work. One unique property of {FF}-{CNNs} is that no backpropagation is used in model parameters determination. Since unlabeled data may not always enhance semi-supervised learning, we define an effective quality score and use it to select a subset of unlabeled data in the training process. We conduct experiments on the {MNIST}, {SVHN}, and {CIFAR}-10 datasets, and show that the proposed semi-supervised {FF}-{CNN} solution outperforms the {CNN} trained by backpropagation ({BP}-{CNN}) when the amount of labeled data is reduced. Furthermore, we develop an ensemble system that combines the output decision vectors of different semi-supervised {FF}-{CNNs} to boost classification accuracy. The ensemble systems can achieve further performance gains on all three benchmarking datasets.},
	journaltitle = {{arXiv}:1902.01980 [cs]},
	author = {Chen, Yueru and Yang, Yijing and Zhang, Min and Kuo, C.-C. Jay},
	urldate = {2019-05-21},
	date = {2019-02-05},
	eprinttype = {arxiv},
	eprint = {1902.01980},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{keriven_universal_2019-1,
	title = {Universal Invariant and Equivariant Graph Neural Networks},
	url = {http://arxiv.org/abs/1905.04943},
	abstract = {Graph Neural Networks ({GNN}) come in many flavors, but should always be either invariant (permutation of the nodes of the input graph does not affect the output) or equivariant (permutation of the input permutes the output). In this paper, we consider a specific class of invariant and equivariant networks, for which we prove new universality theorems. More precisely, we consider networks with a single hidden layer, obtained by summing channels formed by applying an equivariant linear operator, a pointwise non-linearity and either an invariant or equivariant linear operator. Recently, Maron et al. (2019) showed that by allowing higher-order tensorization inside the network, universal invariant {GNNs} can be obtained. As a first contribution, we propose an alternative proof of this result, which relies on the Stone-Weierstrass theorem for algebra of real-valued functions. Our main contribution is then an extension of this result to the equivariant case, which appears in many practical applications but has been less studied from a theoretical point of view. The proof relies on a new generalized Stone-Weierstrass theorem for algebra of equivariant functions, which is of independent interest. Finally, unlike many previous settings that consider a fixed number of nodes, our results show that a {GNN} defined by a single set of parameters can approximate uniformly well a function defined on graphs of varying size.},
	journaltitle = {{arXiv}:1905.04943 [cs, stat]},
	author = {Keriven, Nicolas and Peyré, Gabriel},
	urldate = {2019-05-14},
	date = {2019-05-13},
	eprinttype = {arxiv},
	eprint = {1905.04943},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{saff_distributing_1997,
	title = {Distributing many points on a sphere},
	volume = {19},
	issn = {0343-6993},
	url = {http://link.springer.com/10.1007/BF03024331},
	doi = {10.1007/BF03024331},
	pages = {5--11},
	number = {1},
	journaltitle = {The Mathematical Intelligencer},
	shortjournal = {The Mathematical Intelligencer},
	author = {Saff, E. B. and Kuijlaars, A. B. J.},
	urldate = {2019-04-30},
	date = {1997-12},
	langid = {english}
}

@article{ronchi_cubed_1996,
	title = {The “Cubed Sphere”: A New Method for the Solution of Partial Differential Equations in Spherical Geometry},
	volume = {124},
	issn = {00219991},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0021999196900479},
	doi = {10.1006/jcph.1996.0047},
	shorttitle = {The “Cubed Sphere”},
	pages = {93--114},
	number = {1},
	journaltitle = {Journal of Computational Physics},
	shortjournal = {Journal of Computational Physics},
	author = {Ronchi, C. and Iacono, R. and Paolucci, P.S.},
	urldate = {2019-04-29},
	date = {1996-03},
	langid = {english}
}

@online{noauthor_index_nodate,
	title = {index},
	url = {https://extremeweatherdataset.github.io/},
	urldate = {2019-04-29}
}

@online{noauthor_large_nodate,
	title = {Large Scale Parsing},
	url = {http://buildingparser.stanford.edu/dataset.html},
	urldate = {2019-04-25}
}

@article{su_pano2vid:_nodate,
	title = {Pano2Vid: Automatic cinematography for watching 360◦ videos},
	abstract = {We introduce the novel task of Pano2Vid — automatic cinematography in panoramic 360◦ videos. Given a 360◦ video, the goal is to direct an imaginary camera to virtually capture natural-looking normal ﬁeld-of-view ({NFOV}) video. By selecting “where to look” within the panorama at each time step, Pano2Vid aims to free both the videographer and the end viewer from the task of determining what to watch. Towards this goal, we ﬁrst compile a dataset of 360◦ videos downloaded from the web, together with human-edited {NFOV} camera trajectories to facilitate evaluation. Next, we propose {AutoCam}, a data-driven approach to solve the Pano2Vid task. {AutoCam} leverages {NFOV} web video to discriminatively identify space-time “glimpses” of interest at each time instant, and then uses dynamic programming to select optimal humanlike camera trajectories. Through experimental evaluation on multiple newly deﬁned Pano2Vid performance measures against several baselines, we show that our method successfully produces informative videos that could conceivably have been captured by human videographers.},
	pages = {16},
	author = {Su, Yu-Chuan and Jayaraman, Dinesh and Grauman, Kristen},
	langid = {english}
}

@online{noauthor_pano2vid_nodate,
	title = {Pano2Vid},
	url = {http://vision.cs.utexas.edu/projects/Pano2Vid/#Pano2Vid},
	urldate = {2019-04-25}
}

@online{noauthor_testing_nodate,
	title = {Testing data — {HARDI} reconstruction challenge 2013},
	url = {http://hardi.epfl.ch/static/events/2013_ISBI/testing_data.html},
	urldate = {2019-04-25}
}

@article{descoteaux_regularized_2007,
	title = {Regularized, fast, and robust analytical Q-ball imaging},
	volume = {58},
	issn = {1522-2594},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.21277},
	doi = {10.1002/mrm.21277},
	abstract = {We propose a regularized, fast, and robust analytical solution for the Q-ball imaging ({QBI}) reconstruction of the orientation distribution function ({ODF}) together with its detailed validation and a discussion on its benefits over the state-of-the-art. Our analytical solution is achieved by modeling the raw high angular resolution diffusion imaging signal with a spherical harmonic basis that incorporates a regularization term based on the Laplace–Beltrami operator defined on the unit sphere. This leads to an elegant mathematical simplification of the Funk–Radon transform which approximates the {ODF}. We prove a new corollary of the Funk–Hecke theorem to obtain this simplification. Then, we show that the Laplace–Beltrami regularization is theoretically and practically better than Tikhonov regularization. At the cost of slightly reducing angular resolution, the Laplace–Beltrami regularization reduces {ODF} estimation errors and improves fiber detection while reducing angular error in the {ODF} maxima detected. Finally, a careful quantitative validation is performed against ground truth from synthetic data and against real data from a biological phantom and a human brain dataset. We show that our technique is also able to recover known fiber crossings in the human brain and provides the practical advantage of being up to 15 times faster than original numerical {QBI} method. Magn Reson Med 58:497–510, 2007. © 2007 Wiley-Liss, Inc.},
	pages = {497--510},
	number = {3},
	journaltitle = {Magnetic Resonance in Medicine},
	author = {Descoteaux, Maxime and Angelino, Elaine and Fitzgibbons, Shaun and Deriche, Rachid},
	urldate = {2019-04-25},
	date = {2007},
	langid = {english},
	keywords = {Funk Radon transform, Q-ball imaging ({QBI}), diffusion tensor imaging ({DTI}), fiber tractography, high angular resolution diffusion imaging ({HARDI}), orientation distribution function ({ODF}), regularization, spherical harmonic}
}

@article{mudigonda_segmenting_nodate,
	title = {Segmenting and Tracking Extreme Climate Events using Neural Networks},
	abstract = {Predicting extreme weather events in a warming world is one of the most pressing and challenging problems that humanity faces today. Deep learning and advances in the ﬁeld of computer vision provide a novel and powerful set of tools to tackle this demanding task. However, unlike images employed in computer vision, climate datasets present unique challenges. The channels (or physical variables) in a climate dataset are manifold, and unlike pixel information in computer vision data, these channels have physical properties. We present preliminary work using a convolutional neural network and a recurrent neural network for tracking cyclonic storms. We also show how state-of-the-art segmentation algorithms can be used to segment atmospheric rivers and tropical cyclones in global climate model simulations. We show how the latest advances in machine learning and computer vision can provide solutions to important problems in weather and climate sciences, and we highlight unique challenges and limitations.},
	pages = {5},
	author = {Mudigonda, Mayur and Kim, Sookyung and Mahesh, Ankur and Kahou, Samira and Kashinath, Karthik and Williams, Dean and Michalski, Vincent and O’Brien, Travis and Prabhat, Mr},
	langid = {english}
}

@online{noauthor_shrec_nodate,
	title = {{SHREC} 2017: Large-scale 3D Shape Retrieval from {ShapeNet} Core55},
	url = {https://shapenet.cs.stanford.edu/shrec17/},
	urldate = {2019-04-25},
	keywords = {dataset}
}

@article{armeni_joint_nodate,
	title = {Joint 2D-3D-Semantic Data for Indoor Scene Understanding},
	abstract = {We present a dataset of large-scale indoor spaces that provides a variety of mutually registered modalities from 2D, 2.5D and 3D domains, with instance-level semantic and geometric annotations. The dataset covers over 6,000 m2 and contains over 70,000 {RGB} images, along with the corresponding depths, surface normals, semantic annotations, global {XYZ} images (all in forms of both regular and 360◦ equirectangular images) as well as camera information. It also includes registered raw and semantically annotated 3D meshes and point clouds. The dataset enables development of joint and cross-modal learning models and potentially unsupervised approaches utilizing the regularities present in large-scale indoor spaces.},
	pages = {9},
	author = {Armeni, Iro and Sax, Alexander and Zamir, Amir R and Savarese, Silvio},
	langid = {english}
}

@online{noauthor_large_nodate-1,
	title = {Large Scale Parsing},
	url = {http://buildingparser.stanford.edu/dataset.html},
	urldate = {2019-04-24}
}

@article{khalid_optimal-dimensionality_2014,
	title = {An Optimal-Dimensionality Sampling Scheme on the Sphere with Fast Spherical Harmonic Transforms},
	volume = {62},
	issn = {1053-587X, 1941-0476},
	url = {http://arxiv.org/abs/1403.4661},
	doi = {10.1109/TSP.2014.2337278},
	abstract = {We develop a sampling scheme on the sphere that permits accurate computation of the spherical harmonic transform and its inverse for signals band-limited at \$L\$ using only \$L{\textasciicircum}2\$ samples. We obtain the optimal number of samples given by the degrees of freedom of the signal in harmonic space. The number of samples required in our scheme is a factor of two or four fewer than existing techniques, which require either \$2L{\textasciicircum}2\$ or \$4L{\textasciicircum}2\$ samples. We note, however, that we do not recover a sampling theorem on the sphere, where spherical harmonic transforms are theoretically exact. Nevertheless, we achieve high accuracy even for very large band-limits. For our optimal-dimensionality sampling scheme, we develop a fast and accurate algorithm to compute the spherical harmonic transform (and inverse), with computational complexity comparable with existing schemes in practice. We conduct numerical experiments to study in detail the stability, accuracy and computational complexity of the proposed transforms. We also highlight the advantages of the proposed sampling scheme and associated transforms in the context of potential applications.},
	pages = {4597--4610},
	number = {17},
	journaltitle = {{IEEE} Transactions on Signal Processing},
	author = {Khalid, Zubair and Kennedy, Rodney A. and {McEwen}, Jason D.},
	urldate = {2019-04-24},
	date = {2014-09},
	eprinttype = {arxiv},
	eprint = {1403.4661},
	keywords = {Computer Science - Information Theory}
}

@article{shuman_distributed_2011,
	title = {Distributed Signal Processing via Chebyshev Polynomial Approximation},
	url = {http://arxiv.org/abs/1111.5239},
	abstract = {Unions of graph multiplier operators are an important class of linear operators for processing signals defined on graphs. We present a novel method to efficiently distribute the application of these operators. The proposed method features approximations of the graph multipliers by shifted Chebyshev polynomials, whose recurrence relations make them readily amenable to distributed computation. We demonstrate how the proposed method can be applied to distributed processing tasks such as smoothing, denoising, inverse filtering, and semi-supervised classification, and show that the communication requirements of the method scale gracefully with the size of the network.},
	journaltitle = {{arXiv}:1111.5239 [cs]},
	author = {Shuman, David I. and Vandergheynst, Pierre and Kressner, Daniel and Frossard, Pascal},
	urldate = {2019-04-17},
	date = {2011-11-22},
	eprinttype = {arxiv},
	eprint = {1111.5239},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing}
}

@article{bruna_spectral_2013,
	title = {Spectral Networks and Locally Connected Networks on Graphs},
	url = {http://arxiv.org/abs/1312.6203},
	abstract = {Convolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of {CNNs} to signals defined on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for low-dimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efficient deep architectures.},
	journaltitle = {{arXiv}:1312.6203 [cs]},
	author = {Bruna, Joan and Zaremba, Wojciech and Szlam, Arthur and {LeCun}, Yann},
	urldate = {2019-04-16},
	date = {2013-12-20},
	eprinttype = {arxiv},
	eprint = {1312.6203},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing}
}

@online{noauthor_matterport3d:_nodate,
	title = {Matterport3D: Learning from {RGB}-D Data in Indoor Environments},
	url = {https://niessner.github.io/Matterport/},
	urldate = {2019-04-16}
}

@online{noauthor_geometric_nodate,
	title = {Geometric Deep Learning},
	url = {http://geometricdeeplearning.com/},
	urldate = {2019-04-16},
	langid = {english}
}

@article{cohen_convolutional_2017,
	title = {Convolutional Networks for Spherical Signals},
	url = {http://arxiv.org/abs/1709.04893},
	abstract = {The success of convolutional networks in learning problems involving planar signals such as images is due to their ability to exploit the translation symmetry of the data distribution through weight sharing. Many areas of science and egineering deal with signals with other symmetries, such as rotation invariant data on the sphere. Examples include climate and weather science, astrophysics, and chemistry. In this paper we present spherical convolutional networks. These networks use convolutions on the sphere and rotation group, which results in rotational weight sharing and rotation equivariance. Using a synthetic spherical {MNIST} dataset, we show that spherical convolutional networks are very effective at dealing with rotationally invariant classification problems.},
	journaltitle = {{arXiv}:1709.04893 [cs]},
	author = {Cohen, Taco and Geiger, Mario and Köhler, Jonas and Welling, Max},
	urldate = {2019-04-12},
	date = {2017-09-14},
	eprinttype = {arxiv},
	eprint = {1709.04893},
	keywords = {Computer Science - Machine Learning}
}

@article{ran_convolutional_2017,
	title = {Convolutional Neural Network-Based Robot Navigation Using Uncalibrated Spherical Images},
	volume = {17},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/17/6/1341},
	doi = {10.3390/s17061341},
	abstract = {Vision-based mobile robot navigation is a vibrant area of research with numerous algorithms having been developed, the vast majority of which either belong to the scene-oriented simultaneous localization and mapping ({SLAM}) or fall into the category of robot-oriented lane-detection/trajectory tracking. These methods suffer from high computational cost and require stringent labelling and calibration efforts. To address these challenges, this paper proposes a lightweight robot navigation framework based purely on uncalibrated spherical images. To simplify the orientation estimation, path prediction and improve computational efficiency, the navigation problem is decomposed into a series of classification tasks. To mitigate the adverse effects of insufficient negative samples in the “navigation via classification” task, we introduce the spherical camera for scene capturing, which enables 360° fisheye panorama as training samples and generation of sufficient positive and negative heading directions. The classification is implemented as an end-to-end Convolutional Neural Network ({CNN}), trained on our proposed Spherical-Navi image dataset, whose category labels can be efficiently collected. This {CNN} is capable of predicting potential path directions with high confidence levels based on a single, uncalibrated spherical image. Experimental results demonstrate that the proposed framework outperforms competing ones in realistic applications.},
	pages = {1341},
	number = {6},
	journaltitle = {Sensors},
	author = {Ran, Lingyan and Zhang, Yanning and Zhang, Qilin and Yang, Tao},
	urldate = {2019-04-12},
	date = {2017-06},
	langid = {english},
	keywords = {convolutional neural networks, navigation via learning, spherical camera, vision-based robot navigation}
}

@incollection{su_learning_2017,
	title = {Learning Spherical Convolution for Fast Features from 360° Imagery},
	url = {http://papers.nips.cc/paper/6656-learning-spherical-convolution-for-fast-features-from-360-imagery.pdf},
	pages = {529--539},
	booktitle = {Advances in Neural Information Processing Systems 30},
	publisher = {Curran Associates, Inc.},
	author = {Su, Yu-Chuan and Grauman, Kristen},
	editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	urldate = {2019-04-12},
	date = {2017}
}

@inproceedings{sinha_deep_2016,
	title = {Deep Learning 3D Shape Surfaces Using Geometry Images},
	isbn = {978-3-319-46466-4},
	series = {Lecture Notes in Computer Science},
	abstract = {Surfaces serve as a natural parametrization to 3D shapes. Learning surfaces using convolutional neural networks ({CNNs}) is a challenging task. Current paradigms to tackle this challenge are to either adapt the convolutional filters to operate on surfaces, learn spectral descriptors defined by the Laplace-Beltrami operator, or to drop surfaces altogether in lieu of voxelized inputs. Here we adopt an approach of converting the 3D shape into a ‘geometry image’ so that standard {CNNs} can directly be used to learn 3D shapes. We qualitatively and quantitatively validate that creating geometry images using authalic parametrization on a spherical domain is suitable for robust learning of 3D shape surfaces. This spherically parameterized shape is then projected and cut to convert the original 3D shape into a flat and regular geometry image. We propose a way to implicitly learn the topology and structure of 3D shapes using geometry images encoded with suitable features. We show the efficacy of our approach to learn 3D shape surfaces for classification and retrieval tasks on non-rigid and rigid shape datasets.},
	pages = {223--240},
	booktitle = {Computer Vision – {ECCV} 2016},
	publisher = {Springer International Publishing},
	author = {Sinha, Ayan and Bai, Jing and Ramani, Karthik},
	editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
	date = {2016},
	langid = {english},
	keywords = {3D Shape, {CNN}, Deep learning, Geometry images, Surfaces}
}

@incollection{boomsma_spherical_2017,
	title = {Spherical convolutions and their application in molecular modelling},
	url = {http://papers.nips.cc/paper/6935-spherical-convolutions-and-their-application-in-molecular-modelling.pdf},
	pages = {3433--3443},
	booktitle = {Advances in Neural Information Processing Systems 30},
	publisher = {Curran Associates, Inc.},
	author = {Boomsma, Wouter and Frellsen, Jes},
	editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	urldate = {2019-04-12},
	date = {2017}
}

@inproceedings{frossard_graph-based_2017,
	location = {Venice, Italy},
	title = {Graph-Based Classification of Omnidirectional Images},
	isbn = {978-1-5386-1034-3},
	url = {http://ieeexplore.ieee.org/document/8265315/},
	doi = {10.1109/ICCVW.2017.106},
	abstract = {Omnidirectional cameras are widely used in such areas as robotics and virtual reality as they provide a wide ﬁeld of view. Their images are often processed with classical methods, which might unfortunately lead to non-optimal solutions as these methods are designed for planar images that have different geometrical properties than omnidirectional ones. In this paper we study image classiﬁcation task by taking into account the speciﬁc geometry of omnidirectional cameras with graph-based representations. In particular, we extend deep learning architectures to data on graphs; we propose a principled way of graph construction such that convolutional ﬁlters respond similarly for the same pattern on different positions of the image regardless of lens distortions. Our experiments show that the proposed method outperforms current techniques for the omnidirectional image classiﬁcation problem.},
	eventtitle = {2017 {IEEE} International Conference on Computer Vision Workshop ({ICCVW})},
	pages = {860--869},
	booktitle = {2017 {IEEE} International Conference on Computer Vision Workshops ({ICCVW})},
	publisher = {{IEEE}},
	author = {Frossard, Pascal and Khasanova, Renata},
	urldate = {2019-04-12},
	date = {2017-10},
	langid = {english}
}

@online{ramasinghe_spherical_2018,
	title = {Spherical Convolution — A Theoretical Walk-Through.},
	url = {https://medium.com/@samramasinghe/spherical-convolution-a-theoretical-walk-through-98e98ee64655},
	abstract = {Convolution is an extremely effective technique that can capture useful features from data distributions. Specifically, convolution based…},
	titleaddon = {Medium},
	author = {Ramasinghe, Sameera},
	urldate = {2019-04-12},
	date = {2018-12-14}
}
@book{noauthor_proceedings_2014,
	location = {New York, {NY}},
	title = {Proceedings of {ELM}-2014 volume 1: algorithms and theories},
	isbn = {978-3-319-14062-9},
	series = {Proceedings in adaptation, learning and optimization},
	shorttitle = {Proceedings of {ELM}-2014 volume 1},
	number = {3},
	publisher = {Springer Berlin Heidelberg},
	date = {2014},
	langid = {english}
}

@online{noauthor_data_nodate,
	title = {Data Input Pipeline Performance {\textbar} {TensorFlow} Core},
	url = {https://www.tensorflow.org/guide/performance/datasets},
	titleaddon = {{TensorFlow}},
	urldate = {2019-04-10},
	langid = {english}
}

@online{noauthor_importing_nodate,
	title = {Importing Data {\textbar} {TensorFlow} Core},
	url = {https://www.tensorflow.org/guide/datasets},
	titleaddon = {{TensorFlow}},
	urldate = {2019-04-10},
	langid = {english}
}

@inproceedings{su_multi-view_2015,
	location = {Santiago, Chile},
	title = {Multi-view Convolutional Neural Networks for 3D Shape Recognition},
	isbn = {978-1-4673-8391-2},
	url = {http://ieeexplore.ieee.org/document/7410471/},
	doi = {10.1109/ICCV.2015.114},
	abstract = {A longstanding question in computer vision concerns the representation of 3D shapes for recognition: should 3D shapes be represented with descriptors operating on their native 3D formats, such as voxel grid or polygon mesh, or can they be effectively represented with view-based descriptors? We address this question in the context of learning to recognize 3D shapes from a collection of their rendered views on 2D images. We ﬁrst present a standard {CNN} architecture trained to recognize the shapes’ rendered views independently of each other, and show that a 3D shape can be recognized even from a single view at an accuracy far higher than using state-of-the-art 3D shape descriptors. Recognition rates further increase when multiple views of the shapes are provided. In addition, we present a novel {CNN} architecture that combines information from multiple views of a 3D shape into a single and compact shape descriptor offering even better recognition performance. The same architecture can be applied to accurately recognize human hand-drawn sketches of shapes. We conclude that a collection of 2D views can be highly informative for 3D shape recognition and is amenable to emerging {CNN} architectures and their derivatives.},
	eventtitle = {2015 {IEEE} International Conference on Computer Vision ({ICCV})},
	pages = {945--953},
	booktitle = {2015 {IEEE} International Conference on Computer Vision ({ICCV})},
	publisher = {{IEEE}},
	author = {Su, Hang and Maji, Subhransu and Kalogerakis, Evangelos and Learned-Miller, Erik},
	urldate = {2019-04-09},
	date = {2015-12},
	langid = {english}
}

@online{noauthor_classification_nodate,
	title = {Classification of finite subgroups of {SO}(3,R) - Groupprops},
	url = {https://groupprops.subwiki.org/wiki/Classification_of_finite_subgroups_of_SO(3,R)},
	urldate = {2019-04-05}
}

@inreference{noauthor_symmetry_2019,
	title = {Symmetry group},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Symmetry_group&oldid=888198642},
	abstract = {In group theory, the symmetry group of a geometric object is the group of all transformations under which the object is invariant, endowed with the group operation of composition. Such a transformation is an invertible mapping of the ambient space which takes the object to itself, and which preserves all the relevant structure of the object. A frequent notation for the symmetry group of an object X is G = Sym(X).
For an object in a metric space, its symmetries form a subgroup of the isometry group of the ambient space. This article mainly considers symmetry groups in Euclidean geometry, but the concept may also be studied for more general types of geometric structure.},
	booktitle = {Wikipedia},
	urldate = {2019-04-03},
	date = {2019-03-17},
	langid = {english},
	note = {Page Version {ID}: 888198642}
}

@inreference{noauthor_lie_2019,
	title = {Lie group},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Lie_group&oldid=888309204},
	abstract = {In mathematics, a Lie group (pronounced  "Lee") is a group that is also a differentiable manifold, with the property that the group operations are smooth. Lie groups are named after Norwegian mathematician Sophus Lie, who laid the foundations of the theory of continuous transformation groups.
In rough terms, a Lie group is a continuous group, that is, one whose elements are described by several real parameters. As such, Lie groups provide a natural model for the concept of continuous symmetry, such as rotational symmetry in three dimensions. Lie groups are widely used in many parts of modern mathematics and physics. Lie's original motivation for introducing Lie groups was to model the continuous symmetries of differential equations, in much the same way that finite groups are used in Galois theory to model the discrete symmetries of algebraic equations.},
	booktitle = {Wikipedia},
	urldate = {2019-04-03},
	date = {2019-03-18},
	langid = {english},
	note = {Page Version {ID}: 888309204}
}

@inreference{noauthor_gauge_2019,
	title = {Gauge theory},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Gauge_theory&oldid=887279263},
	abstract = {In physics, a gauge theory is a type of field theory in which the Lagrangian is invariant under certain Lie groups of local transformations.
The term gauge refers to any specific mathematical formalism to regulate redundant degrees of freedom in the Lagrangian. The transformations between possible gauges, called gauge transformations, form a Lie group—referred to as the symmetry group or the gauge group of the theory. Associated with any Lie group is the Lie algebra of group generators. For each group generator there necessarily arises a corresponding field (usually a vector field) called the gauge field. Gauge fields are included in the Lagrangian to ensure its invariance under the local group transformations (called gauge invariance). When such a theory is quantized, the quanta of the gauge fields are called gauge bosons. If the symmetry group is non-commutative, then the gauge theory is referred to as non-abelian gauge theory, the usual example being the Yang–Mills theory.
Many powerful theories in physics are described by Lagrangians that are invariant under some symmetry transformation groups. When they are invariant under a transformation identically performed at every point in the spacetime in which the physical processes occur, they are said to have a global symmetry. Local symmetry, the cornerstone of gauge theories, is a stronger constraint. In fact, a global symmetry is just a local symmetry whose group's parameters are fixed in spacetime (the same way a constant value can be understood as a function of a certain parameter, the output of which is always the same).
Gauge theories are important as the successful field theories explaining the dynamics of elementary particles.  Quantum electrodynamics is an abelian gauge theory with the symmetry group U(1) and has one gauge field, the electromagnetic four-potential, with the photon being the gauge boson. The Standard Model is a non-abelian gauge theory with the symmetry group U(1) × {SU}(2) × {SU}(3) and has a total of twelve gauge bosons: the photon, three weak bosons and eight gluons.
Gauge theories are also important in explaining gravitation in the theory of general relativity.  Its case is somewhat unusual in that the gauge field is a tensor, the Lanczos tensor.  Theories of quantum gravity, beginning with gauge gravitation theory, also postulate the existence of a gauge boson known as the graviton.  Gauge symmetries can be viewed as analogues of the principle of general covariance of general relativity in which the coordinate system can be chosen freely under arbitrary diffeomorphisms of spacetime.  Both gauge invariance and diffeomorphism invariance reflect a redundancy in the description of the system.  An alternative theory of gravitation, gauge theory gravity, replaces the principle of general covariance with a true gauge principle with new gauge fields.
Historically, these ideas were first stated in the context of classical electromagnetism and later in general relativity.  However, the modern importance of gauge symmetries appeared first in the relativistic quantum mechanics of electrons – quantum electrodynamics, elaborated on below. Today, gauge theories are useful in condensed matter, nuclear and high energy physics among other subfields.},
	booktitle = {Wikipedia},
	urldate = {2019-04-03},
	date = {2019-03-11},
	langid = {english},
	note = {Page Version {ID}: 887279263}
}

@article{cohen_gauge_2019,
	title = {Gauge Equivariant Convolutional Networks and the Icosahedral {CNN}},
	url = {http://arxiv.org/abs/1902.04615},
	abstract = {The idea of equivariance to symmetry transformations provides one of the first theoretically grounded principles for neural network architecture design. Equivariant networks have shown excellent performance and data efficiency on vision and medical imaging problems that exhibit symmetries. Here we show how this principle can be extended beyond global symmetries to local gauge transformations, thereby enabling the development of equivariant convolutional networks on general manifolds. We implement gauge equivariant {CNNs} for signals defined on the icosahedron, which provides a reasonable approximation of spherical signals. By choosing to work with this very regular manifold, we are able to implement the gauge equivariant convolution using a single conv2d call, making it a highly scalable and practical alternative to Spherical {CNNs}. We evaluate the Icosahedral {CNN} on omnidirectional image segmentation and climate pattern segmentation, and find that it outperforms previous methods.},
	journaltitle = {{arXiv}:1902.04615 [cs, stat]},
	author = {Cohen, Taco S. and Weiler, Maurice and Kicanaoglu, Berkay and Welling, Max},
	urldate = {2019-04-03},
	date = {2019-02-11},
	eprinttype = {arxiv},
	eprint = {1902.04615},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning}
}

@article{esteves_equivariant_2019,
	title = {Equivariant Multi-View Networks},
	url = {http://arxiv.org/abs/1904.00993},
	abstract = {Several approaches to 3D vision tasks process multiple views of the input independently with deep neural networks pre-trained on natural images, achieving view permutation invariance through a single round of pooling over all views. We argue that this operation discards important information and leads to subpar global descriptors. In this paper, we propose a group convolutional approach to multiple view aggregation where convolutions are performed over a discrete subgroup of the rotation group, enabling, thus, joint reasoning over all views in an equivariant (instead of invariant) fashion, up to the very last layer. We further develop this idea to operate on smaller discrete homogeneous spaces of the rotation group, where a polar view representation is used to maintain equivariance with only a fraction of the number of input views. We set the new state of the art in several large scale 3D shape retrieval tasks, and show additional applications to panoramic scene classification.},
	journaltitle = {{arXiv}:1904.00993 [cs]},
	author = {Esteves, Carlos and Xu, Yinshuang and Allen-Blanchette, Christine and Daniilidis, Kostas},
	urldate = {2019-04-03},
	date = {2019-04-01},
	eprinttype = {arxiv},
	eprint = {1904.00993},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{healy_ffts_2003,
	title = {{FFTs} for the 2-Sphere-Improvements and Variations},
	volume = {9},
	issn = {1069-5869, 1531-5851},
	url = {http://link.springer.com/10.1007/s00041-003-0018-9},
	doi = {10.1007/s00041-003-0018-9},
	abstract = {Earlier work by Driscoll and Healy [18] has produced an efﬁcient algorithm for computing the Fourier transform of band-limited functions on the 2-sphere. In this article we present a reformulation and variation of the original algorithm which results in a greatly improved inverse transform, and consequent improved convolution algorithm for such functions. All require at most O(N log2 N ) operations where N is the number of sample points. We also address implementation considerations and give heuristics for allowing reliable and computationally efﬁcient ﬂoating point implementations of slightly modiﬁed algorithms. These claims are supported by extensive numerical experiments from our implementation in C on {DEC}, {HP}, {SGI} and Linux Pentium platforms. These results indicate that variations of the algorithm are both reliable and efﬁcient for a large range of useful problem sizes. Performance appears to be architecture-dependent. The article concludes with a brief discussion of a few potential applications.},
	pages = {341--385},
	number = {4},
	journaltitle = {Journal of Fourier Analysis and Applications},
	author = {Healy, D.M. and Rockmore, D.N. and Kostelec, P.J. and Moore, S.},
	urldate = {2019-03-27},
	date = {2003-07-01},
	langid = {english}
}

@article{kostelec_soft:_nodate,
	title = {{SOFT}: {SO}(3) Fourier Transforms},
	pages = {21},
	author = {Kostelec, Peter J},
	langid = {english}
}

@article{zhu_negative_2018,
	title = {Negative Log Likelihood Ratio Loss for Deep Neural Network Classification},
	url = {http://arxiv.org/abs/1804.10690},
	abstract = {In deep neural network, the cross-entropy loss function is commonly used for classification. Minimizing cross-entropy is equivalent to maximizing likelihood under assumptions of uniform feature and class distributions. It belongs to generative training criteria which does not directly discriminate correct class from competing classes. We propose a discriminative loss function with negative log likelihood ratio between correct and competing classes. It significantly outperforms the cross-entropy loss on the {CIFAR}-10 image classification task.},
	journaltitle = {{arXiv}:1804.10690 [cs, stat]},
	author = {Zhu, Donglai and Yao, Hengshuai and Jiang, Bei and Yu, Peng},
	urldate = {2019-03-13},
	date = {2018-04-27},
	eprinttype = {arxiv},
	eprint = {1804.10690},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{janocha_loss_2017,
	title = {On Loss Functions for Deep Neural Networks in Classification},
	url = {http://arxiv.org/abs/1702.05659},
	abstract = {Deep neural networks are currently among the most commonly used classifiers. Despite easily achieving very good performance, one of the best selling points of these models is their modular design - one can conveniently adapt their architecture to specific needs, change connectivity patterns, attach specialised layers, experiment with a large amount of activation functions, normalisation schemes and many others. While one can find impressively wide spread of various configurations of almost every aspect of the deep nets, one element is, in authors' opinion, underrepresented - while solving classification problems, vast majority of papers and applications simply use log loss. In this paper we try to investigate how particular choices of loss functions affect deep models and their learning dynamics, as well as resulting classifiers robustness to various effects. We perform experiments on classical datasets, as well as provide some additional, theoretical insights into the problem. In particular we show that L1 and L2 losses are, quite surprisingly, justified classification objectives for deep nets, by providing probabilistic interpretation in terms of expected misclassification. We also introduce two losses which are not typically used as deep nets objectives and show that they are viable alternatives to the existing ones.},
	journaltitle = {{arXiv}:1702.05659 [cs]},
	author = {Janocha, Katarzyna and Czarnecki, Wojciech Marian},
	urldate = {2019-03-13},
	date = {2017-02-18},
	eprinttype = {arxiv},
	eprint = {1702.05659},
	keywords = {Computer Science - Machine Learning}
}

@article{weiler_3d_2018,
	title = {3D Steerable {CNNs}: Learning Rotationally Equivariant Features in Volumetric Data},
	url = {http://arxiv.org/abs/1807.02547},
	shorttitle = {3D Steerable {CNNs}},
	abstract = {We present a convolutional network that is equivariant to rigid body motions. The model uses scalar-, vector-, and tensor fields over 3D Euclidean space to represent data, and equivariant convolutions to map between such representations. These {SE}(3)-equivariant convolutions utilize kernels which are parameterized as a linear combination of a complete steerable kernel basis, which is derived analytically in this paper. We prove that equivariant convolutions are the most general equivariant linear maps between fields over R{\textasciicircum}3. Our experimental results confirm the effectiveness of 3D Steerable {CNNs} for the problem of amino acid propensity prediction and protein structure classification, both of which have inherent {SE}(3) symmetry.},
	journaltitle = {{arXiv}:1807.02547 [cs, stat]},
	author = {Weiler, Maurice and Geiger, Mario and Welling, Max and Boomsma, Wouter and Cohen, Taco},
	urldate = {2019-02-25},
	date = {2018-07-06},
	eprinttype = {arxiv},
	eprint = {1807.02547},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@inreference{noauthor_list_2019,
	title = {List of map projections},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=List_of_map_projections&oldid=883860417},
	abstract = {This list provides an overview of some of the significant or common map projections. Because there is no limit to the number of possible map projections, there is no definitive list that includes all of them.},
	booktitle = {Wikipedia},
	urldate = {2019-02-22},
	date = {2019-02-18},
	langid = {english},
	note = {Page Version {ID}: 883860417}
}

@inproceedings{elahi_comparative_2016,
	title = {Comparative analysis of geometrical properties of sampling schemes on the sphere},
	doi = {10.1109/ICSPCS.2016.7843316},
	abstract = {In this work, we carry out the comparative analysis of the geometrical properties of the sampling schemes on the sphere. Among the sampling schemes devised on the sphere, we focus on equiangular sampling, Gauss-Legendre ({GL}) quadrature based sampling, optimal-dimensionality sampling, sampling points of extremal systems and spherical design as these schemes support the accurate representation of the band-limited signals. We analyse sampling efficiency, minimum geodesic distance, mesh norm, mesh ratio and Riesz s-energy for these sampling schemes. Since these sampling schemes require different number of samples for the accurate representation of a band-limited signal and therefore have different sampling efficiency, we formulate these geometrical properties to take into account the sampling efficiency for a meaningful comparison. We illustrate that the optimal dimensionality, extremal system and spherical design sampling schemes exhibit desirable geometrical properties. Among these schemes, extremal system sampling scheme has superior geometrical properties. However, the accuracy of the representation of a band-limited signal degrades with the increase in band-limit for extremal system sampling scheme, due to which we propose to use extremal point sampling scheme for small band-limits. We also propose to use optimal dimensional sampling scheme for moderate to large band-limits as it exhibits desirable geometrical properties and has the capability to accurately represent the band-limited signal.},
	eventtitle = {2016 10th International Conference on Signal Processing and Communication Systems ({ICSPCS})},
	pages = {1--7},
	booktitle = {2016 10th International Conference on Signal Processing and Communication Systems ({ICSPCS})},
	author = {Elahi, U. and Khalid, Z. and Kennedy, R. A.},
	date = {2016-12},
	keywords = {2-sphere (unit sphere), Australia, Computer science, Electronic mail, Gauss-Legendre quadrature based sampling, Geodesy, Harmonic analysis, Indexes, Riesz s-energy, Sampling, Transforms, band-limited signal, band-limited signals, bandlimited signals, comparative analysis, equiangular sampling, extremal systems sampling point, geometrical properties, mesh norm, mesh ratio, minimum geodesic distance, optimal dimensionality, optimal-dimensionality sampling, sampling efficiency, sampling scheme, signal sampling, spherical design sampling scheme, spherical harmonic transform, spherical harmonics}
}

@online{noauthor_pdf_nodate,
	title = {({PDF}) Fast evaluation of quadrature formulae on the sphere},
	url = {https://www.researchgate.net/publication/220577103_Fast_evaluation_of_quadrature_formulae_on_the_sphere},
	abstract = {{PDF} {\textbar} Recently, a fast approximate algorithm for the evaluation of expansions in terms of standard L2 (double-struck S sign2 )-orthonormal spherical harmonics at arbitrary nodes on the sphere double-struck S sign 2 has been proposed in [S. Kunis and D. Potts. Fast spherical Fourier...},
	titleaddon = {{ResearchGate}},
	urldate = {2019-02-19},
	langid = {english},
	doi = {http://dx.doi.org/10.1090/S0025-5718-07-02029-7}
}

@software{noauthor_computations_2019,
	title = {Computations involving Lie groups and harmonic analysis: {AMLab}-Amsterdam/lie\_learn},
	url = {https://github.com/AMLab-Amsterdam/lie_learn},
	shorttitle = {Computations involving Lie groups and harmonic analysis},
	publisher = {{AMLAB}},
	urldate = {2019-02-19},
	date = {2019-01-06},
	note = {original-date: 2017-03-13T13:20:21Z},
	keywords = {{DiffTypeGrid}}
}

@article{cohen_intertwiners_2018,
	title = {Intertwiners between Induced Representations (with Applications to the Theory of Equivariant Neural Networks)},
	url = {http://arxiv.org/abs/1803.10743},
	abstract = {Group equivariant and steerable convolutional neural networks (regular and steerable G-{CNNs}) have recently emerged as a very effective model class for learning from signal data such as 2D and 3D images, video, and other data where symmetries are present. In geometrical terms, regular G-{CNNs} represent data in terms of scalar fields ("feature channels"), whereas the steerable G-{CNN} can also use vector or tensor fields ("capsules") to represent data. In algebraic terms, the feature spaces in regular G-{CNNs} transform according to a regular representation of the group G, whereas the feature spaces in Steerable G-{CNNs} transform according to the more general induced representations of G. In order to make the network equivariant, each layer in a G-{CNN} is required to intertwine between the induced representations associated with its input and output space. In this paper we present a general mathematical framework for G-{CNNs} on homogeneous spaces like Euclidean space or the sphere. We show, using elementary methods, that the layers of an equivariant network are convolutional if and only if the input and output feature spaces transform according to an induced representation. This result, which follows from G.W. Mackey's abstract theory on induced representations, establishes G-{CNNs} as a universal class of equivariant network architectures, and generalizes the important recent work of Kondor \& Trivedi on the intertwiners between regular representations.},
	journaltitle = {{arXiv}:1803.10743 [cs, stat]},
	author = {Cohen, Taco S. and Geiger, Mario and Weiler, Maurice},
	urldate = {2019-02-19},
	date = {2018-03-28},
	eprinttype = {arxiv},
	eprint = {1803.10743},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{esteves_learning_2017,
	title = {Learning {SO}(3) Equivariant Representations with Spherical {CNNs}},
	url = {http://arxiv.org/abs/1711.06721},
	abstract = {We address the problem of 3D rotation equivariance in convolutional neural networks. 3D rotations have been a challenging nuisance in 3D classification tasks requiring higher capacity and extended data augmentation in order to tackle it. We model 3D data with multi-valued spherical functions and we propose a novel spherical convolutional network that implements exact convolutions on the sphere by realizing them in the spherical harmonic domain. Resulting filters have local symmetry and are localized by enforcing smooth spectra. We apply a novel pooling on the spectral domain and our operations are independent of the underlying spherical resolution throughout the network. We show that networks with much lower capacity and without requiring data augmentation can exhibit performance comparable to the state of the art in standard retrieval and classification benchmarks.},
	journaltitle = {{arXiv}:1711.06721 [cs]},
	author = {Esteves, Carlos and Allen-Blanchette, Christine and Makadia, Ameesh and Daniilidis, Kostas},
	urldate = {2019-02-19},
	date = {2017-11-17},
	eprinttype = {arxiv},
	eprint = {1711.06721},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{defferrard_convolutional_2016,
	title = {Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering},
	url = {http://arxiv.org/abs/1606.09375},
	abstract = {In this work, we are interested in generalizing convolutional neural networks ({CNNs}) from low-dimensional regular grids, where image, video and speech are represented, to high-dimensional irregular domains, such as social networks, brain connectomes or words' embedding, represented by graphs. We present a formulation of {CNNs} in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs. Importantly, the proposed technique offers the same linear computational complexity and constant learning complexity as classical {CNNs}, while being universal to any graph structure. Experiments on {MNIST} and 20NEWS demonstrate the ability of this novel deep learning system to learn local, stationary, and compositional features on graphs.},
	journaltitle = {{arXiv}:1606.09375 [cs, stat]},
	author = {Defferrard, Michaël and Bresson, Xavier and Vandergheynst, Pierre},
	urldate = {2019-02-19},
	date = {2016-06-30},
	eprinttype = {arxiv},
	eprint = {1606.09375},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{shuman_emerging_2013,
	title = {The Emerging Field of Signal Processing on Graphs: Extending High-Dimensional Data Analysis to Networks and Other Irregular Domains},
	volume = {30},
	issn = {1053-5888},
	url = {http://arxiv.org/abs/1211.0053},
	doi = {10.1109/MSP.2012.2235192},
	shorttitle = {The Emerging Field of Signal Processing on Graphs},
	abstract = {In applications such as social, energy, transportation, sensor, and neuronal networks, high-dimensional data naturally reside on the vertices of weighted graphs. The emerging field of signal processing on graphs merges algebraic and spectral graph theoretic concepts with computational harmonic analysis to process such signals on graphs. In this tutorial overview, we outline the main challenges of the area, discuss different ways to define graph spectral domains, which are the analogues to the classical frequency domain, and highlight the importance of incorporating the irregular structures of graph data domains when processing signals on graphs. We then review methods to generalize fundamental operations such as filtering, translation, modulation, dilation, and downsampling to the graph setting, and survey the localized, multiscale transforms that have been proposed to efficiently extract information from high-dimensional data on graphs. We conclude with a brief discussion of open issues and possible extensions.},
	pages = {83--98},
	number = {3},
	journaltitle = {{IEEE} Signal Processing Magazine},
	author = {Shuman, David I. and Narang, Sunil K. and Frossard, Pascal and Ortega, Antonio and Vandergheynst, Pierre},
	urldate = {2019-02-19},
	date = {2013-05},
	eprinttype = {arxiv},
	eprint = {1211.0053},
	keywords = {Computer Science - Discrete Mathematics, Computer Science - Machine Learning, Computer Science - Social and Information Networks}
}

@online{noauthor_princeton_nodate,
	title = {Princeton {ModelNet}},
	url = {http://modelnet.cs.princeton.edu/},
	urldate = {2019-02-13}
}

@software{noauthor_demo_2019,
	title = {Demo code for the paper "Learning {SO}(3) Equivariant Representations with Spherical {CNNs}": daniilidis-group/spherical-cnn},
	rights = {{MIT}},
	url = {https://github.com/daniilidis-group/spherical-cnn},
	shorttitle = {Demo code for the paper "Learning {SO}(3) Equivariant Representations with Spherical {CNNs}"},
	publisher = {Daniilidis Group University of Pennsylvania},
	urldate = {2019-02-13},
	date = {2019-02-02},
	note = {original-date: 2017-11-17T20:10:00Z}
}

@software{kohler_spherical_2019,
	title = {Spherical {CNNs}. Contribute to jonas-koehler/s2cnn development by creating an account on {GitHub}},
	rights = {{MIT}},
	url = {https://github.com/jonas-koehler/s2cnn},
	author = {Köhler, Jonas},
	urldate = {2019-02-13},
	date = {2019-02-07},
	note = {original-date: 2017-09-23T16:49:11Z}
}

@article{cohen_spherical_2018,
	title = {Spherical {CNNs}},
	url = {http://arxiv.org/abs/1801.10130},
	abstract = {Convolutional Neural Networks ({CNNs}) have become the method of choice for learning problems involving 2D planar images. However, a number of problems of recent interest have created a demand for models that can analyze spherical images. Examples include omnidirectional vision for drones, robots, and autonomous cars, molecular regression problems, and global weather and climate modelling. A naive application of convolutional networks to a planar projection of the spherical signal is destined to fail, because the space-varying distortions introduced by such a projection will make translational weight sharing ineffective. In this paper we introduce the building blocks for constructing spherical {CNNs}. We propose a definition for the spherical cross-correlation that is both expressive and rotation-equivariant. The spherical correlation satisfies a generalized Fourier theorem, which allows us to compute it efficiently using a generalized (non-commutative) Fast Fourier Transform ({FFT}) algorithm. We demonstrate the computational efficiency, numerical accuracy, and effectiveness of spherical {CNNs} applied to 3D model recognition and atomization energy regression.},
	journaltitle = {{arXiv}:1801.10130 [cs, stat]},
	author = {Cohen, Taco S. and Geiger, Mario and Koehler, Jonas and Welling, Max},
	urldate = {2019-02-13},
	date = {2018-01-30},
	eprinttype = {arxiv},
	eprint = {1801.10130},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@software{noauthor_spherical_2019,
	title = {A spherical convolutional neural network (for cosmological applications): {SwissDataScienceCenter}/{DeepSphere}},
	rights = {{MIT}},
	url = {https://github.com/SwissDataScienceCenter/DeepSphere},
	shorttitle = {A spherical convolutional neural network (for cosmological applications)},
	publisher = {Swiss Data Science Center},
	urldate = {2019-02-13},
	date = {2019-01-30},
	note = {original-date: 2017-12-18T16:42:24Z}
}

@article{perraudin_deepsphere:_2018,
	title = {{DeepSphere}: Efficient spherical Convolutional Neural Network with {HEALPix} sampling for cosmological applications},
	url = {http://arxiv.org/abs/1810.12186},
	shorttitle = {{DeepSphere}},
	abstract = {Convolutional Neural Networks ({CNNs}) are a cornerstone of the Deep Learning toolbox and have led to many breakthroughs in Artificial Intelligence. These networks have mostly been developed for regular Euclidean domains such as those supporting images, audio, or video. Because of their success, {CNN}-based methods are becoming increasingly popular in Cosmology. Cosmological data often comes as spherical maps, which make the use of the traditional {CNNs} more complicated. The commonly used pixelization scheme for spherical maps is the Hierarchical Equal Area {isoLatitude} Pixelisation ({HEALPix}). We present a spherical {CNN} for analysis of full and partial {HEALPix} maps, which we call {DeepSphere}. The spherical {CNN} is constructed by representing the sphere as a graph. Graphs are versatile data structures that can act as a discrete representation of a continuous manifold. Using the graph-based representation, we define many of the standard {CNN} operations, such as convolution and pooling. With filters restricted to being radial, our convolutions are equivariant to rotation on the sphere, and {DeepSphere} can be made invariant or equivariant to rotation. This way, {DeepSphere} is a special case of a graph {CNN}, tailored to the {HEALPix} sampling of the sphere. This approach is computationally more efficient than using spherical harmonics to perform convolutions. We demonstrate the method on a classification problem of weak lensing mass maps from two cosmological models and compare the performance of the {CNN} with that of two baseline classifiers. The results show that the performance of {DeepSphere} is always superior or equal to both of these baselines. For high noise levels and for data covering only a smaller fraction of the sphere, {DeepSphere} achieves typically 10\% better classification accuracy than those baselines. Finally, we show how learned filters can be visualized to introspect the neural network.},
	journaltitle = {{arXiv}:1810.12186 [astro-ph]},
	author = {Perraudin, Nathanaël and Defferrard, Michaël and Kacprzak, Tomasz and Sgier, Raphael},
	urldate = {2019-02-13},
	date = {2018-10-29},
	eprinttype = {arxiv},
	eprint = {1810.12186},
	keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics, Astrophysics - Instrumentation and Methods for Astrophysics, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning}
}