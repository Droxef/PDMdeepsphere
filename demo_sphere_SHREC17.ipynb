{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSphere using SHREC17 dataset\n",
    "Projection of 3D objects on a unit sphere.\n",
    "This sphere use a HEALpix sampling, and several features are collected:\n",
    "* projection ray length\n",
    "* cos/sin with surface normal\n",
    "* same features using the convex hull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepsphere import models, experiment_helper, plot, utils\n",
    "from deepsphere.data import LabeledDatasetWithNoise, LabeledDataset\n",
    "import hyperparameters\n",
    "\n",
    "from SHREC17.load_shrec import Shrec17DeepSphere as shrecDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2 Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nside = 32\n",
    "experiment_type = 'FCN' # 'CNN'\n",
    "ename = '_'+experiment_type\n",
    "datapath = '../data/shrec17/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_noise = 0\n",
    "noise_dataset = True\n",
    "augmentation = 1    # number of element per file (1 = no augmentation of dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download dataset if True, preprocess data and store it in npy files, and load it in a dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31363it [00:40, 771.86it/s]\n"
     ]
    }
   ],
   "source": [
    "download = False\n",
    "train_dataset = shrecDataset(datapath, 'train', perturbed=noise_dataset, download=download, nside=Nside, augmentation=augmentation, nfile=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements / class\n",
      "  Training set: \n",
      "    Class 0: 1982 elements\n",
      "    Class 1: 160 elements\n",
      "    Class 2: 42 elements\n",
      "    Class 3: 55 elements\n",
      "    Class 4: 423 elements\n",
      "    Class 5: 126 elements\n",
      "    Class 6: 889 elements\n",
      "    Class 7: 38 elements\n",
      "    Class 8: 200 elements\n",
      "    Class 9: 234 elements\n",
      "    Class 10: 82 elements\n",
      "    Class 11: 452 elements\n",
      "    Class 12: 758 elements\n",
      "    Class 13: 53 elements\n",
      "    Class 14: 53 elements\n",
      "    Class 15: 26 elements\n",
      "    Class 16: 1744 elements\n",
      "    Class 17: 257 elements\n",
      "    Class 18: 3235 elements\n",
      "    Class 19: 330 elements\n",
      "    Class 20: 37 elements\n",
      "    Class 21: 45 elements\n",
      "    Class 22: 518 elements\n",
      "    Class 23: 33 elements\n",
      "    Class 24: 368 elements\n",
      "    Class 25: 150 elements\n",
      "    Class 26: 388 elements\n",
      "    Class 27: 77 elements\n",
      "    Class 28: 268 elements\n",
      "    Class 29: 193 elements\n",
      "    Class 30: 1131 elements\n",
      "    Class 31: 227 elements\n",
      "    Class 32: 793 elements\n",
      "    Class 33: 50 elements\n",
      "    Class 34: 34 elements\n",
      "    Class 35: 70 elements\n",
      "    Class 36: 159 elements\n",
      "    Class 37: 104 elements\n",
      "    Class 38: 115 elements\n",
      "    Class 39: 45 elements\n",
      "    Class 40: 130 elements\n",
      "    Class 41: 313 elements\n",
      "    Class 42: 81 elements\n",
      "    Class 43: 29 elements\n",
      "    Class 44: 1171 elements\n",
      "    Class 45: 36 elements\n",
      "    Class 46: 72 elements\n",
      "    Class 47: 1541 elements\n",
      "    Class 48: 102 elements\n",
      "    Class 49: 4147 elements\n",
      "    Class 50: 225 elements\n",
      "    Class 51: 60 elements\n",
      "    Class 52: 200 elements\n",
      "    Class 53: 958 elements\n",
      "    Class 54: 81 elements\n",
      "  Validation set: \n",
      "    Class 0: 492 elements\n",
      "    Class 1: 45 elements\n",
      "    Class 2: 10 elements\n",
      "    Class 3: 10 elements\n",
      "    Class 4: 112 elements\n",
      "    Class 5: 20 elements\n",
      "    Class 6: 235 elements\n",
      "    Class 7: 7 elements\n",
      "    Class 8: 66 elements\n",
      "    Class 9: 52 elements\n",
      "    Class 10: 22 elements\n",
      "    Class 11: 101 elements\n",
      "    Class 12: 177 elements\n",
      "    Class 13: 14 elements\n",
      "    Class 14: 11 elements\n",
      "    Class 15: 8 elements\n",
      "    Class 16: 442 elements\n",
      "    Class 17: 93 elements\n",
      "    Class 18: 815 elements\n",
      "    Class 19: 72 elements\n",
      "    Class 20: 5 elements\n",
      "    Class 21: 11 elements\n",
      "    Class 22: 156 elements\n",
      "    Class 23: 10 elements\n",
      "    Class 24: 91 elements\n",
      "    Class 25: 36 elements\n",
      "    Class 26: 104 elements\n",
      "    Class 27: 25 elements\n",
      "    Class 28: 67 elements\n",
      "    Class 29: 66 elements\n",
      "    Class 30: 282 elements\n",
      "    Class 31: 46 elements\n",
      "    Class 32: 186 elements\n",
      "    Class 33: 7 elements\n",
      "    Class 34: 10 elements\n",
      "    Class 35: 14 elements\n",
      "    Class 36: 47 elements\n",
      "    Class 37: 25 elements\n",
      "    Class 38: 28 elements\n",
      "    Class 39: 13 elements\n",
      "    Class 40: 28 elements\n",
      "    Class 41: 68 elements\n",
      "    Class 42: 20 elements\n",
      "    Class 43: 10 elements\n",
      "    Class 44: 269 elements\n",
      "    Class 45: 12 elements\n",
      "    Class 46: 19 elements\n",
      "    Class 47: 393 elements\n",
      "    Class 48: 31 elements\n",
      "    Class 49: 1004 elements\n",
      "    Class 50: 65 elements\n",
      "    Class 51: 17 elements\n",
      "    Class 52: 38 elements\n",
      "    Class 53: 245 elements\n",
      "    Class 54: 21 elements\n"
     ]
    }
   ],
   "source": [
    "x_train, labels_train, x_val, labels_val = train_dataset.return_data(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of class: 55 \n",
      "number of elements: 31363 \n",
      "first id: 000003\n"
     ]
    }
   ],
   "source": [
    "nclass = train_dataset.nclass\n",
    "num_elem = train_dataset.N\n",
    "ids = train_dataset.retrieve_ids()\n",
    "print('number of class:',nclass,'\\nnumber of elements:',num_elem,'\\nfirst id:',ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Classification using DeepSphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = LabeledDatasetWithNoise(x_train, labels_train, end_level=sigma_noise)\n",
    "validation = LabeledDataset(x_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = 'shrec17_40sim_{}sides_{}noise{}'.format(Nside, sigma_noise, ename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sides: [32, 16, 8, 4, 2, 2]\n",
      "#pixels: [12288, 3072, 768, 192, 48, 48]\n",
      "#samples per batch: 32\n",
      "=> #pixels per batch (input): 393,216\n",
      "=> #pixels for training (input): 24,664,473,600\n",
      "Learning rate will start at 2.0e-04 and finish at 1.1e-31.\n",
      "NN architecture\n",
      "  input: M_0 = 12288\n",
      "  layer 1: cgconv1\n",
      "    representation: M_0 * F_1 / p_1 = 12288 * 96 / 4 = 294912\n",
      "    weights: F_0 * F_1 * K_1 = 1 * 96 * 5 = 480\n",
      "    biases: F_1 = 96\n",
      "    batch normalization\n",
      "  layer 2: cgconv2\n",
      "    representation: M_1 * F_2 / p_2 = 3072 * 192 / 4 = 147456\n",
      "    weights: F_1 * F_2 * K_2 = 96 * 192 * 5 = 92160\n",
      "    biases: F_2 = 192\n",
      "    batch normalization\n",
      "  layer 3: cgconv3\n",
      "    representation: M_2 * F_3 / p_3 = 768 * 384 / 4 = 73728\n",
      "    weights: F_2 * F_3 * K_3 = 192 * 384 * 5 = 368640\n",
      "    biases: F_3 = 384\n",
      "    batch normalization\n",
      "  layer 4: cgconv4\n",
      "    representation: M_3 * F_4 / p_4 = 192 * 384 / 4 = 18432\n",
      "    weights: F_3 * F_4 * K_4 = 384 * 384 * 5 = 737280\n",
      "    biases: F_4 = 384\n",
      "    batch normalization\n",
      "  layer 5: cgconv5\n",
      "    representation: M_4 * F_5 / p_5 = 48 * 55 / 1 = 2640\n",
      "    weights: F_4 * F_5 * K_5 = 384 * 55 * 5 = 105600\n",
      "    batch normalization\n",
      "  Statistical layer: mean\n",
      "    representation: 1 * 55 = 55\n"
     ]
    }
   ],
   "source": [
    "params = hyperparameters.get_params_shrec17(training.N, EXP_NAME, Nside, train_dataset.nclass, architecture=experiment_type)\n",
    "model = models.deepsphere(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('summaries/{}/'.format(EXP_NAME), ignore_errors=True)\n",
    "shutil.rmtree('checkpoints/{}/'.format(EXP_NAME), ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 313 / 62725 (epoch 0.40 / 80):\n",
      "  learning_rate = 1.07e-04, training loss = 1.09e+00\n",
      "{2, 3, 5, 7, 13, 15, 20, 21, 25, 29, 33, 34, 35, 38, 39, 40, 42, 43, 45, 48, 50, 51}\n",
      "  validation accuracy: 72.76 (4564 / 6273), f1 (weighted): 69.25, loss: 1.04e+00\n",
      "  CPU time: 111s, wall time: 183s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusset/miniconda3/envs/PDMsphere/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 626 / 62725 (epoch 0.80 / 80):\n",
      "  learning_rate = 5.72e-05, training loss = 8.00e-01\n",
      "{33, 2, 34, 35, 5, 7, 39, 42, 43, 13, 45, 15, 48, 51, 20, 21, 54, 25}\n",
      "  validation accuracy: 75.23 (4719 / 6273), f1 (weighted): 72.95, loss: 9.13e-01\n",
      "  CPU time: 213s, wall time: 357s\n",
      "step 939 / 62725 (epoch 1.20 / 80):\n",
      "  learning_rate = 3.06e-05, training loss = 8.00e-01\n",
      "{33, 2, 34, 35, 7, 42, 43, 13, 45, 15, 51, 20}\n",
      "  validation accuracy: 77.27 (4847 / 6273), f1 (weighted): 75.21, loss: 8.43e-01\n",
      "  CPU time: 314s, wall time: 530s\n",
      "step 1252 / 62725 (epoch 1.60 / 80):\n",
      "  learning_rate = 1.63e-05, training loss = 1.14e+00\n",
      "{33, 2, 3, 34, 35, 38, 7, 39, 42, 43, 13, 45, 15, 48, 21}\n",
      "  validation accuracy: 77.32 (4850 / 6273), f1 (weighted): 75.22, loss: 8.15e-01\n",
      "  CPU time: 414s, wall time: 704s\n",
      "step 1565 / 62725 (epoch 2.00 / 80):\n",
      "  learning_rate = 8.74e-06, training loss = 7.91e-01\n",
      "{33, 2, 34, 35, 5, 38, 7, 42, 43, 13, 45, 15, 48, 21, 54, 25}\n",
      "  validation accuracy: 78.35 (4915 / 6273), f1 (weighted): 76.30, loss: 7.94e-01\n",
      "  CPU time: 514s, wall time: 876s\n",
      "step 1878 / 62725 (epoch 2.40 / 80):\n",
      "  learning_rate = 4.67e-06, training loss = 8.17e-01\n",
      "{33, 2, 3, 34, 35, 7, 42, 43, 45, 48, 51, 21}\n",
      "  validation accuracy: 78.34 (4914 / 6273), f1 (weighted): 76.30, loss: 7.85e-01\n",
      "  CPU time: 614s, wall time: 1048s\n",
      "step 2191 / 62725 (epoch 2.79 / 80):\n",
      "  learning_rate = 2.50e-06, training loss = 9.35e-01\n",
      "{33, 2, 3, 34, 35, 7, 42, 43, 13, 45, 48, 21}\n",
      "  validation accuracy: 78.75 (4940 / 6273), f1 (weighted): 76.78, loss: 7.78e-01\n",
      "  CPU time: 713s, wall time: 1221s\n",
      "step 2504 / 62725 (epoch 3.19 / 80):\n",
      "  learning_rate = 1.33e-06, training loss = 6.44e-01\n",
      "{33, 2, 34, 35, 7, 42, 43, 13, 45, 48, 21}\n",
      "  validation accuracy: 78.85 (4946 / 6273), f1 (weighted): 77.01, loss: 7.86e-01\n",
      "  CPU time: 813s, wall time: 1393s\n",
      "step 2817 / 62725 (epoch 3.59 / 80):\n",
      "  learning_rate = 7.14e-07, training loss = 1.07e+00\n",
      "{33, 2, 3, 34, 35, 7, 42, 43, 13, 45, 15, 48, 21}\n",
      "  validation accuracy: 78.81 (4944 / 6273), f1 (weighted): 76.79, loss: 7.74e-01\n",
      "  CPU time: 913s, wall time: 1565s\n",
      "step 3130 / 62725 (epoch 3.99 / 80):\n",
      "  learning_rate = 3.81e-07, training loss = 6.85e-01\n",
      "{33, 2, 3, 34, 35, 7, 42, 43, 13, 45, 48, 21}\n",
      "  validation accuracy: 78.77 (4941 / 6273), f1 (weighted): 76.83, loss: 7.75e-01\n",
      "  CPU time: 1015s, wall time: 1745s\n",
      "step 3443 / 62725 (epoch 4.39 / 80):\n",
      "  learning_rate = 2.04e-07, training loss = 8.35e-01\n",
      "{33, 2, 3, 34, 35, 7, 42, 43, 45, 48, 21}\n",
      "  validation accuracy: 78.62 (4932 / 6273), f1 (weighted): 76.78, loss: 7.81e-01\n",
      "  CPU time: 1118s, wall time: 1929s\n",
      "step 3756 / 62725 (epoch 4.79 / 80):\n",
      "  learning_rate = 1.09e-07, training loss = 1.03e+00\n",
      "{33, 2, 3, 34, 35, 7, 42, 43, 45, 48, 21}\n",
      "  validation accuracy: 78.80 (4943 / 6273), f1 (weighted): 76.91, loss: 7.75e-01\n",
      "  CPU time: 1221s, wall time: 2115s\n",
      "step 4069 / 62725 (epoch 5.19 / 80):\n",
      "  learning_rate = 5.83e-08, training loss = 7.37e-01\n",
      "{33, 2, 3, 34, 35, 7, 42, 43, 45, 15, 48, 21}\n",
      "  validation accuracy: 78.78 (4942 / 6273), f1 (weighted): 76.96, loss: 7.81e-01\n",
      "  CPU time: 1323s, wall time: 2299s\n",
      "step 4382 / 62725 (epoch 5.59 / 80):\n",
      "  learning_rate = 3.11e-08, training loss = 8.94e-01\n",
      "{33, 2, 3, 34, 35, 7, 42, 43, 45, 48, 21}\n",
      "  validation accuracy: 78.67 (4935 / 6273), f1 (weighted): 76.71, loss: 7.77e-01\n",
      "  CPU time: 1425s, wall time: 2482s\n",
      "step 4695 / 62725 (epoch 5.99 / 80):\n",
      "  learning_rate = 1.67e-08, training loss = 4.95e-01\n",
      "{33, 2, 34, 35, 7, 42, 43, 13, 45, 48, 21}\n",
      "  validation accuracy: 78.51 (4925 / 6273), f1 (weighted): 76.49, loss: 7.78e-01\n",
      "  CPU time: 1525s, wall time: 2665s\n",
      "step 5008 / 62725 (epoch 6.39 / 80):\n",
      "  learning_rate = 8.90e-09, training loss = 6.33e-01\n",
      "{33, 2, 34, 35, 7, 42, 43, 13, 45, 15, 48, 21}\n",
      "  validation accuracy: 78.77 (4941 / 6273), f1 (weighted): 76.88, loss: 7.77e-01\n",
      "  CPU time: 1626s, wall time: 2848s\n",
      "step 5321 / 62725 (epoch 6.79 / 80):\n",
      "  learning_rate = 4.76e-09, training loss = 1.09e+00\n",
      "{33, 2, 34, 35, 38, 7, 42, 43, 45, 15, 48, 21}\n",
      "  validation accuracy: 78.70 (4937 / 6273), f1 (weighted): 76.73, loss: 7.74e-01\n",
      "  CPU time: 1726s, wall time: 3030s\n",
      "step 5634 / 62725 (epoch 7.19 / 80):\n",
      "  learning_rate = 2.54e-09, training loss = 8.31e-01\n",
      "{33, 2, 34, 35, 7, 42, 43, 13, 45, 15, 48, 21}\n",
      "  validation accuracy: 78.81 (4944 / 6273), f1 (weighted): 76.87, loss: 7.72e-01\n",
      "  CPU time: 1826s, wall time: 3212s\n",
      "step 5947 / 62725 (epoch 7.58 / 80):\n",
      "  learning_rate = 1.36e-09, training loss = 6.77e-01\n",
      "{33, 2, 34, 35, 7, 42, 43, 13, 45, 48, 21}\n",
      "  validation accuracy: 78.70 (4937 / 6273), f1 (weighted): 76.72, loss: 7.75e-01\n",
      "  CPU time: 1928s, wall time: 3395s\n",
      "step 6260 / 62725 (epoch 7.98 / 80):\n",
      "  learning_rate = 7.27e-10, training loss = 9.58e-01\n",
      "{33, 2, 34, 35, 7, 42, 43, 45, 48, 21}\n",
      "  validation accuracy: 78.78 (4942 / 6273), f1 (weighted): 76.79, loss: 7.76e-01\n",
      "  CPU time: 2029s, wall time: 3578s\n",
      "step 6573 / 62725 (epoch 8.38 / 80):\n",
      "  learning_rate = 3.89e-10, training loss = 4.56e-01\n",
      "{33, 2, 3, 34, 35, 7, 42, 43, 45, 15, 48, 21}\n",
      "  validation accuracy: 78.57 (4929 / 6273), f1 (weighted): 76.64, loss: 7.75e-01\n",
      "  CPU time: 2129s, wall time: 3761s\n",
      "step 6886 / 62725 (epoch 8.78 / 80):\n",
      "  learning_rate = 2.08e-10, training loss = 9.86e-01\n"
     ]
    }
   ],
   "source": [
    "accuracy_validation, loss_validation, loss_training, t_step = model.fit(training, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_loss(loss_training, loss_validation, t_step, params['eval_frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, loss = model.predict(x_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions-labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, loss = model.predict(x_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions-labels_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_40sim_32sides_0noise_FCN\n",
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_40sim_32sides_0noise_FCN/model-1750\n",
      "{2, 5, 37, 7, 38, 42, 43, 46, 15, 19, 51, 21, 23, 27, 28, 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusset/miniconda3/envs/PDMsphere/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gusset/miniconda3/envs/PDMsphere/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('accuracy: 70.00 (210 / 300), f1 (weighted): 66.63, loss: 1.48e+00\\nCPU time: 1s, wall time: 1s',\n",
       " 70.0,\n",
       " 66.63168219425292,\n",
       " 1.4809802881876628)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
