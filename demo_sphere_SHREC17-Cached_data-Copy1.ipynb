{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSphere using SHREC17 dataset\n",
    "### Benchmark with Cohen method S2CNN[[1]](http://arxiv.org/abs/1801.10130) and Esteves method[[2]](http://arxiv.org/abs/1711.06721)\n",
    "Multi-class classification of 3D objects, using the interesting property of rotation equivariance.\n",
    "\n",
    "The 3D objects are projected on a unit sphere.\n",
    "Cohen and Esteves use equiangular sampling, while our method use a HEAlpix sampling\n",
    "\n",
    "Several features are collected:\n",
    "* projection ray length (from sphere border to intersection [0, 2])\n",
    "* cos/sin with surface normal\n",
    "* same features using the convex hull of the 3D object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # change to chosen GPU to use, nothing if work on CPU\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import healpy as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepsphere import models, experiment_helper, plot, utils\n",
    "from deepsphere.data import LabeledDatasetWithNoise, LabeledDataset\n",
    "import hyperparameters\n",
    "\n",
    "from SHREC17.load_shrec import fix_dataset, Shrec17Dataset, Shrec17DatasetCache, Shrec17DatasetTF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nside = 32\n",
    "experiment_type = 'CNN' # 'FCN'\n",
    "ename = '_'+experiment_type\n",
    "datapath = '../data/shrec17/' # localisation of the .obj files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dataset = True    # use perturbed dataset (Cohen and Esteves do the same)\n",
    "augmentation = 1        # number of element per file (1 = no augmentation of dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if datasets are already downloaded but not preprocessed\n",
    "fix = False\n",
    "download = False\n",
    "if fix:\n",
    "    fix_dataset(datapath+'val_perturbed')\n",
    "    fix_dataset(datapath+'test_perturbed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download dataset if True, preprocess data and store it in npy files, and load it in a dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = Shrec17DatasetCache(datapath, 'train', perturbed=noise_dataset, download=download, nside=Nside, augmentation=augmentation, nfile=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better to keep validation and testing set in RAM, but not always possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Shrec17DatasetCache(datapath, 'val', perturbed=noise_dataset, download=download, nside=Nside, augmentation=1, nfile=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try do make a tensorflow dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_TFDataset = Shrec17DatasetTF(datapath, 'train', perturbed=noise_dataset, download=download, nside=Nside, augmentation=augmentation, nfile=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = train_TFDataset.get_tf_dataset(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.56311297416687 s\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "# import tensorflow as tf\n",
    "\n",
    "# #dataset = tf_dataset_file(datapath, dataset, file_pattern, 32, Nside, augmentation)\n",
    "# t_start = time.time()\n",
    "# data_next = dataset.make_one_shot_iterator().get_next()\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# steps = train_TFDataset.N // 32 + 1\n",
    "# with tf.Session(config=config) as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     try:\n",
    "#         for i in range(steps):\n",
    "#             out = sess.run(data_next)\n",
    "#     except tf.errors.OutOfRangeError:\n",
    "#         print(\"Done\") # Never reach this as will iterate on infinite sets\n",
    "# t_end = time.time()\n",
    "# print(str(t_end-t_start)+\" s\")\n",
    "\n",
    "# # t_start = time.time()\n",
    "# # data_iter = train_dataset.iter(32)\n",
    "# # steps = int(train_dataset.N / 32)\n",
    "# # for i in range(steps):\n",
    "# #     next(data_iter)\n",
    "# #     #feed_dict = {self.ph_data: batch_data, self.ph_labels: batch_labels, self.ph_training: True}\n",
    "# # t_end = time.time()\n",
    "# # print(str(t_end-t_start)+\" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the training dataset and print the classes distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of class: 55 \n",
      "number of elements: 31364\n"
     ]
    }
   ],
   "source": [
    "nclass = train_TFDataset.nclass\n",
    "num_elem = train_TFDataset.N\n",
    "#ids_train = train_dataset.ids\n",
    "print('number of class:',nclass,'\\nnumber of elements:',num_elem)#,'\\nfirst id:',ids_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x_val, labels_val, ids_val = val_dataset.return_data(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeat = 6#x_val.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Classification using DeepSphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of the Dataset object used for other DeepSphere experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #training = LabeledDatasetWithNoise(x_train, labels_train, end_level=sigma_noise)\n",
    "# #training = LabeledDataset(x_train, labels_train)\n",
    "# validation = LabeledDataset(x_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = 'shrec17_newGraph_best_4K_cache_{}aug_{}sides{}'.format(augmentation, Nside, ename)\n",
    "#EXP_NAME = 'shrec17_Cohen_simple_SGD_max_nsides_300epoch_{}sides{}'.format(Nside, ename)\n",
    "#EXP_NAME = \"shrec17_best_5K_cache_3aug_32sides_CNN\"\n",
    "#EXP_NAME = 'essai_TFDataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model with hyperparameters chosen.\n",
    "For each experiment, a new EXP_NAME is chosen, and new hyperparameters are store.\n",
    "All informations are present 'DeepSphere/Shrec17/experiments.md'\n",
    "The fastest way to reproduce an experiment is to revert to the commit of the experiment to load the correct files and notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a layer in the fully connected can be beneficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sides: [32, 16, 8, 4, 2, 1, 1]\n",
      "#pixels: [12288, 3072, 768, 192, 48, 12, 12]\n",
      "#samples per batch: 32\n",
      "=> #pixels per batch (input): 393,216\n",
      "=> #pixels for training (input): 19,270,041,600\n",
      "Learning rate will start at 1.0e-02 and finish at 1.0e-02.\n",
      "NN architecture\n",
      "  input: M_0 = 12288\n",
      "  layer 1: cgconv1\n",
      "    representation: M_0 * F_1 / p_1 = 12288 * 16 / 4 = 49152\n",
      "    weights: F_0 * F_1 * K_1 = 6 * 16 * 4 = 384\n",
      "    biases: F_1 = 16\n",
      "    batch normalization\n",
      "  layer 2: cgconv2\n",
      "    representation: M_1 * F_2 / p_2 = 3072 * 32 / 4 = 24576\n",
      "    weights: F_1 * F_2 * K_2 = 16 * 32 * 4 = 2048\n",
      "    biases: F_2 = 32\n",
      "    batch normalization\n",
      "  layer 3: cgconv3\n",
      "    representation: M_2 * F_3 / p_3 = 768 * 64 / 4 = 12288\n",
      "    weights: F_2 * F_3 * K_3 = 32 * 64 * 4 = 8192\n",
      "    biases: F_3 = 64\n",
      "    batch normalization\n",
      "  layer 4: cgconv4\n",
      "    representation: M_3 * F_4 / p_4 = 192 * 128 / 4 = 6144\n",
      "    weights: F_3 * F_4 * K_4 = 64 * 128 * 4 = 32768\n",
      "    biases: F_4 = 128\n",
      "    batch normalization\n",
      "  layer 5: cgconv5\n",
      "    representation: M_4 * F_5 / p_5 = 48 * 256 / 4 = 3072\n",
      "    weights: F_4 * F_5 * K_5 = 128 * 256 * 4 = 131072\n",
      "    biases: F_5 = 256\n",
      "    batch normalization\n",
      "  Statistical layer: mean\n",
      "    representation: 1 * 256 = 256\n",
      "  layer 6: logits (softmax)\n",
      "    representation: M_6 = 55\n",
      "    weights: M_5 * M_6 = 256 * 55 = 14080\n"
     ]
    }
   ],
   "source": [
    "params = hyperparameters.get_params_shrec17_optim(num_elem, EXP_NAME, Nside, nclass, nfeat_in=nfeat, architecture=experiment_type)\n",
    "params[\"tf_dataset\"] = train_TFDataset.get_tf_dataset(params[\"batch_size\"])\n",
    "params[\"std\"] = 0.001\n",
    "model = models.deepsphere(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXP_NAME = \"shrec17_best_4K_cache_1aug_128sides_CNN\"\n",
    "shutil.rmtree('summaries/{}/'.format(EXP_NAME), ignore_errors=True)\n",
    "shutil.rmtree('checkpoints/{}/'.format(EXP_NAME), ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a correct learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN architecture\n",
      "  input: M_0 = 196608\n",
      "  layer 1: cgconv1\n",
      "    representation: M_0 * F_1 / p_1 = 196608 * 16 / 4 = 786432\n",
      "    weights: F_0 * F_1 * K_1 = 6 * 16 * 5 = 480\n",
      "    biases: F_1 = 16\n",
      "    batch normalization\n",
      "  layer 2: cgconv2\n",
      "    representation: M_1 * F_2 / p_2 = 49152 * 32 / 4 = 393216\n",
      "    weights: F_1 * F_2 * K_2 = 16 * 32 * 5 = 2560\n",
      "    biases: F_2 = 32\n",
      "    batch normalization\n",
      "  layer 3: cgconv3\n",
      "    representation: M_2 * F_3 / p_3 = 12288 * 64 / 4 = 196608\n",
      "    weights: F_2 * F_3 * K_3 = 32 * 64 * 5 = 10240\n",
      "    biases: F_3 = 64\n",
      "    batch normalization\n",
      "  layer 4: cgconv4\n",
      "    representation: M_3 * F_4 / p_4 = 3072 * 128 / 4 = 98304\n",
      "    weights: F_3 * F_4 * K_4 = 64 * 128 * 5 = 40960\n",
      "    biases: F_4 = 128\n",
      "    batch normalization\n",
      "  layer 5: cgconv5\n",
      "    representation: M_4 * F_5 / p_5 = 768 * 256 / 4 = 49152\n",
      "    weights: F_4 * F_5 * K_5 = 128 * 256 * 5 = 163840\n",
      "    biases: F_5 = 256\n",
      "    batch normalization\n",
      "  Statistical layer: mean\n",
      "    representation: 1 * 256 = 256\n",
      "  layer 6: logits (softmax)\n",
      "    representation: M_6 = 55\n",
      "    weights: M_5 * M_6 = 256 * 55 = 14080\n",
      "step 490 / 19602 (epoch 0.50 / 20):\n",
      "  learning_rate = 1.78e-06, training loss = 4.24e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusset/miniconda3/envs/PDMsphere/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  validation accuracy: 0.76 (39 / 5133), f1 (weighted): 0.80, loss: 4.29e+00\n",
      "  CPU time: 1477s, wall time: 797s, perf_time_load: 1.16s, perf_time: 1.16s\n",
      "step 980 / 19602 (epoch 1.00 / 20):\n",
      "  learning_rate = 3.16e-06, training loss = 4.13e+00\n",
      "  validation accuracy: 3.78 (194 / 5133), f1 (weighted): 2.88, loss: 4.19e+00\n",
      "  CPU time: 2964s, wall time: 1587s, perf_time_load: 1.13s, perf_time: 1.13s\n",
      "step 1470 / 19602 (epoch 1.50 / 20):\n",
      "  learning_rate = 5.62e-06, training loss = 4.08e+00\n",
      "  validation accuracy: 10.29 (528 / 5133), f1 (weighted): 4.54, loss: 4.00e+00\n",
      "  CPU time: 4446s, wall time: 2374s, perf_time_load: 1.16s, perf_time: 1.16s\n",
      "step 1960 / 19602 (epoch 2.00 / 20):\n",
      "  learning_rate = 9.99e-06, training loss = 3.78e+00\n",
      "  validation accuracy: 26.57 (1364 / 5133), f1 (weighted): 15.49, loss: 3.70e+00\n",
      "  CPU time: 5924s, wall time: 3166s, perf_time_load: 1.15s, perf_time: 1.15s\n",
      "step 2450 / 19602 (epoch 2.50 / 20):\n",
      "  learning_rate = 1.78e-05, training loss = 3.08e+00\n",
      "  validation accuracy: 35.52 (1823 / 5133), f1 (weighted): 23.55, loss: 3.37e+00\n",
      "  CPU time: 7409s, wall time: 3951s, perf_time_load: 1.15s, perf_time: 1.15s\n",
      "step 2940 / 19602 (epoch 3.00 / 20):\n",
      "  learning_rate = 3.16e-05, training loss = 2.92e+00\n",
      "  validation accuracy: 41.22 (2116 / 5133), f1 (weighted): 27.08, loss: 3.05e+00\n",
      "  CPU time: 8890s, wall time: 4737s, perf_time_load: 1.17s, perf_time: 1.17s\n",
      "step 3430 / 19602 (epoch 3.50 / 20):\n",
      "  learning_rate = 5.62e-05, training loss = 2.43e+00\n",
      "  validation accuracy: 43.13 (2214 / 5133), f1 (weighted): 29.75, loss: 2.78e+00\n",
      "  CPU time: 10385s, wall time: 5525s, perf_time_load: 1.14s, perf_time: 1.14s\n",
      "step 3920 / 19602 (epoch 4.00 / 20):\n",
      "  learning_rate = 9.99e-05, training loss = 2.51e+00\n",
      "  validation accuracy: 46.13 (2368 / 5133), f1 (weighted): 34.35, loss: 2.55e+00\n",
      "  CPU time: 11895s, wall time: 6315s, perf_time_load: 1.14s, perf_time: 1.14s\n",
      "step 4410 / 19602 (epoch 4.50 / 20):\n",
      "  learning_rate = 1.78e-04, training loss = 2.13e+00\n",
      "  validation accuracy: 48.61 (2495 / 5133), f1 (weighted): 38.04, loss: 2.32e+00\n",
      "  CPU time: 13355s, wall time: 7094s, perf_time_load: 1.17s, perf_time: 1.17s\n",
      "step 4900 / 19602 (epoch 5.00 / 20):\n",
      "  learning_rate = 3.16e-04, training loss = 2.27e+00\n",
      "  validation accuracy: 52.41 (2690 / 5133), f1 (weighted): 43.24, loss: 2.12e+00\n",
      "  CPU time: 14828s, wall time: 7876s, perf_time_load: 1.17s, perf_time: 1.17s\n",
      "step 5390 / 19602 (epoch 5.50 / 20):\n",
      "  learning_rate = 5.61e-04, training loss = 1.93e+00\n",
      "  validation accuracy: 56.91 (2921 / 5133), f1 (weighted): 49.32, loss: 1.93e+00\n",
      "  CPU time: 16301s, wall time: 8660s, perf_time_load: 1.17s, perf_time: 1.17s\n",
      "step 5880 / 19602 (epoch 6.00 / 20):\n",
      "  learning_rate = 9.98e-04, training loss = 1.77e+00\n",
      "  validation accuracy: 61.33 (3148 / 5133), f1 (weighted): 55.17, loss: 1.75e+00\n",
      "  CPU time: 17783s, wall time: 9427s, perf_time_load: 1.11s, perf_time: 1.11s\n",
      "step 6370 / 19602 (epoch 6.50 / 20):\n",
      "  learning_rate = 1.77e-03, training loss = 1.69e+00\n",
      "  validation accuracy: 64.50 (3311 / 5133), f1 (weighted): 59.56, loss: 1.60e+00\n",
      "  CPU time: 19248s, wall time: 10200s, perf_time_load: 1.13s, perf_time: 1.13s\n"
     ]
    }
   ],
   "source": [
    "backup = params.copy()\n",
    "\n",
    "params, learning_rate = utils.test_learning_rates(params, train_TFDataset.N, 1e-6, 1e-1, num_epochs=20)\n",
    "\n",
    "shutil.rmtree('summaries/{}/'.format(params['dir_name']), ignore_errors=True)\n",
    "shutil.rmtree('checkpoints/{}/'.format(params['dir_name']), ignore_errors=True)\n",
    "\n",
    "model = models.deepsphere(**params)\n",
    "_, loss_validation, _, _ = model.fit(train_TFDataset, val_dataset, use_tf_dataset=True, cache=True)\n",
    "\n",
    "params.update(backup)\n",
    "\n",
    "plt.semilogx(learning_rate, loss_validation, '.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('summaries/lr_finder/', ignore_errors=True)\n",
    "shutil.rmtree('checkpoints/lr_finder/', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.9 seems to be a good learning rate for SGD with current parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1/weights:0\n",
      "conv1/bias:0\n",
      "conv2/weights:0\n",
      "conv2/bias:0\n",
      "conv3/weights:0\n",
      "conv3/bias:0\n",
      "conv4/weights:0\n",
      "conv4/bias:0\n",
      "conv5/weights:0\n",
      "conv5/bias:0\n",
      "logits/weights:0\n",
      "the number of parameters in the model is: 189,040\n"
     ]
    }
   ],
   "source": [
    "print(\"the number of parameters in the model is: {:,}\".format(model.get_nbr_var()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 245 / 49006 (epoch 0.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.18e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusset/miniconda3/envs/PDMsphere/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  validation accuracy: 65.54 (3364 / 5133), f1 (weighted): 61.03, loss: 1.35e+00\n",
      "  CPU time: 89s, wall time: 60s, perf_time_load: 0.09s, perf_time: 0.09s\n",
      "step 490 / 49006 (epoch 0.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.36e+00\n",
      "  validation accuracy: 65.30 (3352 / 5133), f1 (weighted): 62.12, loss: 1.27e+00\n",
      "  CPU time: 159s, wall time: 106s, perf_time_load: 0.07s, perf_time: 0.07s\n",
      "step 735 / 49006 (epoch 0.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 9.89e-01\n",
      "  validation accuracy: 71.07 (3648 / 5133), f1 (weighted): 68.48, loss: 1.07e+00\n",
      "  CPU time: 243s, wall time: 159s, perf_time_load: 0.13s, perf_time: 0.13s\n",
      "step 980 / 49006 (epoch 1.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.18e+00\n",
      "  validation accuracy: 73.91 (3794 / 5133), f1 (weighted): 71.63, loss: 9.72e-01\n",
      "  CPU time: 320s, wall time: 209s, perf_time_load: 0.12s, perf_time: 0.12s\n",
      "step 1225 / 49006 (epoch 1.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.14e-01\n",
      "  validation accuracy: 72.34 (3713 / 5133), f1 (weighted): 70.51, loss: 1.02e+00\n",
      "  CPU time: 388s, wall time: 253s, perf_time_load: 0.09s, perf_time: 0.09s\n",
      "step 1470 / 49006 (epoch 1.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.44e-01\n",
      "  validation accuracy: 75.06 (3853 / 5133), f1 (weighted): 73.66, loss: 9.38e-01\n",
      "  CPU time: 469s, wall time: 307s, perf_time_load: 0.16s, perf_time: 0.16s\n",
      "step 1715 / 49006 (epoch 1.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 5.65e-01\n",
      "  validation accuracy: 76.84 (3944 / 5133), f1 (weighted): 74.80, loss: 8.70e-01\n",
      "  CPU time: 556s, wall time: 367s, perf_time_load: 0.11s, perf_time: 0.11s\n",
      "step 1960 / 49006 (epoch 2.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.34e-01\n",
      "  validation accuracy: 76.86 (3945 / 5133), f1 (weighted): 74.42, loss: 8.70e-01\n",
      "  CPU time: 632s, wall time: 416s, perf_time_load: 0.10s, perf_time: 0.10s\n",
      "step 2205 / 49006 (epoch 2.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 8.40e-01\n",
      "  validation accuracy: 77.28 (3967 / 5133), f1 (weighted): 75.64, loss: 8.44e-01\n",
      "  CPU time: 701s, wall time: 455s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 2450 / 49006 (epoch 2.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 5.96e-01\n",
      "  validation accuracy: 77.23 (3964 / 5133), f1 (weighted): 75.71, loss: 8.37e-01\n",
      "  CPU time: 748s, wall time: 479s, perf_time_load: 0.07s, perf_time: 0.07s\n",
      "step 2695 / 49006 (epoch 2.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 7.08e-01\n",
      "  validation accuracy: 78.71 (4040 / 5133), f1 (weighted): 77.22, loss: 8.14e-01\n",
      "  CPU time: 798s, wall time: 503s, perf_time_load: 0.06s, perf_time: 0.06s\n",
      "step 2940 / 49006 (epoch 3.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 8.56e-01\n",
      "  validation accuracy: 76.80 (3942 / 5133), f1 (weighted): 75.39, loss: 8.55e-01\n",
      "  CPU time: 843s, wall time: 526s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 3185 / 49006 (epoch 3.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.66e-01\n",
      "  validation accuracy: 77.26 (3966 / 5133), f1 (weighted): 76.24, loss: 8.58e-01\n",
      "  CPU time: 891s, wall time: 549s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 3430 / 49006 (epoch 3.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.66e-01\n",
      "  validation accuracy: 78.32 (4020 / 5133), f1 (weighted): 77.08, loss: 8.02e-01\n",
      "  CPU time: 940s, wall time: 573s, perf_time_load: 0.07s, perf_time: 0.07s\n",
      "step 3675 / 49006 (epoch 3.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.58e-01\n",
      "  validation accuracy: 77.17 (3961 / 5133), f1 (weighted): 75.66, loss: 8.45e-01\n",
      "  CPU time: 985s, wall time: 596s, perf_time_load: 0.07s, perf_time: 0.07s\n",
      "step 3920 / 49006 (epoch 4.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 5.17e-01\n",
      "  validation accuracy: 79.64 (4088 / 5133), f1 (weighted): 78.39, loss: 7.67e-01\n",
      "  CPU time: 1035s, wall time: 620s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 4165 / 49006 (epoch 4.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.95e-01\n",
      "  validation accuracy: 78.43 (4026 / 5133), f1 (weighted): 77.19, loss: 8.06e-01\n",
      "  CPU time: 1080s, wall time: 643s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 4410 / 49006 (epoch 4.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.08e-01\n",
      "  validation accuracy: 79.58 (4085 / 5133), f1 (weighted): 78.51, loss: 7.68e-01\n",
      "  CPU time: 1126s, wall time: 666s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 4655 / 49006 (epoch 4.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.48e-01\n",
      "  validation accuracy: 80.19 (4116 / 5133), f1 (weighted): 78.57, loss: 7.54e-01\n",
      "  CPU time: 1173s, wall time: 689s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 4900 / 49006 (epoch 5.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.56e-01\n",
      "  validation accuracy: 79.66 (4089 / 5133), f1 (weighted): 79.11, loss: 7.53e-01\n",
      "  CPU time: 1219s, wall time: 712s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 5145 / 49006 (epoch 5.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.46e-01\n",
      "  validation accuracy: 79.99 (4106 / 5133), f1 (weighted): 78.87, loss: 7.67e-01\n",
      "  CPU time: 1266s, wall time: 735s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 5390 / 49006 (epoch 5.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.76e-01\n",
      "  validation accuracy: 79.89 (4101 / 5133), f1 (weighted): 78.41, loss: 7.46e-01\n",
      "  CPU time: 1313s, wall time: 758s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 5635 / 49006 (epoch 5.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.79e-01\n",
      "  validation accuracy: 79.95 (4104 / 5133), f1 (weighted): 78.88, loss: 7.41e-01\n",
      "  CPU time: 1362s, wall time: 782s, perf_time_load: 0.06s, perf_time: 0.06s\n",
      "step 5880 / 49006 (epoch 6.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.96e-01\n",
      "  validation accuracy: 80.69 (4142 / 5133), f1 (weighted): 79.31, loss: 7.38e-01\n",
      "  CPU time: 1408s, wall time: 804s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 6125 / 49006 (epoch 6.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.44e-01\n",
      "  validation accuracy: 79.91 (4102 / 5133), f1 (weighted): 78.99, loss: 7.57e-01\n",
      "  CPU time: 1452s, wall time: 827s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 6370 / 49006 (epoch 6.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.98e-01\n",
      "  validation accuracy: 79.76 (4094 / 5133), f1 (weighted): 78.71, loss: 7.40e-01\n",
      "  CPU time: 1500s, wall time: 850s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 6615 / 49006 (epoch 6.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.78e-01\n",
      "  validation accuracy: 79.62 (4087 / 5133), f1 (weighted): 78.76, loss: 7.75e-01\n",
      "  CPU time: 1544s, wall time: 872s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 6860 / 49006 (epoch 7.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.42e-01\n",
      "  validation accuracy: 80.85 (4150 / 5133), f1 (weighted): 79.99, loss: 7.11e-01\n",
      "  CPU time: 1589s, wall time: 895s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 7105 / 49006 (epoch 7.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.45e-01\n",
      "  validation accuracy: 80.25 (4119 / 5133), f1 (weighted): 79.68, loss: 7.17e-01\n",
      "  CPU time: 1634s, wall time: 919s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 7350 / 49006 (epoch 7.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.63e-01\n",
      "  validation accuracy: 81.94 (4206 / 5133), f1 (weighted): 81.04, loss: 6.95e-01\n",
      "  CPU time: 1682s, wall time: 943s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 7595 / 49006 (epoch 7.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.67e-01\n",
      "  validation accuracy: 80.75 (4145 / 5133), f1 (weighted): 79.74, loss: 7.45e-01\n",
      "  CPU time: 1732s, wall time: 967s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 7840 / 49006 (epoch 8.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.66e-01\n",
      "  validation accuracy: 80.13 (4113 / 5133), f1 (weighted): 79.66, loss: 7.60e-01\n",
      "  CPU time: 1783s, wall time: 992s, perf_time_load: 0.06s, perf_time: 0.06s\n",
      "step 8085 / 49006 (epoch 8.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.94e-01\n",
      "  validation accuracy: 81.92 (4205 / 5133), f1 (weighted): 80.99, loss: 7.09e-01\n",
      "  CPU time: 1833s, wall time: 1015s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 8330 / 49006 (epoch 8.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.30e-01\n",
      "  validation accuracy: 81.20 (4168 / 5133), f1 (weighted): 80.47, loss: 7.14e-01\n",
      "  CPU time: 1879s, wall time: 1038s, perf_time_load: 0.05s, perf_time: 0.05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8575 / 49006 (epoch 8.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.75e-01\n",
      "  validation accuracy: 79.72 (4092 / 5133), f1 (weighted): 79.32, loss: 7.48e-01\n",
      "  CPU time: 1924s, wall time: 1061s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 8820 / 49006 (epoch 9.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.55e-01\n",
      "  validation accuracy: 81.02 (4159 / 5133), f1 (weighted): 80.43, loss: 7.11e-01\n",
      "  CPU time: 1969s, wall time: 1083s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 9065 / 49006 (epoch 9.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.88e-01\n",
      "  validation accuracy: 80.91 (4153 / 5133), f1 (weighted): 80.13, loss: 7.13e-01\n",
      "  CPU time: 2016s, wall time: 1107s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 9310 / 49006 (epoch 9.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.28e-01\n",
      "  validation accuracy: 81.06 (4161 / 5133), f1 (weighted): 80.51, loss: 7.10e-01\n",
      "  CPU time: 2060s, wall time: 1129s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 9555 / 49006 (epoch 9.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 9.91e-02\n",
      "  validation accuracy: 80.26 (4120 / 5133), f1 (weighted): 79.58, loss: 7.36e-01\n",
      "  CPU time: 2106s, wall time: 1152s, perf_time_load: 0.06s, perf_time: 0.06s\n",
      "step 9800 / 49006 (epoch 10.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.45e-01\n",
      "  validation accuracy: 80.42 (4128 / 5133), f1 (weighted): 79.39, loss: 7.31e-01\n",
      "  CPU time: 2152s, wall time: 1174s, perf_time_load: 0.06s, perf_time: 0.06s\n",
      "step 10045 / 49006 (epoch 10.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.05e-01\n",
      "  validation accuracy: 80.11 (4112 / 5133), f1 (weighted): 79.14, loss: 7.72e-01\n",
      "  CPU time: 2197s, wall time: 1197s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 10290 / 49006 (epoch 10.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.73e-01\n",
      "  validation accuracy: 80.32 (4123 / 5133), f1 (weighted): 79.75, loss: 7.29e-01\n",
      "  CPU time: 2241s, wall time: 1219s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 10535 / 49006 (epoch 10.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 9.59e-02\n",
      "  validation accuracy: 81.67 (4192 / 5133), f1 (weighted): 81.02, loss: 7.07e-01\n",
      "  CPU time: 2286s, wall time: 1243s, perf_time_load: 0.06s, perf_time: 0.06s\n",
      "step 10780 / 49006 (epoch 11.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 8.63e-02\n",
      "  validation accuracy: 81.20 (4168 / 5133), f1 (weighted): 80.57, loss: 7.10e-01\n",
      "  CPU time: 2333s, wall time: 1265s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 11025 / 49006 (epoch 11.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.28e-01\n",
      "  validation accuracy: 80.93 (4154 / 5133), f1 (weighted): 80.39, loss: 7.23e-01\n",
      "  CPU time: 2378s, wall time: 1288s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 11270 / 49006 (epoch 11.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.76e-01\n",
      "  validation accuracy: 81.18 (4167 / 5133), f1 (weighted): 80.51, loss: 7.25e-01\n",
      "  CPU time: 2425s, wall time: 1312s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 11515 / 49006 (epoch 11.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.12e-01\n",
      "  validation accuracy: 81.55 (4186 / 5133), f1 (weighted): 80.94, loss: 7.22e-01\n",
      "  CPU time: 2471s, wall time: 1335s, perf_time_load: 0.06s, perf_time: 0.06s\n",
      "step 11760 / 49006 (epoch 12.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.58e-01\n",
      "  validation accuracy: 81.22 (4169 / 5133), f1 (weighted): 80.66, loss: 7.13e-01\n",
      "  CPU time: 2516s, wall time: 1357s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 12005 / 49006 (epoch 12.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 8.72e-02\n",
      "  validation accuracy: 81.04 (4160 / 5133), f1 (weighted): 80.48, loss: 7.27e-01\n",
      "  CPU time: 2560s, wall time: 1379s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 12250 / 49006 (epoch 12.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.80e-01\n",
      "  validation accuracy: 80.83 (4149 / 5133), f1 (weighted): 80.26, loss: 7.56e-01\n",
      "  CPU time: 2605s, wall time: 1401s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 12495 / 49006 (epoch 12.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.59e-01\n",
      "  validation accuracy: 80.32 (4123 / 5133), f1 (weighted): 80.20, loss: 7.53e-01\n",
      "  CPU time: 2649s, wall time: 1423s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 12740 / 49006 (epoch 13.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 5.68e-02\n",
      "  validation accuracy: 81.36 (4176 / 5133), f1 (weighted): 80.60, loss: 7.14e-01\n",
      "  CPU time: 2694s, wall time: 1446s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 12985 / 49006 (epoch 13.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 5.81e-02\n",
      "  validation accuracy: 80.44 (4129 / 5133), f1 (weighted): 79.76, loss: 7.66e-01\n",
      "  CPU time: 2740s, wall time: 1469s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 13230 / 49006 (epoch 13.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.32e-01\n",
      "  validation accuracy: 81.22 (4169 / 5133), f1 (weighted): 80.61, loss: 7.46e-01\n",
      "  CPU time: 2785s, wall time: 1491s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 13475 / 49006 (epoch 13.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.64e-01\n",
      "  validation accuracy: 81.47 (4182 / 5133), f1 (weighted): 80.81, loss: 7.44e-01\n",
      "  CPU time: 2830s, wall time: 1514s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 13720 / 49006 (epoch 14.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.52e-01\n",
      "  validation accuracy: 79.82 (4097 / 5133), f1 (weighted): 79.28, loss: 7.93e-01\n",
      "  CPU time: 2875s, wall time: 1536s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 13965 / 49006 (epoch 14.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.19e-01\n",
      "  validation accuracy: 80.93 (4154 / 5133), f1 (weighted): 80.41, loss: 7.61e-01\n",
      "  CPU time: 2921s, wall time: 1559s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 14210 / 49006 (epoch 14.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.07e-01\n",
      "  validation accuracy: 81.16 (4166 / 5133), f1 (weighted): 80.59, loss: 7.51e-01\n",
      "  CPU time: 2966s, wall time: 1582s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 14455 / 49006 (epoch 14.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.55e-02\n",
      "  validation accuracy: 81.59 (4188 / 5133), f1 (weighted): 80.84, loss: 7.47e-01\n",
      "  CPU time: 3011s, wall time: 1604s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 14700 / 49006 (epoch 15.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.76e-01\n",
      "  validation accuracy: 81.67 (4192 / 5133), f1 (weighted): 81.26, loss: 7.42e-01\n",
      "  CPU time: 3057s, wall time: 1627s, perf_time_load: 0.06s, perf_time: 0.06s\n",
      "step 14945 / 49006 (epoch 15.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.06e-01\n",
      "  validation accuracy: 81.22 (4169 / 5133), f1 (weighted): 80.84, loss: 7.65e-01\n",
      "  CPU time: 3101s, wall time: 1649s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 15190 / 49006 (epoch 15.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.45e-01\n",
      "  validation accuracy: 80.69 (4142 / 5133), f1 (weighted): 80.36, loss: 7.60e-01\n",
      "  CPU time: 3146s, wall time: 1671s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 15435 / 49006 (epoch 15.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.05e-01\n",
      "  validation accuracy: 81.32 (4174 / 5133), f1 (weighted): 80.59, loss: 7.98e-01\n",
      "  CPU time: 3192s, wall time: 1694s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 15680 / 49006 (epoch 16.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.50e-01\n",
      "  validation accuracy: 81.94 (4206 / 5133), f1 (weighted): 81.23, loss: 7.41e-01\n",
      "  CPU time: 3236s, wall time: 1717s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 15925 / 49006 (epoch 16.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 7.42e-02\n",
      "  validation accuracy: 81.67 (4192 / 5133), f1 (weighted): 81.14, loss: 7.63e-01\n",
      "  CPU time: 3282s, wall time: 1739s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 16170 / 49006 (epoch 16.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.60e-01\n",
      "  validation accuracy: 81.22 (4169 / 5133), f1 (weighted): 80.64, loss: 7.60e-01\n",
      "  CPU time: 3327s, wall time: 1761s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 16415 / 49006 (epoch 16.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.50e-01\n",
      "  validation accuracy: 81.47 (4182 / 5133), f1 (weighted): 80.72, loss: 7.68e-01\n",
      "  CPU time: 3371s, wall time: 1784s, perf_time_load: 0.05s, perf_time: 0.05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 16660 / 49006 (epoch 17.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.04e-01\n",
      "  validation accuracy: 81.63 (4190 / 5133), f1 (weighted): 80.98, loss: 7.42e-01\n",
      "  CPU time: 3417s, wall time: 1806s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 16905 / 49006 (epoch 17.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.40e-01\n",
      "  validation accuracy: 81.28 (4172 / 5133), f1 (weighted): 80.42, loss: 7.50e-01\n",
      "  CPU time: 3461s, wall time: 1829s, perf_time_load: 0.06s, perf_time: 0.06s\n",
      "step 17150 / 49006 (epoch 17.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.00e-01\n",
      "  validation accuracy: 80.32 (4123 / 5133), f1 (weighted): 79.95, loss: 7.94e-01\n",
      "  CPU time: 3506s, wall time: 1851s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 17395 / 49006 (epoch 17.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.96e-02\n",
      "  validation accuracy: 81.16 (4166 / 5133), f1 (weighted): 80.45, loss: 7.90e-01\n",
      "  CPU time: 3551s, wall time: 1874s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 17640 / 49006 (epoch 18.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 7.80e-02\n",
      "  validation accuracy: 80.99 (4157 / 5133), f1 (weighted): 80.45, loss: 7.90e-01\n",
      "  CPU time: 3596s, wall time: 1897s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 17885 / 49006 (epoch 18.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.23e-01\n",
      "  validation accuracy: 80.75 (4145 / 5133), f1 (weighted): 80.32, loss: 7.91e-01\n",
      "  CPU time: 3643s, wall time: 1920s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 18130 / 49006 (epoch 18.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 7.51e-02\n",
      "  validation accuracy: 81.06 (4161 / 5133), f1 (weighted): 80.31, loss: 8.39e-01\n",
      "  CPU time: 3688s, wall time: 1942s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 18375 / 49006 (epoch 18.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 7.01e-02\n",
      "  validation accuracy: 81.49 (4183 / 5133), f1 (weighted): 81.05, loss: 7.68e-01\n",
      "  CPU time: 3732s, wall time: 1965s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 18620 / 49006 (epoch 19.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.02e-01\n",
      "  validation accuracy: 81.59 (4188 / 5133), f1 (weighted): 81.24, loss: 7.75e-01\n",
      "  CPU time: 3777s, wall time: 1987s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 18865 / 49006 (epoch 19.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 7.73e-02\n",
      "  validation accuracy: 80.58 (4136 / 5133), f1 (weighted): 80.18, loss: 7.96e-01\n",
      "  CPU time: 3822s, wall time: 2009s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 19110 / 49006 (epoch 19.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.46e-01\n",
      "  validation accuracy: 81.59 (4188 / 5133), f1 (weighted): 81.10, loss: 7.86e-01\n",
      "  CPU time: 3867s, wall time: 2032s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 19355 / 49006 (epoch 19.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 8.07e-02\n",
      "  validation accuracy: 81.39 (4178 / 5133), f1 (weighted): 80.68, loss: 8.01e-01\n",
      "  CPU time: 3912s, wall time: 2054s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 19600 / 49006 (epoch 20.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 7.99e-02\n",
      "  validation accuracy: 81.57 (4187 / 5133), f1 (weighted): 80.98, loss: 7.97e-01\n",
      "  CPU time: 3957s, wall time: 2076s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 19845 / 49006 (epoch 20.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.90e-02\n",
      "  validation accuracy: 80.83 (4149 / 5133), f1 (weighted): 80.79, loss: 7.99e-01\n",
      "  CPU time: 4001s, wall time: 2099s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 20090 / 49006 (epoch 20.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 8.55e-02\n",
      "  validation accuracy: 81.20 (4168 / 5133), f1 (weighted): 80.97, loss: 7.92e-01\n",
      "  CPU time: 4049s, wall time: 2122s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 20335 / 49006 (epoch 20.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.03e-01\n",
      "  validation accuracy: 80.77 (4146 / 5133), f1 (weighted): 80.34, loss: 8.20e-01\n",
      "  CPU time: 4094s, wall time: 2145s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 20580 / 49006 (epoch 21.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 9.91e-02\n",
      "  validation accuracy: 81.32 (4174 / 5133), f1 (weighted): 80.60, loss: 8.12e-01\n",
      "  CPU time: 4139s, wall time: 2167s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 20825 / 49006 (epoch 21.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.51e-01\n",
      "  validation accuracy: 81.92 (4205 / 5133), f1 (weighted): 81.12, loss: 8.02e-01\n",
      "  CPU time: 4186s, wall time: 2190s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 21070 / 49006 (epoch 21.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.11e-02\n",
      "  validation accuracy: 81.24 (4170 / 5133), f1 (weighted): 80.78, loss: 8.25e-01\n",
      "  CPU time: 4231s, wall time: 2212s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 21315 / 49006 (epoch 21.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.32e-01\n",
      "  validation accuracy: 81.45 (4181 / 5133), f1 (weighted): 80.86, loss: 8.26e-01\n",
      "  CPU time: 4275s, wall time: 2235s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 21560 / 49006 (epoch 22.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 8.63e-03\n",
      "  validation accuracy: 82.02 (4210 / 5133), f1 (weighted): 81.61, loss: 7.94e-01\n",
      "  CPU time: 4320s, wall time: 2257s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 21805 / 49006 (epoch 22.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.40e-01\n",
      "  validation accuracy: 82.06 (4212 / 5133), f1 (weighted): 81.40, loss: 7.92e-01\n",
      "  CPU time: 4364s, wall time: 2280s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 22050 / 49006 (epoch 22.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.77e-02\n",
      "  validation accuracy: 81.32 (4174 / 5133), f1 (weighted): 80.88, loss: 8.00e-01\n",
      "  CPU time: 4409s, wall time: 2302s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 22295 / 49006 (epoch 22.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.54e-01\n",
      "  validation accuracy: 81.51 (4184 / 5133), f1 (weighted): 80.99, loss: 8.12e-01\n",
      "  CPU time: 4454s, wall time: 2326s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 22540 / 49006 (epoch 23.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.47e-01\n",
      "  validation accuracy: 81.02 (4159 / 5133), f1 (weighted): 80.62, loss: 8.26e-01\n",
      "  CPU time: 4499s, wall time: 2348s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 22785 / 49006 (epoch 23.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 5.87e-02\n",
      "  validation accuracy: 81.36 (4176 / 5133), f1 (weighted): 80.73, loss: 8.11e-01\n",
      "  CPU time: 4543s, wall time: 2370s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 23030 / 49006 (epoch 23.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.11e-01\n",
      "  validation accuracy: 82.27 (4223 / 5133), f1 (weighted): 81.69, loss: 7.99e-01\n",
      "  CPU time: 4588s, wall time: 2393s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 23275 / 49006 (epoch 23.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.38e-02\n",
      "  validation accuracy: 81.45 (4181 / 5133), f1 (weighted): 81.01, loss: 8.02e-01\n",
      "  CPU time: 4632s, wall time: 2415s, perf_time_load: 0.08s, perf_time: 0.08s\n",
      "step 23520 / 49006 (epoch 24.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 7.56e-02\n",
      "  validation accuracy: 81.06 (4161 / 5133), f1 (weighted): 80.67, loss: 8.25e-01\n",
      "  CPU time: 4678s, wall time: 2438s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 23765 / 49006 (epoch 24.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.52e-02\n",
      "  validation accuracy: 81.34 (4175 / 5133), f1 (weighted): 80.86, loss: 8.65e-01\n",
      "  CPU time: 4722s, wall time: 2461s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 24010 / 49006 (epoch 24.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 8.74e-02\n",
      "  validation accuracy: 82.14 (4216 / 5133), f1 (weighted): 81.48, loss: 8.14e-01\n",
      "  CPU time: 4767s, wall time: 2483s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 24255 / 49006 (epoch 24.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.63e-02\n",
      "  validation accuracy: 82.00 (4209 / 5133), f1 (weighted): 81.62, loss: 8.07e-01\n",
      "  CPU time: 4811s, wall time: 2505s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 24500 / 49006 (epoch 25.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.68e-02\n",
      "  validation accuracy: 82.14 (4216 / 5133), f1 (weighted): 81.65, loss: 8.03e-01\n",
      "  CPU time: 4857s, wall time: 2528s, perf_time_load: 0.05s, perf_time: 0.05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 24745 / 49006 (epoch 25.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.72e-01\n",
      "  validation accuracy: 81.73 (4195 / 5133), f1 (weighted): 81.16, loss: 8.32e-01\n",
      "  CPU time: 4902s, wall time: 2550s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 24990 / 49006 (epoch 25.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.25e-02\n",
      "  validation accuracy: 81.73 (4195 / 5133), f1 (weighted): 81.15, loss: 8.58e-01\n",
      "  CPU time: 4946s, wall time: 2573s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 25235 / 49006 (epoch 25.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 8.36e-02\n",
      "  validation accuracy: 81.02 (4159 / 5133), f1 (weighted): 80.64, loss: 8.48e-01\n",
      "  CPU time: 4991s, wall time: 2595s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 25480 / 49006 (epoch 26.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 9.06e-02\n",
      "  validation accuracy: 81.84 (4201 / 5133), f1 (weighted): 81.20, loss: 8.40e-01\n",
      "  CPU time: 5038s, wall time: 2619s, perf_time_load: 0.07s, perf_time: 0.07s\n",
      "step 25725 / 49006 (epoch 26.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.63e-02\n",
      "  validation accuracy: 81.94 (4206 / 5133), f1 (weighted): 81.52, loss: 8.47e-01\n",
      "  CPU time: 5086s, wall time: 2642s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 25970 / 49006 (epoch 26.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.86e-02\n",
      "  validation accuracy: 81.57 (4187 / 5133), f1 (weighted): 81.27, loss: 8.49e-01\n",
      "  CPU time: 5131s, wall time: 2664s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 26215 / 49006 (epoch 26.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.93e-02\n",
      "  validation accuracy: 81.57 (4187 / 5133), f1 (weighted): 81.21, loss: 8.42e-01\n",
      "  CPU time: 5177s, wall time: 2687s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 26460 / 49006 (epoch 27.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.55e-02\n",
      "  validation accuracy: 81.98 (4208 / 5133), f1 (weighted): 81.50, loss: 8.27e-01\n",
      "  CPU time: 5222s, wall time: 2710s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 26705 / 49006 (epoch 27.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.03e-01\n",
      "  validation accuracy: 81.77 (4197 / 5133), f1 (weighted): 81.48, loss: 8.30e-01\n",
      "  CPU time: 5266s, wall time: 2732s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 26950 / 49006 (epoch 27.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.24e-02\n",
      "  validation accuracy: 81.43 (4180 / 5133), f1 (weighted): 80.95, loss: 8.70e-01\n",
      "  CPU time: 5312s, wall time: 2754s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 27195 / 49006 (epoch 27.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.12e-01\n",
      "  validation accuracy: 81.71 (4194 / 5133), f1 (weighted): 81.20, loss: 8.51e-01\n",
      "  CPU time: 5356s, wall time: 2776s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 27440 / 49006 (epoch 28.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.65e-02\n",
      "  validation accuracy: 81.78 (4198 / 5133), f1 (weighted): 81.40, loss: 8.38e-01\n",
      "  CPU time: 5401s, wall time: 2799s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 27685 / 49006 (epoch 28.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.78e-02\n",
      "  validation accuracy: 81.92 (4205 / 5133), f1 (weighted): 81.31, loss: 8.65e-01\n",
      "  CPU time: 5447s, wall time: 2822s, perf_time_load: 0.06s, perf_time: 0.06s\n",
      "step 27930 / 49006 (epoch 28.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.28e-02\n",
      "  validation accuracy: 81.71 (4194 / 5133), f1 (weighted): 81.26, loss: 8.66e-01\n",
      "  CPU time: 5491s, wall time: 2844s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 28175 / 49006 (epoch 28.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 5.15e-02\n",
      "  validation accuracy: 81.82 (4200 / 5133), f1 (weighted): 81.18, loss: 8.62e-01\n",
      "  CPU time: 5537s, wall time: 2867s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 28420 / 49006 (epoch 29.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.10e-02\n",
      "  validation accuracy: 81.77 (4197 / 5133), f1 (weighted): 81.41, loss: 8.48e-01\n",
      "  CPU time: 5582s, wall time: 2889s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 28665 / 49006 (epoch 29.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.28e-02\n",
      "  validation accuracy: 81.78 (4198 / 5133), f1 (weighted): 81.32, loss: 8.49e-01\n",
      "  CPU time: 5628s, wall time: 2912s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 28910 / 49006 (epoch 29.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.72e-02\n",
      "  validation accuracy: 81.22 (4169 / 5133), f1 (weighted): 80.58, loss: 8.96e-01\n",
      "  CPU time: 5674s, wall time: 2935s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 29155 / 49006 (epoch 29.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.48e-02\n",
      "  validation accuracy: 82.17 (4218 / 5133), f1 (weighted): 81.68, loss: 8.39e-01\n",
      "  CPU time: 5719s, wall time: 2958s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 29400 / 49006 (epoch 30.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 5.99e-02\n",
      "  validation accuracy: 81.51 (4184 / 5133), f1 (weighted): 81.31, loss: 8.42e-01\n",
      "  CPU time: 5764s, wall time: 2980s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 29645 / 49006 (epoch 30.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.55e-02\n",
      "  validation accuracy: 81.26 (4171 / 5133), f1 (weighted): 81.28, loss: 8.51e-01\n",
      "  CPU time: 5808s, wall time: 3002s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 29890 / 49006 (epoch 30.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.36e-02\n",
      "  validation accuracy: 81.59 (4188 / 5133), f1 (weighted): 81.11, loss: 8.56e-01\n",
      "  CPU time: 5854s, wall time: 3025s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 30135 / 49006 (epoch 30.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 8.53e-03\n",
      "  validation accuracy: 81.20 (4168 / 5133), f1 (weighted): 80.74, loss: 8.91e-01\n",
      "  CPU time: 5899s, wall time: 3047s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 30380 / 49006 (epoch 31.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.71e-02\n",
      "  validation accuracy: 82.02 (4210 / 5133), f1 (weighted): 81.64, loss: 8.65e-01\n",
      "  CPU time: 5944s, wall time: 3069s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 30625 / 49006 (epoch 31.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 8.43e-02\n",
      "  validation accuracy: 81.34 (4175 / 5133), f1 (weighted): 81.14, loss: 8.82e-01\n",
      "  CPU time: 5988s, wall time: 3092s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 30870 / 49006 (epoch 31.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.49e-03\n",
      "  validation accuracy: 81.92 (4205 / 5133), f1 (weighted): 81.66, loss: 8.42e-01\n",
      "  CPU time: 6033s, wall time: 3114s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 31115 / 49006 (epoch 31.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.69e-02\n",
      "  validation accuracy: 81.73 (4195 / 5133), f1 (weighted): 81.35, loss: 8.74e-01\n",
      "  CPU time: 6080s, wall time: 3137s, perf_time_load: 0.06s, perf_time: 0.06s\n",
      "step 31360 / 49006 (epoch 32.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.27e-02\n",
      "  validation accuracy: 81.41 (4179 / 5133), f1 (weighted): 81.24, loss: 8.80e-01\n",
      "  CPU time: 6127s, wall time: 3160s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 31605 / 49006 (epoch 32.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.46e-02\n",
      "  validation accuracy: 81.73 (4195 / 5133), f1 (weighted): 81.36, loss: 8.58e-01\n",
      "  CPU time: 6171s, wall time: 3182s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 31850 / 49006 (epoch 32.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 5.22e-02\n",
      "  validation accuracy: 81.41 (4179 / 5133), f1 (weighted): 80.95, loss: 8.84e-01\n",
      "  CPU time: 6216s, wall time: 3204s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 32095 / 49006 (epoch 32.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.12e-02\n",
      "  validation accuracy: 81.43 (4180 / 5133), f1 (weighted): 81.03, loss: 8.88e-01\n",
      "  CPU time: 6261s, wall time: 3227s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 32340 / 49006 (epoch 33.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.09e-02\n",
      "  validation accuracy: 81.75 (4196 / 5133), f1 (weighted): 81.39, loss: 8.85e-01\n",
      "  CPU time: 6305s, wall time: 3249s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 32585 / 49006 (epoch 33.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.37e-02\n",
      "  validation accuracy: 81.32 (4174 / 5133), f1 (weighted): 80.98, loss: 8.83e-01\n",
      "  CPU time: 6350s, wall time: 3271s, perf_time_load: 0.05s, perf_time: 0.05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 32830 / 49006 (epoch 33.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.93e-02\n",
      "  validation accuracy: 81.88 (4203 / 5133), f1 (weighted): 81.67, loss: 8.89e-01\n",
      "  CPU time: 6394s, wall time: 3293s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 33075 / 49006 (epoch 33.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 7.48e-03\n",
      "  validation accuracy: 82.00 (4209 / 5133), f1 (weighted): 81.45, loss: 8.80e-01\n",
      "  CPU time: 6439s, wall time: 3315s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 33320 / 49006 (epoch 34.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.59e-02\n",
      "  validation accuracy: 82.15 (4217 / 5133), f1 (weighted): 81.66, loss: 8.62e-01\n",
      "  CPU time: 6485s, wall time: 3338s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 33565 / 49006 (epoch 34.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.54e-02\n",
      "  validation accuracy: 82.02 (4210 / 5133), f1 (weighted): 81.59, loss: 9.00e-01\n",
      "  CPU time: 6530s, wall time: 3360s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 33810 / 49006 (epoch 34.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.20e-02\n",
      "  validation accuracy: 82.10 (4214 / 5133), f1 (weighted): 81.80, loss: 8.76e-01\n",
      "  CPU time: 6575s, wall time: 3382s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 34055 / 49006 (epoch 34.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.75e-02\n",
      "  validation accuracy: 82.17 (4218 / 5133), f1 (weighted): 81.57, loss: 8.90e-01\n",
      "  CPU time: 6619s, wall time: 3404s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 34300 / 49006 (epoch 35.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 7.20e-02\n",
      "  validation accuracy: 81.59 (4188 / 5133), f1 (weighted): 81.29, loss: 8.83e-01\n",
      "  CPU time: 6664s, wall time: 3427s, perf_time_load: 0.07s, perf_time: 0.07s\n",
      "step 34545 / 49006 (epoch 35.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.90e-02\n",
      "  validation accuracy: 81.39 (4178 / 5133), f1 (weighted): 81.13, loss: 8.96e-01\n",
      "  CPU time: 6711s, wall time: 3450s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 34790 / 49006 (epoch 35.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.72e-02\n",
      "  validation accuracy: 81.92 (4205 / 5133), f1 (weighted): 81.51, loss: 8.80e-01\n",
      "  CPU time: 6756s, wall time: 3472s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 35035 / 49006 (epoch 35.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.36e-02\n",
      "  validation accuracy: 81.86 (4202 / 5133), f1 (weighted): 81.37, loss: 8.91e-01\n",
      "  CPU time: 6801s, wall time: 3495s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 35280 / 49006 (epoch 36.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.18e-02\n",
      "  validation accuracy: 81.22 (4169 / 5133), f1 (weighted): 80.73, loss: 9.19e-01\n",
      "  CPU time: 6845s, wall time: 3517s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 35525 / 49006 (epoch 36.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.20e-02\n",
      "  validation accuracy: 80.93 (4154 / 5133), f1 (weighted): 80.70, loss: 9.29e-01\n",
      "  CPU time: 6890s, wall time: 3539s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 35770 / 49006 (epoch 36.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.07e-02\n",
      "  validation accuracy: 81.34 (4175 / 5133), f1 (weighted): 80.90, loss: 9.26e-01\n",
      "  CPU time: 6935s, wall time: 3561s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 36015 / 49006 (epoch 36.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 5.02e-02\n",
      "  validation accuracy: 81.63 (4190 / 5133), f1 (weighted): 81.10, loss: 9.04e-01\n",
      "  CPU time: 6979s, wall time: 3583s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 36260 / 49006 (epoch 37.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.97e-02\n",
      "  validation accuracy: 81.49 (4183 / 5133), f1 (weighted): 81.10, loss: 9.14e-01\n",
      "  CPU time: 7025s, wall time: 3606s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 36505 / 49006 (epoch 37.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.50e-02\n",
      "  validation accuracy: 81.38 (4177 / 5133), f1 (weighted): 81.03, loss: 9.15e-01\n",
      "  CPU time: 7071s, wall time: 3629s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 36750 / 49006 (epoch 37.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.29e-02\n",
      "  validation accuracy: 82.15 (4217 / 5133), f1 (weighted): 81.66, loss: 8.98e-01\n",
      "  CPU time: 7115s, wall time: 3651s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 36995 / 49006 (epoch 37.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 9.98e-02\n",
      "  validation accuracy: 82.37 (4228 / 5133), f1 (weighted): 81.85, loss: 8.87e-01\n",
      "  CPU time: 7160s, wall time: 3673s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 37240 / 49006 (epoch 38.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.56e-02\n",
      "  validation accuracy: 82.14 (4216 / 5133), f1 (weighted): 81.72, loss: 9.32e-01\n",
      "  CPU time: 7206s, wall time: 3696s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 37485 / 49006 (epoch 38.25 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.82e-03\n",
      "  validation accuracy: 81.45 (4181 / 5133), f1 (weighted): 81.15, loss: 9.47e-01\n",
      "  CPU time: 7251s, wall time: 3718s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 37730 / 49006 (epoch 38.50 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 7.68e-03\n",
      "  validation accuracy: 81.77 (4197 / 5133), f1 (weighted): 81.33, loss: 9.30e-01\n",
      "  CPU time: 7296s, wall time: 3741s, perf_time_load: 0.06s, perf_time: 0.06s\n",
      "step 37975 / 49006 (epoch 38.75 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.53e-02\n",
      "  validation accuracy: 81.49 (4183 / 5133), f1 (weighted): 81.10, loss: 9.29e-01\n",
      "  CPU time: 7343s, wall time: 3764s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 38220 / 49006 (epoch 39.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 9.66e-03\n",
      "  validation accuracy: 81.86 (4202 / 5133), f1 (weighted): 81.46, loss: 8.98e-01\n",
      "  CPU time: 7387s, wall time: 3786s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 38465 / 49006 (epoch 39.24 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 8.63e-03\n",
      "  validation accuracy: 81.41 (4179 / 5133), f1 (weighted): 80.94, loss: 9.18e-01\n",
      "  CPU time: 7432s, wall time: 3808s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 38710 / 49006 (epoch 39.49 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.12e-02\n",
      "  validation accuracy: 81.71 (4194 / 5133), f1 (weighted): 81.50, loss: 9.25e-01\n",
      "  CPU time: 7476s, wall time: 3830s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 38955 / 49006 (epoch 39.74 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 9.15e-03\n",
      "  validation accuracy: 81.88 (4203 / 5133), f1 (weighted): 81.33, loss: 9.38e-01\n",
      "  CPU time: 7521s, wall time: 3852s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 39200 / 49006 (epoch 39.99 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.80e-03\n",
      "  validation accuracy: 82.00 (4209 / 5133), f1 (weighted): 81.50, loss: 9.32e-01\n",
      "  CPU time: 7568s, wall time: 3875s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 39445 / 49006 (epoch 40.24 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.15e-02\n",
      "  validation accuracy: 81.75 (4196 / 5133), f1 (weighted): 81.36, loss: 9.28e-01\n",
      "  CPU time: 7612s, wall time: 3898s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 39690 / 49006 (epoch 40.49 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.78e-02\n",
      "  validation accuracy: 81.82 (4200 / 5133), f1 (weighted): 81.47, loss: 9.32e-01\n",
      "  CPU time: 7657s, wall time: 3920s, perf_time_load: 0.06s, perf_time: 0.06s\n",
      "step 39935 / 49006 (epoch 40.74 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.24e-03\n",
      "  validation accuracy: 81.57 (4187 / 5133), f1 (weighted): 81.30, loss: 9.34e-01\n",
      "  CPU time: 7704s, wall time: 3943s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 40180 / 49006 (epoch 40.99 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.77e-02\n",
      "  validation accuracy: 81.55 (4186 / 5133), f1 (weighted): 81.17, loss: 9.36e-01\n",
      "  CPU time: 7749s, wall time: 3965s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 40425 / 49006 (epoch 41.24 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.93e-02\n",
      "  validation accuracy: 81.49 (4183 / 5133), f1 (weighted): 81.19, loss: 9.53e-01\n",
      "  CPU time: 7793s, wall time: 3988s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 40670 / 49006 (epoch 41.49 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.52e-03\n",
      "  validation accuracy: 81.26 (4171 / 5133), f1 (weighted): 80.92, loss: 9.32e-01\n",
      "  CPU time: 7838s, wall time: 4011s, perf_time_load: 0.05s, perf_time: 0.05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 40915 / 49006 (epoch 41.74 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 4.99e-02\n",
      "  validation accuracy: 81.51 (4184 / 5133), f1 (weighted): 81.12, loss: 9.54e-01\n",
      "  CPU time: 7883s, wall time: 4033s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 41160 / 49006 (epoch 41.99 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.77e-02\n",
      "  validation accuracy: 81.08 (4162 / 5133), f1 (weighted): 80.56, loss: 9.74e-01\n",
      "  CPU time: 7928s, wall time: 4055s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 41405 / 49006 (epoch 42.24 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.00e-02\n",
      "  validation accuracy: 81.80 (4199 / 5133), f1 (weighted): 81.36, loss: 9.31e-01\n",
      "  CPU time: 7973s, wall time: 4077s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 41650 / 49006 (epoch 42.49 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.35e-02\n",
      "  validation accuracy: 81.78 (4198 / 5133), f1 (weighted): 81.31, loss: 9.34e-01\n",
      "  CPU time: 8018s, wall time: 4099s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 41895 / 49006 (epoch 42.74 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.15e-02\n",
      "  validation accuracy: 81.57 (4187 / 5133), f1 (weighted): 81.28, loss: 9.30e-01\n",
      "  CPU time: 8063s, wall time: 4122s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 42140 / 49006 (epoch 42.99 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.29e-02\n",
      "  validation accuracy: 81.67 (4192 / 5133), f1 (weighted): 81.47, loss: 9.43e-01\n",
      "  CPU time: 8110s, wall time: 4145s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 42385 / 49006 (epoch 43.24 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.57e-02\n",
      "  validation accuracy: 81.69 (4193 / 5133), f1 (weighted): 81.24, loss: 9.54e-01\n",
      "  CPU time: 8155s, wall time: 4167s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 42630 / 49006 (epoch 43.49 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.12e-02\n",
      "  validation accuracy: 81.71 (4194 / 5133), f1 (weighted): 81.19, loss: 9.55e-01\n",
      "  CPU time: 8199s, wall time: 4189s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 42875 / 49006 (epoch 43.74 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.24e-02\n",
      "  validation accuracy: 82.00 (4209 / 5133), f1 (weighted): 81.63, loss: 9.59e-01\n",
      "  CPU time: 8244s, wall time: 4212s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 43120 / 49006 (epoch 43.99 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.40e-02\n",
      "  validation accuracy: 82.04 (4211 / 5133), f1 (weighted): 81.72, loss: 9.36e-01\n",
      "  CPU time: 8289s, wall time: 4234s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 43365 / 49006 (epoch 44.24 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.23e-02\n",
      "  validation accuracy: 81.73 (4195 / 5133), f1 (weighted): 81.47, loss: 9.21e-01\n",
      "  CPU time: 8335s, wall time: 4257s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 43610 / 49006 (epoch 44.49 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.22e-02\n",
      "  validation accuracy: 81.51 (4184 / 5133), f1 (weighted): 81.12, loss: 9.57e-01\n",
      "  CPU time: 8379s, wall time: 4279s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 43855 / 49006 (epoch 44.74 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.43e-02\n",
      "  validation accuracy: 81.65 (4191 / 5133), f1 (weighted): 81.27, loss: 9.38e-01\n",
      "  CPU time: 8423s, wall time: 4301s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 44100 / 49006 (epoch 44.99 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.83e-03\n",
      "  validation accuracy: 81.59 (4188 / 5133), f1 (weighted): 81.37, loss: 9.51e-01\n",
      "  CPU time: 8468s, wall time: 4323s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 44345 / 49006 (epoch 45.24 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.39e-03\n",
      "  validation accuracy: 81.73 (4195 / 5133), f1 (weighted): 81.31, loss: 9.43e-01\n",
      "  CPU time: 8511s, wall time: 4345s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 44590 / 49006 (epoch 45.49 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 7.47e-03\n",
      "  validation accuracy: 81.24 (4170 / 5133), f1 (weighted): 80.96, loss: 9.63e-01\n",
      "  CPU time: 8556s, wall time: 4367s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 44835 / 49006 (epoch 45.74 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 9.01e-03\n",
      "  validation accuracy: 81.34 (4175 / 5133), f1 (weighted): 80.86, loss: 9.59e-01\n",
      "  CPU time: 8600s, wall time: 4389s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 45080 / 49006 (epoch 45.99 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.27e-02\n",
      "  validation accuracy: 82.00 (4209 / 5133), f1 (weighted): 81.54, loss: 9.51e-01\n",
      "  CPU time: 8645s, wall time: 4412s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 45325 / 49006 (epoch 46.24 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.10e-02\n",
      "  validation accuracy: 82.29 (4224 / 5133), f1 (weighted): 81.85, loss: 9.45e-01\n",
      "  CPU time: 8689s, wall time: 4434s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 45570 / 49006 (epoch 46.49 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.06e-02\n",
      "  validation accuracy: 81.73 (4195 / 5133), f1 (weighted): 81.38, loss: 9.51e-01\n",
      "  CPU time: 8734s, wall time: 4456s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 45815 / 49006 (epoch 46.74 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.95e-02\n",
      "  validation accuracy: 82.14 (4216 / 5133), f1 (weighted): 81.73, loss: 9.35e-01\n",
      "  CPU time: 8779s, wall time: 4479s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 46060 / 49006 (epoch 46.99 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.24e-02\n",
      "  validation accuracy: 81.90 (4204 / 5133), f1 (weighted): 81.48, loss: 9.57e-01\n",
      "  CPU time: 8824s, wall time: 4501s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 46305 / 49006 (epoch 47.24 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.40e-02\n",
      "  validation accuracy: 81.88 (4203 / 5133), f1 (weighted): 81.37, loss: 9.71e-01\n",
      "  CPU time: 8869s, wall time: 4524s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 46550 / 49006 (epoch 47.49 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.82e-03\n",
      "  validation accuracy: 81.80 (4199 / 5133), f1 (weighted): 81.40, loss: 9.75e-01\n",
      "  CPU time: 8913s, wall time: 4546s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 46795 / 49006 (epoch 47.74 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.39e-02\n",
      "  validation accuracy: 81.90 (4204 / 5133), f1 (weighted): 81.53, loss: 9.66e-01\n",
      "  CPU time: 8959s, wall time: 4569s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 47040 / 49006 (epoch 47.99 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 6.37e-03\n",
      "  validation accuracy: 81.55 (4186 / 5133), f1 (weighted): 81.20, loss: 9.90e-01\n",
      "  CPU time: 9003s, wall time: 4591s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 47285 / 49006 (epoch 48.24 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 3.15e-02\n",
      "  validation accuracy: 81.57 (4187 / 5133), f1 (weighted): 81.30, loss: 9.84e-01\n",
      "  CPU time: 9049s, wall time: 4614s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 47530 / 49006 (epoch 48.49 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 7.04e-03\n",
      "  validation accuracy: 82.15 (4217 / 5133), f1 (weighted): 81.78, loss: 9.58e-01\n",
      "  CPU time: 9094s, wall time: 4637s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 47775 / 49006 (epoch 48.74 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 7.66e-03\n",
      "  validation accuracy: 81.73 (4195 / 5133), f1 (weighted): 81.34, loss: 9.86e-01\n",
      "  CPU time: 9139s, wall time: 4659s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 48020 / 49006 (epoch 48.99 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.35e-02\n",
      "  validation accuracy: 82.33 (4226 / 5133), f1 (weighted): 81.95, loss: 9.59e-01\n",
      "  CPU time: 9183s, wall time: 4681s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 48265 / 49006 (epoch 49.24 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.60e-02\n",
      "  validation accuracy: 81.82 (4200 / 5133), f1 (weighted): 81.40, loss: 9.55e-01\n",
      "  CPU time: 9228s, wall time: 4703s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 48510 / 49006 (epoch 49.49 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.58e-02\n",
      "  validation accuracy: 81.77 (4197 / 5133), f1 (weighted): 81.26, loss: 9.89e-01\n",
      "  CPU time: 9273s, wall time: 4726s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 48755 / 49006 (epoch 49.74 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 2.39e-02\n",
      "  validation accuracy: 81.80 (4199 / 5133), f1 (weighted): 81.45, loss: 9.67e-01\n",
      "  CPU time: 9317s, wall time: 4748s, perf_time_load: 0.05s, perf_time: 0.05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 49000 / 49006 (epoch 49.99 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 1.17e-02\n",
      "  validation accuracy: 81.82 (4200 / 5133), f1 (weighted): 81.54, loss: 9.63e-01\n",
      "  CPU time: 9362s, wall time: 4770s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "step 49006 / 49006 (epoch 50.00 / 50):\n",
      "  learning_rate = 1.00e-02, training loss = 9.28e-03\n",
      "  validation accuracy: 81.86 (4202 / 5133), f1 (weighted): 81.47, loss: 9.74e-01\n",
      "  CPU time: 9375s, wall time: 4781s, perf_time_load: 0.05s, perf_time: 0.05s\n",
      "validation accuracy: best = 82.37, mean = 81.84\n",
      "time per batch: mean = 0.05, var = 0.00076\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-9416646c45b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_TFDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_tf_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "accuracy_validation, loss_validation, loss_training, t_step, t_batch = model.fit(train_TFDataset, val_dataset, use_tf_dataset=True, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6e3d065454a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_frequency'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_training' is not defined"
     ]
    }
   ],
   "source": [
    "plot.plot_loss(loss_training, loss_validation, t_step, params['eval_frequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_Cohen_simple_SGD_max_nsides_300epoch_reg_32sides_CNN\n",
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_Cohen_simple_SGD_max_nsides_300epoch_reg_32sides_CNN/model-294037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('accuracy: 96.53 (30277 / 31364), f1 (weighted): 96.54, loss: 1.16e-01\\nCPU time: 275s, wall time: 257s',\n",
       " 96.53424308123964,\n",
       " 96.54157073077505,\n",
       " 0.115866209483545)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions, loss = model.predict(x_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_5K_cache_1aug_32sides_CNN\n",
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_5K_cache_1aug_32sides_CNN/model-49006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('accuracy: 81.86 (4202 / 5133), f1 (weighted): 81.47, loss: 9.74e-01\\nCPU time: 12s, wall time: 11s',\n",
       " 81.86245860120786,\n",
       " 81.46578216620523,\n",
       " 0.9739741521947174)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.evaluate(x_val, labels_val)\n",
    "model.evaluate(val_dataset, None, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_5K_cache_1aug_32sides_CNN\n",
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_5K_cache_1aug_32sides_CNN/model-49006\n"
     ]
    }
   ],
   "source": [
    "# probabilities = model.probs(x_val, nclass)\n",
    "probabilities, _ = model.probs(val_dataset, nclass, cache=True)\n",
    "if augmentation>1:\n",
    "    probabilities = probabilities.reshape((-1,augmentation,nclass))\n",
    "    probabilities = probabilities.mean(axis=1)\n",
    "    #ids_val = ids_val[::repeat]\n",
    "predictions = np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_val = val_dataset.get_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = predictions.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SHREC17.load_shrec import shrec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrec_output(probabilities, ids_val, datapath, 'results/val_perturbed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every file, find every object with the same class, sorted by most relevance\n",
    "os.makedirs(os.path.join(datapath,'results_aug/val_perturbed'), exist_ok=True)\n",
    "for i,_id in enumerate(ids_val):\n",
    "    idfile = os.path.join(datapath,'results_aug/val_perturbed',_id)\n",
    "    # predictions batchxclass\n",
    "    # pred_class batch == predictions\n",
    "    retrieved = [(probabilities[j, predictions[j]], ids_val[j]) for j in range(len(ids_val)) if predictions[j] == predictions[i]]\n",
    "    retrieved = sorted(retrieved, reverse=True)\n",
    "    retrieved = [i for _, i in retrieved]\n",
    "    with open(idfile, \"w\") as f:\n",
    "        f.write(\"\\n\".join(retrieved))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN appears if remove i==j case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10265it [00:20, 493.48it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = Shrec17Dataset(datapath, 'test', perturbed=noise_dataset, download=download, nside=Nside, augmentation=augmentation, nfile=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test, labels_test, ids_test = test_dataset.return_data(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_5K_cache_1aug_32sides_CNN\n",
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_5K_cache_1aug_32sides_CNN/model-49006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('accuracy: 78.81 (8090 / 10265), f1 (weighted): 78.83, loss: 1.19e+00\\nCPU time: 14s, wall time: 13s',\n",
       " 78.81149537262543,\n",
       " 78.8281112626363,\n",
       " 1.1859818069283345)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_5K_cache_1aug_32sides_CNN\n",
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_5K_cache_1aug_32sides_CNN/model-49006\n"
     ]
    }
   ],
   "source": [
    "probabilities = model.probs(x_test, nclass)\n",
    "if augmentation>1:\n",
    "    probabilities = probabilities.reshape((-1,augmentation,nclass))\n",
    "    probabilities = repeat.mean(axis=1)\n",
    "#probabilities = np.log(probabilities)\n",
    "predictions = np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = predictions.astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every file, find every object with the same class, sorted by most relevance\n",
    "os.makedirs(os.path.join(datapath,'results_aug/test_perturbed'), exist_ok=True)\n",
    "for i, _id in enumerate(ids_test):\n",
    "    idfile = os.path.join(datapath,'results_aug/test_perturbed',_id)\n",
    "    # predictions batchxclass\n",
    "    # pred_class batch == predictions\n",
    "    retrieved = [(probabilities[j, predictions[j]], ids_test[j]) for j in range(len(ids_test)) if predictions[j] == predictions[i]]\n",
    "    retrieved = sorted(retrieved, reverse=True)\n",
    "    retrieved = [i for _, i in retrieved]\n",
    "    with open(idfile, \"w\") as f:\n",
    "        f.write(\"\\n\".join(retrieved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrec_output(probabilities, ids_test, datapath, 'results/test_perturbed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why not working?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_histogram(nclass, labels_train, labels_min=None):\n",
    "    if labels_train is None:\n",
    "        return\n",
    "    import matplotlib.pyplot as plt\n",
    "    from collections import Counter\n",
    "    hist_train=Counter(labels_train)\n",
    "    if labels_min is not None:\n",
    "        hist_min = Counter(labels_min)\n",
    "        hist_temp = hist_train - hist_min\n",
    "        hist_min = hist_min - hist_train\n",
    "        hist_train = hist_temp + hist_min\n",
    "#         for i in range(self.nclass):\n",
    "#             hist_train.append(np.sum(labels_train == i))\n",
    "    labels, values = zip(*hist_train.items())\n",
    "    indexes = np.asarray(labels)\n",
    "#     miss = set(indexes) - set(labels)\n",
    "#     if len(miss) is not 0:\n",
    "#         hist_train.update({elem:0 for elem in miss})\n",
    "#     labels, values = zip(*hist_train.items())\n",
    "    width = 1\n",
    "    plt.bar(labels, values, width)\n",
    "    plt.title(\"labels distribution\")\n",
    "    plt.ylim(0,1700)\n",
    "    #plt.xticks(indexes + width * 0.5, labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_print_histogram(55, labels_test)\n",
    "_print_histogram(55, predictions)\n",
    "_print_histogram(55, labels_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1fdaff4a58>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.spy(confusion_matrix(labels_test, predictions, range(55)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
