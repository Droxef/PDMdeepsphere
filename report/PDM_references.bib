
@article{boureau_theoretical_2010,
	title = {A Theoretical Analysis of Feature Pooling in Visual Recognition},
	abstract = {Many modern visual recognition algorithms incorporate a step of spatial ‘pooling’, where the outputs of several nearby feature detectors are combined into a local or global ‘bag of features’, in a way that preserves task-related information while removing irrelevant details. Pooling is used to achieve invariance to image transformations, more compact representations, and better robustness to noise and clutter. Several papers have shown that the details of the pooling operation can greatly inﬂuence the performance, but studies have so far been purely empirical. In this paper, we show that the reasons underlying the performance of various pooling methods are obscured by several confounding factors, such as the link between the sample cardinality in a spatial pool and the resolution at which low-level features have been extracted. We provide a detailed theoretical analysis of max pooling and average pooling, and give extensive empirical comparisons for object recognition tasks.},
	pages = {111--118},
	journaltitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
	author = {Boureau, Y-Lan and Ponce, Jean and {LeCun}, Yann},
	date = {2010},
	langid = {english}
}

@report{milani_about_nodate,
	title = {About the spectrum of the Discrete Laplace-Beltrami operator on the Sphere for Rotation Equivariant Neural Networks},
	pages = {50},
	author = {Milani, Martino and Perraudin, Nathanaël and Defferrard, Michaël and Secchi, Piercesare and Vandergheynst, Pierre},
	langid = {english}
}

@article{bronstein_geometric_2017,
	title = {Geometric deep learning: going beyond Euclidean data},
	volume = {34},
	issn = {1053-5888},
	url = {http://arxiv.org/abs/1611.08097},
	doi = {10.1109/MSP.2017.2693418},
	shorttitle = {Geometric deep learning},
	abstract = {Many scientific fields study data with an underlying structure that is a non-Euclidean space. Some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. In many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions), and are natural targets for machine learning techniques. In particular, we would like to use deep neural networks, which have recently proven to be powerful tools for a broad range of problems from computer vision, natural language processing, and audio analysis. However, these tools have been most successful on data with an underlying Euclidean or grid-like structure, and in cases where the invariances of these structures are built into networks used to model them. Geometric deep learning is an umbrella term for emerging techniques attempting to generalize (structured) deep neural models to non-Euclidean domains such as graphs and manifolds. The purpose of this paper is to overview different examples of geometric deep learning problems and present available solutions, key difficulties, applications, and future research directions in this nascent field.},
	pages = {18--42},
	number = {4},
	journaltitle = {{IEEE} Signal Processing Magazine},
	shortjournal = {{IEEE} Signal Process. Mag.},
	author = {Bronstein, Michael M. and Bruna, Joan and {LeCun}, Yann and Szlam, Arthur and Vandergheynst, Pierre},
	urldate = {2019-06-16},
	date = {2017-07},
	eprinttype = {arxiv},
	eprint = {1611.08097},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{henaff_deep_2015,
	title = {Deep Convolutional Networks on Graph-Structured Data},
	url = {http://arxiv.org/abs/1506.05163},
	abstract = {Deep Learning's recent successes have mostly relied on Convolutional Networks, which exploit fundamental statistical properties of images, sounds and video data: the local stationarity and multi-scale compositional structure, that allows expressing long range interactions in terms of shorter, localized interactions. However, there exist other important examples, such as text documents or bioinformatic data, that may lack some or all of these strong statistical regularities. In this paper we consider the general question of how to construct deep architectures with small learning complexity on general non-Euclidean domains, which are typically unknown and need to be estimated from the data. In particular, we develop an extension of Spectral Networks which incorporates a Graph Estimation procedure, that we test on large-scale classification problems, matching or improving over Dropout Networks with far less parameters to estimate.},
	journaltitle = {{arXiv}:1506.05163 [cs]},
	author = {Henaff, Mikael and Bruna, Joan and {LeCun}, Yann},
	urldate = {2019-06-16},
	date = {2015-06-16},
	eprinttype = {arxiv},
	eprint = {1506.05163},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing}
}

@article{boscaini_learning_2016,
	title = {Learning shape correspondence with anisotropic convolutional neural networks},
	url = {http://arxiv.org/abs/1605.06437},
	abstract = {Establishing correspondence between shapes is a fundamental problem in geometry processing, arising in a wide variety of applications. The problem is especially difficult in the setting of non-isometric deformations, as well as in the presence of topological noise and missing parts, mainly due to the limited capability to model such deformations axiomatically. Several recent works showed that invariance to complex shape transformations can be learned from examples. In this paper, we introduce an intrinsic convolutional neural network architecture based on anisotropic diffusion kernels, which we term Anisotropic Convolutional Neural Network ({ACNN}). In our construction, we generalize convolutions to non-Euclidean domains by constructing a set of oriented anisotropic diffusion kernels, creating in this way a local intrinsic polar representation of the data (`patch'), which is then correlated with a filter. Several cascades of such filters, linear, and non-linear operators are stacked to form a deep neural network whose parameters are learned by minimizing a task-specific cost. We use {ACNNs} to effectively learn intrinsic dense correspondences between deformable shapes in very challenging settings, achieving state-of-the-art results on some of the most difficult recent correspondence benchmarks.},
	journaltitle = {{arXiv}:1605.06437 [cs]},
	author = {Boscaini, Davide and Masci, Jonathan and Rodolà, Emanuele and Bronstein, Michael M.},
	urldate = {2019-06-16},
	date = {2016-05-20},
	eprinttype = {arxiv},
	eprint = {1605.06437},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{masci_geodesic_2015,
	title = {Geodesic convolutional neural networks on Riemannian manifolds},
	url = {http://arxiv.org/abs/1501.06297},
	abstract = {Feature descriptors play a crucial role in a wide range of geometry analysis and processing applications, including shape correspondence, retrieval, and segmentation. In this paper, we introduce Geodesic Convolutional Neural Networks ({GCNN}), a generalization of the convolutional networks ({CNN}) paradigm to non-Euclidean manifolds. Our construction is based on a local geodesic system of polar coordinates to extract "patches", which are then passed through a cascade of filters and linear and non-linear operators. The coefficients of the filters and linear combination weights are optimization variables that are learned to minimize a task-specific cost function. We use {GCNN} to learn invariant shape features, allowing to achieve state-of-the-art performance in problems such as shape description, retrieval, and correspondence.},
	journaltitle = {{arXiv}:1501.06297 [cs]},
	author = {Masci, Jonathan and Boscaini, Davide and Bronstein, Michael M. and Vandergheynst, Pierre},
	urldate = {2019-06-16},
	date = {2015-01-26},
	eprinttype = {arxiv},
	eprint = {1501.06297},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{kipf_semi-supervised_2016,
	title = {Semi-Supervised Classification with Graph Convolutional Networks},
	url = {http://arxiv.org/abs/1609.02907},
	abstract = {We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.},
	journaltitle = {{arXiv}:1609.02907 [cs, stat]},
	author = {Kipf, Thomas N. and Welling, Max},
	urldate = {2019-06-16},
	date = {2016-09-09},
	eprinttype = {arxiv},
	eprint = {1609.02907},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@incollection{ferrari_saliency_2018,
	location = {Cham},
	title = {Saliency Detection in 360\$\${\textasciicircum}{\textbackslash}circ \$\$∘ Videos},
	volume = {11211},
	isbn = {978-3-030-01233-5 978-3-030-01234-2},
	url = {http://link.springer.com/10.1007/978-3-030-01234-2_30},
	abstract = {This paper presents a novel spherical convolutional neural network based scheme for saliency detection for 360◦ videos. Speciﬁcally, in our spherical convolution neural network deﬁnition, kernel is deﬁned on a spherical crown, and the convolution involves the rotation of the kernel along the sphere. Considering that the 360◦ videos are usually stored with equirectangular panorama, we propose to implement the spherical convolution on panorama by stretching and rotating the kernel based on the location of patch to be convolved. Compared with existing spherical convolution, our deﬁnition has the parameter sharing property, which would greatly reduce the parameters to be learned. We further take the temporal coherence of the viewing process into consideration, and propose a sequential saliency detection by leveraging a spherical U-Net. To validate our approach, we construct a large-scale 360◦ videos saliency detection benchmark that consists of 104 360◦ videos viewed by 20+ human subjects. Comprehensive experiments validate the effectiveness of our spherical U-net for 360◦ video saliency detection.},
	pages = {504--520},
	booktitle = {Computer Vision – {ECCV} 2018},
	publisher = {Springer International Publishing},
	author = {Zhang, Ziheng and Xu, Yanyu and Yu, Jingyi and Gao, Shenghua},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	urldate = {2019-06-15},
	date = {2018},
	langid = {english},
	doi = {10.1007/978-3-030-01234-2_30}
}

@article{su_kernel_nodate,
	title = {Kernel Transformer Networks for Compact Spherical Convolution},
	abstract = {Ideally, 360◦ imagery could inherit the deep convolutional neural networks ({CNNs}) already trained with great success on perspective projection images. However, existing methods to transfer {CNNs} from perspective to spherical images introduce signiﬁcant computational costs and/or degradations in accuracy. We present the Kernel Transformer Network ({KTN}) to efﬁciently transfer convolution kernels from perspective images to the equirectangular projection of 360◦ images. Given a source {CNN} for perspective images as input, the {KTN} produces a function parameterized by a polar angle and kernel as output. Given a novel 360◦ image, that function in turn can compute convolutions for arbitrary layers and kernels as would the source {CNN} on the corresponding tangent plane projections. Distinct from all existing methods, {KTNs} allow model transfer: the same model can be applied to different source {CNNs} with the same base architecture. This enables application to multiple recognition tasks without re-training the {KTN}. Validating our approach with multiple source {CNNs} and datasets, we show that {KTNs} improve the state of the art for spherical convolution. {KTNs} successfully preserve the source {CNN}’s accuracy, while offering transferability, scalability to typical image resolutions, and, in many cases, a substantially lower memory footprint1.},
	pages = {10},
	author = {Su, Yu-Chuan and Grauman, Kristen},
	langid = {english}
}

@inproceedings{fakour-sevom_360_2018,
	location = {Funchal, Madeira, Portugal},
	title = {360 Panorama Super-resolution using Deep Convolutional Networks:},
	isbn = {978-989-758-290-5},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006618901590165},
	doi = {10.5220/0006618901590165},
	shorttitle = {360 Panorama Super-resolution using Deep Convolutional Networks},
	abstract = {Super-resolution, Virtual Reality, Equirectangular Panorama, Deep Convolutional Neural Network.},
	eventtitle = {International Conference on Computer Vision Theory and Applications},
	pages = {159--165},
	booktitle = {Proceedings of the 13th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
	publisher = {{SCITEPRESS} - Science and Technology Publications},
	author = {Fakour-Sevom, Vida and Guldogan, Esin and Kämäräinen, Joni-Kristian},
	urldate = {2019-06-15},
	date = {2018},
	langid = {english}
}

@inproceedings{zhao_distortion-aware_2018,
	location = {Stockholm, Sweden},
	title = {Distortion-aware {CNNs} for Spherical Images},
	isbn = {978-0-9992411-2-7},
	url = {https://www.ijcai.org/proceedings/2018/167},
	doi = {10.24963/ijcai.2018/167},
	abstract = {Convolutional neural networks are widely used in computer vision applications. Although they have achieved great success, these networks can not be applied to 360◦ spherical images directly due to varying distortion effect. In this paper, we present distortion-aware convolutional network for spherical images. For each pixel, our network samples a non-regular grid based on its distortion level, and convolves the sampled grid using square kernels shared by all pixels. The network successively approximates large image patches from different tangent planes of viewing sphere with small local sampling grids, thus improves the computational efﬁciency. Our method also deals with the boundary problem, which is an inherent issue for spherical images. To evaluate our method, we apply our network in spherical image classiﬁcation problems based on transformed {MNIST} and {CIFAR}-10 datasets. Compared with the baseline method, our method can get much better performance. We also analyze the variants of our network.},
	eventtitle = {Twenty-Seventh International Joint Conference on Artificial Intelligence \{{IJCAI}-18\}},
	pages = {1198--1204},
	booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Zhao, Qiang and Zhu, Chen and Dai, Feng and Ma, Yike and Jin, Guoqing and Zhang, Yongdong},
	urldate = {2019-06-15},
	date = {2018-07},
	langid = {english}
}

@incollection{ferrari_distortion-aware_2018,
	location = {Cham},
	title = {Distortion-Aware Convolutional Filters for Dense Prediction in Panoramic Images},
	volume = {11220},
	isbn = {978-3-030-01269-4 978-3-030-01270-0},
	url = {http://link.springer.com/10.1007/978-3-030-01270-0_43},
	abstract = {There is a high demand of 3D data for 360◦ panoramic images and videos, pushed by the growing availability on the market of specialized hardware for both capturing (e.g., omni-directional cameras) as well as visualizing in 3D (e.g., head mounted displays) panoramic images and videos. At the same time, 3D sensors able to capture 3D panoramic data are expensive and/or hardly available. To ﬁll this gap, we propose a learning approach for panoramic depth map estimation from a single image. Thanks to a speciﬁcally developed distortion-aware deformable convolution ﬁlter, our method can be trained by means of conventional perspective images, then used to regress depth for panoramic images, thus bypassing the effort needed to create annotated panoramic training dataset. We also demonstrate our approach for emerging tasks such as panoramic monocular {SLAM}, panoramic semantic segmentation and panoramic style transfer.},
	pages = {732--750},
	booktitle = {Computer Vision – {ECCV} 2018},
	publisher = {Springer International Publishing},
	author = {Tateno, Keisuke and Navab, Nassir and Tombari, Federico},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	urldate = {2019-06-15},
	date = {2018},
	langid = {english},
	doi = {10.1007/978-3-030-01270-0_43}
}

@article{feng_discriminative_2018,
	title = {Discriminative analysis of the human cortex using spherical {CNNs} - a study on Alzheimer's disease diagnosis},
	url = {http://arxiv.org/abs/1812.07749},
	abstract = {In neuroimaging studies, the human cortex is commonly modeled as a sphere to preserve the topological structure of the cortical surface. Cortical neuroimaging measures hence can be modeled in spherical representation. In this work, we explore analyzing the human cortex using spherical {CNNs} in an Alzheimer's disease ({AD}) classification task using cortical morphometric measures derived from structural {MRI}. Our results show superior performance in classifying {AD} versus cognitively normal and in predicting {MCI} progression within two years, using structural {MRI} information only. This work demonstrates for the first time the potential of the spherical {CNNs} framework in the discriminative analysis of the human cortex and could be extended to other modalities and other neurological diseases.},
	journaltitle = {{arXiv}:1812.07749 [cs]},
	author = {Feng, Xinyang and Yang, Jie and Laine, Andrew F. and Angelini, Elsa D.},
	urldate = {2019-06-15},
	date = {2018-12-18},
	eprinttype = {arxiv},
	eprint = {1812.07749},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@incollection{chang_structure-aware_2018,
	title = {Structure-Aware Convolutional Neural Networks},
	url = {http://papers.nips.cc/paper/7287-structure-aware-convolutional-neural-networks.pdf},
	pages = {11--20},
	booktitle = {Advances in Neural Information Processing Systems 31},
	publisher = {Curran Associates, Inc.},
	author = {Chang, Jianlong and Gu, Jie and Wang, Lingfeng and {MENG}, {GAOFENG} and {XIANG}, {SHIMING} and Pan, Chunhong},
	editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
	urldate = {2019-06-15},
	date = {2018}
}

@article{khasanova_geometry_nodate,
	title = {Geometry Aware Convolutional Filters for Omnidirectional Images Representation},
	abstract = {Due to their wide ﬁeld of view, omnidirectional cameras are frequently used by autonomous vehicles, drones and robots for navigation and other computer vision tasks. The images captured by such cameras, are often analyzed and classiﬁed with techniques designed for planar images that unfortunately fail to properly handle the native geometry of such images and therefore results in suboptimal performance. In this paper we aim at improving popular deep convolutional neural networks so that they can properly take into account the speciﬁc properties of omnidirectional data. In particular we propose an algorithm that adapts convolutional layers, which often serve as a core building block of a {CNN}, to the properties of omnidirectional images. Thus, our ﬁlters adapt their shape and size to the location on the omnidirectional image. We show that our method is not limited to spherical surfaces and is able to incorporate the knowledge about any kind of projective geometry inside the deep learning network. As depicted by our experiments, our method outperforms the existing deep neural network techniques for omnidirectional image classiﬁcation and compression tasks.},
	pages = {9},
	author = {Khasanova, Renata and Frossard, Pascal},
	langid = {english}
}

@article{krachmalnicoff_convolutional_2019,
	title = {Convolutional Neural Networks on the {HEALPix} sphere: a pixel-based algorithm and its application to {CMB} data analysis},
	url = {http://arxiv.org/abs/1902.04083},
	shorttitle = {Convolutional Neural Networks on the {HEALPix} sphere},
	abstract = {We describe a novel method for the application of Convolutional Neural Networks ({CNNs}) to fields defined on the sphere, using the {HEALPix} tessellation scheme. Specifically, We have developed a pixel-based approach to implement convolutional layers on the spherical surface, similarly to what is commonly done for {CNNs} in Euclidian space. The algorithm is fully integrable with existing libraries for {NNs} (e.g., {PyTorch} or {TensorFlow}). We present two applications: (i) recognition of handwritten digits projected on the sphere; (ii) estimation of cosmological parameter from Cosmic Microwave Background ({CMB}) simulated maps. We have built a simple {NN} architecture, consisting in four convolutional+pooling layers, and have used it for all the applications explored herein. For what concerns the handwritten digits, our {CNN} reaches an accuracy of about 95\%, comparable with other existing spherical {CNNs}. For {CMB} applications, we have tested the {CNN} on the estimation of a "mock" parameter, defining the angular scale at which the power spectrum of a Gaussian field projected on the sphere peaks. We have estimated this parameter directly from maps, in several cases: temperature and polarization, presence of noise and partial sky coverage. In all the cases, the {NN} performances are comparable with those from standard spectrum-based bayesian methods. We demonstrate, for the first time, the capability of {CNNs} to extract information from polarization fields and to distinguish between E and B-modes. Lastly, we have applied our {CNN} to the estimation of the Thomson scattering optical depth at reionization (tau) from simulated {CMB} maps. Even without any specific optimization of the {NN} architecture, we reach an accuracy comparable with standard bayesian methods. This work represents a first step towards the exploitation of {NNs} in {CMB} parameter estimation and demonstrates the feasibility of our approach.},
	journaltitle = {{arXiv}:1902.04083 [astro-ph]},
	author = {Krachmalnicoff, Nicoletta and Tomasi, Maurizio},
	urldate = {2019-06-15},
	date = {2019-02-11},
	eprinttype = {arxiv},
	eprint = {1902.04083},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics}
}

@article{worrall_cubenet:_2018,
	title = {{CubeNet}: Equivariance to 3D Rotation and Translation},
	url = {http://arxiv.org/abs/1804.04458},
	shorttitle = {{CubeNet}},
	abstract = {3D Convolutional Neural Networks are sensitive to transformations applied to their input. This is a problem because a voxelized version of a 3D object, and its rotated clone, will look unrelated to each other after passing through to the last layer of a network. Instead, an idealized model would preserve a meaningful representation of the voxelized object, while explaining the pose-difference between the two inputs. An equivariant representation vector has two components: the invariant identity part, and a discernable encoding of the transformation. Models that can't explain pose-differences risk "diluting" the representation, in pursuit of optimizing a classification or regression loss function. We introduce a Group Convolutional Neural Network with linear equivariance to translations and right angle rotations in three dimensions. We call this network {CubeNet}, reflecting its cube-like symmetry. By construction, this network helps preserve a 3D shape's global and local signature, as it is transformed through successive layers. We apply this network to a variety of 3D inference problems, achieving state-of-the-art on the {ModelNet}10 classification challenge, and comparable performance on the {ISBI} 2012 Connectome Segmentation Benchmark. To the best of our knowledge, this is the first 3D rotation equivariant {CNN} for voxel representations.},
	journaltitle = {{arXiv}:1804.04458 [cs, stat]},
	author = {Worrall, Daniel and Brostow, Gabriel},
	urldate = {2019-06-15},
	date = {2018-04-12},
	eprinttype = {arxiv},
	eprint = {1804.04458},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{lenssen_group_2018,
	title = {Group Equivariant Capsule Networks},
	url = {http://arxiv.org/abs/1806.05086},
	abstract = {We present group equivariant capsule networks, a framework to introduce guaranteed equivariance and invariance properties to the capsule network idea. Our work can be divided into two contributions. First, we present a generic routing by agreement algorithm defined on elements of a group and prove that equivariance of output pose vectors, as well as invariance of output activations, hold under certain conditions. Second, we connect the resulting equivariant capsule networks with work from the field of group convolutional networks. Through this connection, we provide intuitions of how both methods relate and are able to combine the strengths of both approaches in one deep neural network architecture. The resulting framework allows sparse evaluation of the group convolution operator, provides control over specific equivariance and invariance properties, and can use routing by agreement instead of pooling operations. In addition, it is able to provide interpretable and equivariant representation vectors as output capsules, which disentangle evidence of object existence from its pose.},
	journaltitle = {{arXiv}:1806.05086 [cs]},
	author = {Lenssen, Jan Eric and Fey, Matthias and Libuschewski, Pascal},
	urldate = {2019-06-15},
	date = {2018-06-13},
	eprinttype = {arxiv},
	eprint = {1806.05086},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{chidester_rotation_2018,
	title = {Rotation Equivariance and Invariance in Convolutional Neural Networks},
	url = {http://arxiv.org/abs/1805.12301},
	abstract = {Performance of neural networks can be significantly improved by encoding known invariance for particular tasks. Many image classification tasks, such as those related to cellular imaging, exhibit invariance to rotation. We present a novel scheme using the magnitude response of the 2D-discrete-Fourier transform (2D-{DFT}) to encode rotational invariance in neural networks, along with a new, efficient convolutional scheme for encoding rotational equivariance throughout convolutional layers. We implemented this scheme for several image classification tasks and demonstrated improved performance, in terms of classification accuracy, time required to train the model, and robustness to hyperparameter selection, over a standard {CNN} and another state-of-the-art method.},
	journaltitle = {{arXiv}:1805.12301 [cs, stat]},
	author = {Chidester, Benjamin and Do, Minh N. and Ma, Jian},
	urldate = {2019-06-15},
	date = {2018-05-30},
	eprinttype = {arxiv},
	eprint = {1805.12301},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{mcewen_novel_2011,
	title = {A novel sampling theorem on the sphere},
	volume = {59},
	issn = {1053-587X, 1941-0476},
	url = {http://arxiv.org/abs/1110.6298},
	doi = {10.1109/TSP.2011.2166394},
	abstract = {We develop a novel sampling theorem on the sphere and corresponding fast algorithms by associating the sphere with the torus through a periodic extension. The fundamental property of any sampling theorem is the number of samples required to represent a band-limited signal. To represent exactly a signal on the sphere band-limited at L, all sampling theorems on the sphere require O(L{\textasciicircum}2) samples. However, our sampling theorem requires less than half the number of samples of other equiangular sampling theorems on the sphere and an asymptotically identical, but smaller, number of samples than the Gauss-Legendre sampling theorem. The complexity of our algorithms scale as O(L{\textasciicircum}3), however, the continual use of fast Fourier transforms reduces the constant prefactor associated with the asymptotic scaling considerably, resulting in algorithms that are fast. Furthermore, we do not require any precomputation and our algorithms apply to both scalar and spin functions on the sphere without any change in computational complexity or computation time. We make our implementation of these algorithms available publicly and perform numerical experiments demonstrating their speed and accuracy up to very high band-limits. Finally, we highlight the advantages of our sampling theorem in the context of potential applications, notably in the field of compressive sampling.},
	pages = {5876--5887},
	number = {12},
	journaltitle = {{IEEE} Transactions on Signal Processing},
	shortjournal = {{IEEE} Trans. Signal Process.},
	author = {{McEwen}, J. D. and Wiaux, Y.},
	urldate = {2019-06-14},
	date = {2011-12},
	eprinttype = {arxiv},
	eprint = {1110.6298},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics, Computer Science - Information Theory}
}

@article{gorski_healpix_2005,
	title = {{HEALPix} -- a Framework for High Resolution Discretization, and Fast Analysis of Data Distributed on the Sphere},
	volume = {622},
	issn = {0004-637X, 1538-4357},
	url = {http://arxiv.org/abs/astro-ph/0409513},
	doi = {10.1086/427976},
	abstract = {{HEALPix} -- the Hierarchical Equal Area iso-Latitude Pixelization -- is a versatile data structure with an associated library of computational algorithms and visualization software that supports fast scientific applications executable directly on very large volumes of astronomical data and large area surveys in the form of discretized spherical maps. Originally developed to address the data processing and analysis needs of the present generation of cosmic microwave background ({CMB}) experiments (e.g. {BOOMERanG}, {WMAP}), {HEALPix} can be expanded to meet many of the profound challenges that will arise in confrontation with the observational output of future missions and experiments, including e.g. Planck, Herschel, {SAFIR}, and the Beyond Einstein {CMB} polarization probe. In this paper we consider the requirements and constraints to be met in order to implement a sufficient framework for the efficient discretization and fast analysis/synthesis of functions defined on the sphere, and summarise how they are satisfied by {HEALPix}.},
	pages = {759--771},
	number = {2},
	journaltitle = {The Astrophysical Journal},
	shortjournal = {{ApJ}},
	author = {Gorski, K. M. and Hivon, E. and Banday, A. J. and Wandelt, B. D. and Hansen, F. K. and Reinecke, M. and Bartelman, M.},
	urldate = {2019-06-13},
	date = {2005-04},
	eprinttype = {arxiv},
	eprint = {astro-ph/0409513},
	keywords = {Astrophysics}
}

@article{baumgardner_icosahedral_1985,
	title = {Icosahedral Discretization of the Two-Sphere},
	volume = {22},
	issn = {0036-1429, 1095-7170},
	url = {http://epubs.siam.org/doi/10.1137/0722066},
	doi = {10.1137/0722066},
	abstract = {We present an almost uniform triangulation of the two-sphere, derived from the icosahedron, and describe a procedure for discretization of a partial differential equation using this triangular grid. The accuracy of our procedure is described by a strong theoretical estimate, and verified by large-scale numerical experiments. We also describe a data structure for this spherical discretization that allows fast computation on either a vector computer or an asynchronous parallel computer.},
	pages = {1107--1115},
	number = {6},
	journaltitle = {{SIAM} Journal on Numerical Analysis},
	shortjournal = {{SIAM} J. Numer. Anal.},
	author = {Baumgardner, John R. and Frederickson, Paul O.},
	urldate = {2019-06-13},
	date = {1985-12},
	langid = {english}
}

@incollection{kondor_clebsch_2018,
	title = {Clebsch– Gordan Nets: a Fully Fourier Space Spherical Convolutional Neural Network},
	url = {http://papers.nips.cc/paper/8215-clebschgordan-nets-a-fully-fourier-space-spherical-convolutional-neural-network.pdf},
	shorttitle = {Clebsch– Gordan Nets},
	pages = {10117--10126},
	booktitle = {Advances in Neural Information Processing Systems 31},
	publisher = {Curran Associates, Inc.},
	author = {Kondor, Risi and Lin, Zhen and Trivedi, Shubhendu},
	editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
	urldate = {2019-06-12},
	date = {2018}
}

@article{neale_description_nodate,
	title = {Description of the {NCAR} Community Atmosphere Model ({CAM} 5.0)},
	pages = {289},
	author = {Neale, Richard B and Gettelman, Andrew and Park, Sungsu and Chen, Chih-Chieh and Lauritzen, Peter H and Williamson, David L and Conley, Andrew J and Kinnison, Doug and Marsh, Dan and Smith, Anne K and Vitt, Francis and Garcia, Rolando and Lamarque, Jean-Francois and Mills, Mike and Tilmes, Simone and Morrison, Hugh and Cameron-Smith, Philip and Collins, William D and Iacono, Michael J and Easter, Richard C and Liu, Xiaohong and Ghan, Steven J and Rasch, Philip J and Taylor, Mark A},
	langid = {english}
}

@inproceedings{zhirong_wu_3d_2015,
	location = {Boston, {MA}, {USA}},
	title = {3D {ShapeNets}: A deep representation for volumetric shapes},
	isbn = {978-1-4673-6964-0},
	url = {http://ieeexplore.ieee.org/document/7298801/},
	doi = {10.1109/CVPR.2015.7298801},
	shorttitle = {3D {ShapeNets}},
	eventtitle = {2015 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	pages = {1912--1920},
	booktitle = {2015 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	publisher = {{IEEE}},
	author = {{Zhirong Wu} and Song, Shuran and Khosla, Aditya and {Fisher Yu} and {Linguang Zhang} and {Xiaoou Tang} and Xiao, Jianxiong},
	urldate = {2019-06-06},
	date = {2015-06},
	langid = {english}
}

@incollection{racah_extremeweather:_2017,
	title = {{ExtremeWeather}: A large-scale climate dataset for semi-supervised detection, localization, and understanding of extreme weather events},
	url = {http://papers.nips.cc/paper/6932-extremeweather-a-large-scale-climate-dataset-for-semi-supervised-detection-localization-and-understanding-of-extreme-weather-events.pdf},
	shorttitle = {{ExtremeWeather}},
	pages = {3402--3413},
	booktitle = {Advances in Neural Information Processing Systems 30},
	publisher = {Curran Associates, Inc.},
	author = {Racah, Evan and Beckham, Christopher and Maharaj, Tegan and Ebrahimi Kahou, Samira and Prabhat, Mr. and Pal, Chris},
	editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	urldate = {2019-06-06},
	date = {2017}
}

@article{ronneberger_u-net:_2015,
	title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	url = {http://arxiv.org/abs/1505.04597},
	shorttitle = {U-Net},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the {ISBI} challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and {DIC}) we won the {ISBI} cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent {GPU}. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	journaltitle = {{arXiv}:1505.04597 [cs]},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	urldate = {2019-06-04},
	date = {2015-05-18},
	eprinttype = {arxiv},
	eprint = {1505.04597},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@online{noauthor_global_nodate,
	title = {Global Historical Climate Network Daily - Description {\textbar} National Centers for Environmental Information ({NCEI}) formerly known as National Climatic Data Center ({NCDC})},
	url = {https://www.ncdc.noaa.gov/ghcn-daily-description},
	urldate = {2019-06-04}
}

@online{noauthor_computations_2019,
	title = {Computations involving Lie groups and harmonic analysis: {AMLab}-Amsterdam/lie\_learn},
	url = {https://github.com/AMLab-Amsterdam/lie_learn},
	shorttitle = {Computations involving Lie groups and harmonic analysis},
	urldate = {2019-02-19},
	date = {2019-01-06},
	note = {original-date: 2017-03-13T13:20:21Z},
	keywords = {{DiffTypeGrid}}
}

@article{wehner_resolution_2015,
	title = {Resolution Dependence of Future Tropical Cyclone Projections of {CAM}5.1 in the U.S. {CLIVAR} Hurricane Working Group Idealized Configurations},
	volume = {28},
	issn = {0894-8755},
	url = {https://journals.ametsoc.org/doi/full/10.1175/JCLI-D-14-00311.1},
	doi = {10.1175/JCLI-D-14-00311.1},
	abstract = {The four idealized configurations of the U.S. {CLIVAR} Hurricane Working Group are integrated using the global Community Atmospheric Model version 5.1 at two different horizontal resolutions, approximately 100 and 25 km. The publicly released 0.9 × 1.3 configuration is a poor predictor of the sign of the 0.23 × 0.31 model configuration’s change in the total number of tropical storms in a warmer climate. However, it does predict the sign of the higher-resolution configuration’s change in the number of intense tropical cyclones in a warmer climate. In the 0.23 × 0.31 model configuration, both increased {CO}2 concentrations and elevated sea surface temperature ({SST}) independently lower the number of weak tropical storms and shorten their average duration. Conversely, increased {SST} causes more intense tropical cyclones and lengthens their average duration, resulting in a greater number of intense tropical cyclone days globally. Increased {SST} also increased maximum tropical storm instantaneous precipitation rates across all storm intensities. It was found that while a measure of maximum potential intensity based on climatological mean quantities adequately predicts the 0.23 × 0.31 model’s forced response in its most intense simulated tropical cyclones, a related measure of cyclogenesis potential fails to predict the model’s actual cyclogenesis response to warmer {SSTs}. These analyses lead to two broader conclusions: 1) Projections of future tropical storm activity obtained by a direct tracking of tropical storms simulated by coarse-resolution climate models must be interpreted with caution. 2) Projections of future tropical cyclogenesis obtained from metrics of model behavior that are based solely on changes in long-term climatological fields and tuned to historical records must also be interpreted with caution.},
	pages = {3905--3925},
	number = {10},
	journaltitle = {Journal of Climate},
	shortjournal = {J. Climate},
	author = {Wehner, Michael and {Prabhat} and Reed, Kevin A. and Stone, Dáithí and Collins, William D. and Bacmeister, Julio},
	urldate = {2019-05-27},
	date = {2015-02-12}
}

@article{su_pano2vid:_nodate,
	title = {Pano2Vid: Automatic cinematography for watching 360 videos},
	abstract = {We introduce the novel task of Pano2Vid — automatic cinematography in panoramic 360◦ videos. Given a 360◦ video, the goal is to direct an imaginary camera to virtually capture natural-looking normal ﬁeld-of-view ({NFOV}) video. By selecting “where to look” within the panorama at each time step, Pano2Vid aims to free both the videographer and the end viewer from the task of determining what to watch. Towards this goal, we ﬁrst compile a dataset of 360◦ videos downloaded from the web, together with human-edited {NFOV} camera trajectories to facilitate evaluation. Next, we propose {AutoCam}, a data-driven approach to solve the Pano2Vid task. {AutoCam} leverages {NFOV} web video to discriminatively identify space-time “glimpses” of interest at each time instant, and then uses dynamic programming to select optimal humanlike camera trajectories. Through experimental evaluation on multiple newly deﬁned Pano2Vid performance measures against several baselines, we show that our method successfully produces informative videos that could conceivably have been captured by human videographers.},
	pages = {16},
	author = {Su, Yu-Chuan and Jayaraman, Dinesh and Grauman, Kristen},
	langid = {english}
}

@incollection{su_learning_2017,
	title = {Learning Spherical Convolution for Fast Features from 360 Imagery},
	url = {http://papers.nips.cc/paper/6656-learning-spherical-convolution-for-fast-features-from-360-imagery.pdf},
	pages = {529--539},
	booktitle = {Advances in Neural Information Processing Systems 30},
	publisher = {Curran Associates, Inc.},
	author = {Su, Yu-Chuan and Grauman, Kristen},
	editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	urldate = {2019-04-12},
	date = {2017}
}

@article{cohen_group_2016,
	title = {Group Equivariant Convolutional Networks},
	url = {http://arxiv.org/abs/1602.07576},
	abstract = {We introduce Group equivariant Convolutional Neural Networks (G-{CNNs}), a natural generalization of convolutional neural networks that reduces sample complexity by exploiting symmetries. G-{CNNs} use G-convolutions, a new type of layer that enjoys a substantially higher degree of weight sharing than regular convolution layers. G-convolutions increase the expressive capacity of the network without increasing the number of parameters. Group convolution layers are easy to use and can be implemented with negligible computational overhead for discrete groups generated by translations, reflections and rotations. G-{CNNs} achieve state of the art results on {CIFAR}10 and rotated {MNIST}.},
	journaltitle = {{arXiv}:1602.07576 [cs, stat]},
	author = {Cohen, Taco S. and Welling, Max},
	urldate = {2019-06-04},
	date = {2016-02-24},
	eprinttype = {arxiv},
	eprint = {1602.07576},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{monti_geometric_2016,
	title = {Geometric deep learning on graphs and manifolds using mixture model {CNNs}},
	url = {http://arxiv.org/abs/1611.08402},
	abstract = {Deep learning has achieved a remarkable performance breakthrough in several fields, most notably in speech recognition, natural language processing, and computer vision. In particular, convolutional neural network ({CNN}) architectures currently produce state-of-the-art performance on a variety of image analysis tasks such as object detection and recognition. Most of deep learning research has so far focused on dealing with 1D, 2D, or 3D Euclidean-structured data such as acoustic signals, images, or videos. Recently, there has been an increasing interest in geometric deep learning, attempting to generalize deep learning methods to non-Euclidean structured data such as graphs and manifolds, with a variety of applications from the domains of network analysis, computational social science, or computer graphics. In this paper, we propose a unified framework allowing to generalize {CNN} architectures to non-Euclidean domains (graphs and manifolds) and learn local, stationary, and compositional task-specific features. We show that various non-Euclidean {CNN} methods previously proposed in the literature can be considered as particular instances of our framework. We test the proposed method on standard tasks from the realms of image-, graph- and 3D shape analysis and show that it consistently outperforms previous approaches.},
	journaltitle = {{arXiv}:1611.08402 [cs]},
	author = {Monti, Federico and Boscaini, Davide and Masci, Jonathan and Rodolà, Emanuele and Svoboda, Jan and Bronstein, Michael M.},
	urldate = {2019-06-03},
	date = {2016-11-25},
	eprinttype = {arxiv},
	eprint = {1611.08402},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{lee_spherephd:_2018,
	title = {{SpherePHD}: Applying {CNNs} on a Spherical {PolyHeDron} Representation of 360 degree Images},
	url = {http://arxiv.org/abs/1811.08196},
	shorttitle = {{SpherePHD}},
	abstract = {Omni-directional cameras have many advantages overconventional cameras in that they have a much wider field-of-view ({FOV}). Accordingly, several approaches have beenproposed recently to apply convolutional neural networks({CNNs}) to omni-directional images for various visual tasks.However, most of them use image representations defined inthe Euclidean space after transforming the omni-directionalviews originally formed in the non-Euclidean space. Thistransformation leads to shape distortion due to nonuniformspatial resolving power and the loss of continuity. Theseeffects make existing convolution kernels experience diffi-culties in extracting meaningful information.This paper presents a novel method to resolve such prob-lems of applying {CNNs} to omni-directional images. Theproposed method utilizes a spherical polyhedron to rep-resent omni-directional views. This method minimizes thevariance of the spatial resolving power on the sphere sur-face, and includes new convolution and pooling methodsfor the proposed representation. The proposed method canalso be adopted by any existing {CNN}-based methods. Thefeasibility of the proposed method is demonstrated throughclassification, detection, and semantic segmentation taskswith synthetic and real datasets.},
	journaltitle = {{arXiv}:1811.08196 [cs]},
	author = {Lee, Yeonkun and Jeong, Jaeseok and Yun, Jongseob and Cho, Wonjune and Yoon, Kuk-Jin},
	urldate = {2019-05-27},
	date = {2018-11-20},
	eprinttype = {arxiv},
	eprint = {1811.08196},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@incollection{ferrari_spherenet:_2018,
	location = {Cham},
	title = {{SphereNet}: Learning Spherical Representations for Detection and Classification in Omnidirectional Images},
	volume = {11213},
	isbn = {978-3-030-01239-7 978-3-030-01240-3},
	url = {http://link.springer.com/10.1007/978-3-030-01240-3_32},
	shorttitle = {{SphereNet}},
	abstract = {Omnidirectional cameras offer great beneﬁts over classical cameras wherever a wide ﬁeld of view is essential, such as in virtual reality applications or in autonomous robots. Unfortunately, standard convolutional neural networks are not well suited for this scenario as the natural projection surface is a sphere which cannot be unwrapped to a plane without introducing signiﬁcant distortions, particularly in the polar regions. In this work, we present {SphereNet}, a novel deep learning framework which encodes invariance against such distortions explicitly into convolutional neural networks. Towards this goal, {SphereNet} adapts the sampling locations of the convolutional ﬁlters, effectively reversing distortions, and wraps the ﬁlters around the sphere. By building on regular convolutions, {SphereNet} enables the transfer of existing perspective convolutional neural network models to the omnidirectional case. We demonstrate the effectiveness of our method on the tasks of image classiﬁcation and object detection, exploiting two newly created semi-synthetic and real-world omnidirectional datasets.},
	pages = {525--541},
	booktitle = {Computer Vision – {ECCV} 2018},
	publisher = {Springer International Publishing},
	author = {Coors, Benjamin and Condurache, Alexandru Paul and Geiger, Andreas},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	urldate = {2019-05-27},
	date = {2018},
	langid = {english},
	doi = {10.1007/978-3-030-01240-3_32}
}

@online{noauthor_healpix_nodate,
	title = {{HEALPix} - Features},
	url = {https://healpix.sourceforge.io/},
	urldate = {2019-05-27}
}

@article{gimbutas_fast_2013,
	title = {A Fast Algorithm for Spherical Grid Rotations and Its Application to Singular Quadrature},
	volume = {35},
	issn = {1064-8275, 1095-7197},
	url = {http://epubs.siam.org/doi/10.1137/120900587},
	doi = {10.1137/120900587},
	abstract = {We present a fast and accurate algorithm for evaluating singular integral operators on smooth surfaces that are globally parametrized by spherical coordinates. Problems of this type arise, for example, in simulating Stokes ﬂows with particulate suspensions and in multi-particle scattering calculations. For smooth surfaces, spherical harmonic expansions are commonly used for geometry representation and the evaluation of the singular integrals is carried out with a spectrally accurate quadrature rule on a set of rotated spherical grids. We propose a new algorithm that interpolates function values on the rotated spherical grids via hybrid nonuniform {FFTs}. The algorithm has a small complexity constant, and the cost of applying the quadrature rule is nearly-optimal O(p4 log p) for a spherical harmonic expansion of degree p.},
	pages = {A2738--A2751},
	number = {6},
	journaltitle = {{SIAM} Journal on Scientific Computing},
	shortjournal = {{SIAM} J. Sci. Comput.},
	author = {Gimbutas, Zydrunas and Veerapaneni, Shravan},
	urldate = {2019-05-27},
	date = {2013-01},
	langid = {english}
}

@article{keiner_fast_2008,
	title = {Fast evaluation of quadrature formulae on the sphere},
	volume = {77},
	issn = {0025-5718, 1088-6842},
	url = {http://www.ams.org/journal-getitem?pii=S0025-5718-07-02029-7},
	doi = {10.1090/S0025-5718-07-02029-7},
	abstract = {Recently, a fast approximate algorithm for the evaluation of expansions in terms of standard L2 S2 -orthonormal spherical harmonics at arbitrary nodes on the sphere S2 has been proposed in [S. Kunis and D. Potts. Fast spherical Fourier algorithms. J. Comput. Appl. Math., 161:75–98, 2003]. The aim of this paper is to develop a new fast algorithm for the adjoint problem which can be used to compute expansion coeﬃcients from sampled data by means of quadrature rules.},
	pages = {397--419},
	number = {261},
	journaltitle = {Mathematics of Computation},
	shortjournal = {Math. Comp.},
	author = {Keiner, Jens and Potts, Daniel},
	urldate = {2019-05-27},
	date = {2008-01-01},
	langid = {english}
}

@article{driscoll_computing_1994,
	title = {Computing Fourier Transforms and Convolutions on the 2-Sphere},
	volume = {15},
	issn = {0196-8858},
	url = {http://www.sciencedirect.com/science/article/pii/S0196885884710086},
	doi = {10.1006/aama.1994.1008},
	abstract = {This paper considers the problem of efficient computation of the spherical harmonic expansion, or Fourier transform, of functions defined on the two dimensional sphere, S2. The resulting algorithms are applied to the efficient computation of convolutions of functions on the sphere. We begin by proving convolution theorems generalizing well known and useful results from the abelian case. These convolution theorems are then used to develop a sampling theorem on the sphere. which reduces the calculation of Fourier transforms and convolutions of band-limited functions to discrete computations. We show how to perform these efficiently, starting with an O(n(log n)2) time algorithm for computing the Legendre transform of a function defined on the interval [−1,1] sampled at n points there. Theoretical and experimental results on the effects of finite precision arithmetic are presented. The Legendre transform algorithm is then generalized to obtain an algorithm for the Fourier transform, requiring O(n(log n)2) time, and an algorithm for its inverse in O(n1.5) time, where n is the number of points on the sphere at which the function is sampled. This improves the naive O(n2) bound, which is the best previously known. These transforms give an O(n1.5) algorithm for convolving two functions on the sphere.},
	pages = {202--250},
	number = {2},
	journaltitle = {Advances in Applied Mathematics},
	shortjournal = {Advances in Applied Mathematics},
	author = {Driscoll, J. R. and Healy, D. M.},
	urldate = {2019-05-27},
	date = {1994-06-01}
}
@article{racah_extremeweather:_2016,
	title = {{ExtremeWeather}: A large-scale climate dataset for semi-supervised detection, localization, and understanding of extreme weather events},
	url = {http://arxiv.org/abs/1612.02095},
	shorttitle = {{ExtremeWeather}},
	abstract = {Then detection and identification of extreme weather events in large-scale climate simulations is an important problem for risk management, informing governmental policy decisions and advancing our basic understanding of the climate system. Recent work has shown that fully supervised convolutional neural networks ({CNNs}) can yield acceptable accuracy for classifying well-known types of extreme weather events when large amounts of labeled data are available. However, many different types of spatially localized climate patterns are of interest including hurricanes, extra-tropical cyclones, weather fronts, and blocking events among others. Existing labeled data for these patterns can be incomplete in various ways, such as covering only certain years or geographic areas and having false negatives. This type of climate data therefore poses a number of interesting machine learning challenges. We present a multichannel spatiotemporal {CNN} architecture for semi-supervised bounding box prediction and exploratory data analysis. We demonstrate that our approach is able to leverage temporal information and unlabeled data to improve the localization of extreme weather events. Further, we explore the representations learned by our model in order to better understand this important data. We present a dataset, {ExtremeWeather}, to encourage machine learning research in this area and to help facilitate further work in understanding and mitigating the effects of climate change. The dataset is available at extremeweatherdataset.github.io and the code is available at https://github.com/eracah/hur-detect.},
	journaltitle = {{arXiv}:1612.02095 [cs, stat]},
	author = {Racah, Evan and Beckham, Christopher and Maharaj, Tegan and Kahou, Samira Ebrahimi and Prabhat and Pal, Christopher},
	urldate = {2019-05-27},
	date = {2016-12-06},
	eprinttype = {arxiv},
	eprint = {1612.02095},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning}
}

@article{jiang_spherical_2019,
	title = {Spherical {CNNs} on Unstructured Grids},
	url = {http://arxiv.org/abs/1901.02039},
	abstract = {We present an efficient convolution kernel for Convolutional Neural Networks ({CNNs}) on unstructured grids using parameterized differential operators while focusing on spherical signals such as panorama images or planetary signals. To this end, we replace conventional convolution kernels with linear combinations of differential operators that are weighted by learnable parameters. Differential operators can be efficiently estimated on unstructured grids using one-ring neighbors, and learnable parameters can be optimized through standard back-propagation. As a result, we obtain extremely efficient neural networks that match or outperform state-of-the-art network architectures in terms of performance but with a significantly lower number of network parameters. We evaluate our algorithm in an extensive series of experiments on a variety of computer vision and climate science tasks, including shape classification, climate pattern segmentation, and omnidirectional image semantic segmentation. Overall, we present (1) a novel {CNN} approach on unstructured grids using parameterized differential operators for spherical signals, and (2) we show that our unique kernel parameterization allows our model to achieve the same or higher accuracy with significantly fewer network parameters.},
	journaltitle = {{arXiv}:1901.02039 [cs]},
	author = {Jiang, Chiyu "Max" and Huang, Jingwei and Kashinath, Karthik and Prabhat and Marcus, Philip and Niessner, Matthias},
	urldate = {2019-05-25},
	date = {2019-01-07},
	eprinttype = {arxiv},
	eprint = {1901.02039},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning}
}

@article{wang_learning_2019,
	title = {{LEARNING} {GEOMETRIC} {OPERATORS} {ON} {MESHES}},
	abstract = {Applications in computer vision, simulation, and computer-aided design motivate interest in deep learning methods that operate directly on triangle meshes. As an analogy to convolutional ﬁlters on images, these methods successively apply local geometric operators like the Laplacian and the Dirac operator to per-element features; this pipeline can be interpreted as applying a ﬁlter to features written in the operators’ spectral bases. Such a technique is analogous to using convolutional ﬁlters with ﬁxed kernels on images, which severely limits representation capacity. As a ﬂexible alternative, we propose learning geometric operators from data in a task-speciﬁc fashion. Inspired by numerical algorithms operating on irregular domains, our framework learns from meshes using a parametric learnable family of linear operators, generalizing previous architectures.},
	pages = {14},
	author = {Wang, Yu and Kim, Vladimir and Bronstein, Michael M and Solomon, Justin},
	date = {2019},
	langid = {english}
}

@article{hanocka_meshcnn:_2018,
	title = {{MeshCNN}: A Network with an Edge},
	url = {http://arxiv.org/abs/1809.05910},
	shorttitle = {{MeshCNN}},
	abstract = {Polygonal meshes provide an efficient representation for 3D shapes. They explicitly capture both shape surface and topology, and leverage non-uniformity to represent large flat regions as well as sharp, intricate features. This non-uniformity and irregularity, however, inhibits mesh analysis efforts using neural networks that combine convolution and pooling operations. In this paper, we utilize the unique properties of the mesh for a direct analysis of 3D shapes using {MeshCNN}, a convolutional neural network designed specifically for triangular meshes. Analogous to classic {CNNs}, {MeshCNN} combines specialized convolution and pooling layers that operate on the mesh edges, by leveraging their intrinsic geodesic connections. Convolutions are applied on edges and the four edges of their incident triangles, and pooling is applied via an edge collapse operation that retains surface topology, thereby, generating new mesh connectivity for the subsequent convolutions. {MeshCNN} learns which edges to collapse, thus forming a task-driven process where the network exposes and expands the important features while discarding the redundant ones. We demonstrate the effectiveness of our task-driven pooling on various learning tasks applied to 3D meshes.},
	journaltitle = {{arXiv}:1809.05910 [cs, stat]},
	author = {Hanocka, Rana and Hertz, Amir and Fish, Noa and Giryes, Raja and Fleishman, Shachar and Cohen-Or, Daniel},
	urldate = {2019-05-25},
	date = {2018-09-16},
	eprinttype = {arxiv},
	eprint = {1809.05910},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@online{noauthor_meshcnn_nodate,
	title = {{MeshCNN}},
	url = {https://ranahanocka.github.io/MeshCNN/},
	urldate = {2019-05-25}
}

@article{chen_semi-supervised_2019,
	title = {Semi-supervised learning via Feedforward-Designed Convolutional Neural Networks},
	url = {http://arxiv.org/abs/1902.01980},
	abstract = {A semi-supervised learning framework using the feedforward-designed convolutional neural networks ({FF}-{CNNs}) is proposed for image classification in this work. One unique property of {FF}-{CNNs} is that no backpropagation is used in model parameters determination. Since unlabeled data may not always enhance semi-supervised learning, we define an effective quality score and use it to select a subset of unlabeled data in the training process. We conduct experiments on the {MNIST}, {SVHN}, and {CIFAR}-10 datasets, and show that the proposed semi-supervised {FF}-{CNN} solution outperforms the {CNN} trained by backpropagation ({BP}-{CNN}) when the amount of labeled data is reduced. Furthermore, we develop an ensemble system that combines the output decision vectors of different semi-supervised {FF}-{CNNs} to boost classification accuracy. The ensemble systems can achieve further performance gains on all three benchmarking datasets.},
	journaltitle = {{arXiv}:1902.01980 [cs]},
	author = {Chen, Yueru and Yang, Yijing and Zhang, Min and Kuo, C.-C. Jay},
	urldate = {2019-05-21},
	date = {2019-02-05},
	eprinttype = {arxiv},
	eprint = {1902.01980},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{keriven_universal_2019,
	title = {Universal Invariant and Equivariant Graph Neural Networks},
	url = {http://arxiv.org/abs/1905.04943},
	abstract = {Graph Neural Networks ({GNN}) come in many flavors, but should always be either invariant (permutation of the nodes of the input graph does not affect the output) or equivariant (permutation of the input permutes the output). In this paper, we consider a specific class of invariant and equivariant networks, for which we prove new universality theorems. More precisely, we consider networks with a single hidden layer, obtained by summing channels formed by applying an equivariant linear operator, a pointwise non-linearity and either an invariant or equivariant linear operator. Recently, Maron et al. (2019) showed that by allowing higher-order tensorization inside the network, universal invariant {GNNs} can be obtained. As a first contribution, we propose an alternative proof of this result, which relies on the Stone-Weierstrass theorem for algebra of real-valued functions. Our main contribution is then an extension of this result to the equivariant case, which appears in many practical applications but has been less studied from a theoretical point of view. The proof relies on a new generalized Stone-Weierstrass theorem for algebra of equivariant functions, which is of independent interest. Finally, unlike many previous settings that consider a fixed number of nodes, our results show that a {GNN} defined by a single set of parameters can approximate uniformly well a function defined on graphs of varying size.},
	journaltitle = {{arXiv}:1905.04943 [cs, stat]},
	author = {Keriven, Nicolas and Peyré, Gabriel},
	urldate = {2019-05-14},
	date = {2019-05-13},
	eprinttype = {arxiv},
	eprint = {1905.04943},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{saff_distributing_1997,
	title = {Distributing many points on a sphere},
	volume = {19},
	issn = {0343-6993},
	url = {http://link.springer.com/10.1007/BF03024331},
	doi = {10.1007/BF03024331},
	pages = {5--11},
	number = {1},
	journaltitle = {The Mathematical Intelligencer},
	shortjournal = {The Mathematical Intelligencer},
	author = {Saff, E. B. and Kuijlaars, A. B. J.},
	urldate = {2019-04-30},
	date = {1997-12},
	langid = {english}
}

@article{ronchi_cubed_1996,
	title = {The “Cubed Sphere”: A New Method for the Solution of Partial Differential Equations in Spherical Geometry},
	volume = {124},
	issn = {00219991},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0021999196900479},
	doi = {10.1006/jcph.1996.0047},
	shorttitle = {The “Cubed Sphere”},
	pages = {93--114},
	number = {1},
	journaltitle = {Journal of Computational Physics},
	shortjournal = {Journal of Computational Physics},
	author = {Ronchi, C. and Iacono, R. and Paolucci, P.S.},
	urldate = {2019-04-29},
	date = {1996-03},
	langid = {english}
}

@online{noauthor_index_nodate,
	title = {index},
	url = {https://extremeweatherdataset.github.io/},
	urldate = {2019-04-29}
}

@online{noauthor_large_nodate,
	title = {Large Scale Parsing},
	url = {http://buildingparser.stanford.edu/dataset.html},
	urldate = {2019-04-25}
}

@online{noauthor_pano2vid_nodate,
	title = {Pano2Vid},
	url = {http://vision.cs.utexas.edu/projects/Pano2Vid/#Pano2Vid},
	urldate = {2019-04-25}
}

@online{noauthor_testing_nodate,
	title = {Testing data — {HARDI} reconstruction challenge 2013},
	url = {http://hardi.epfl.ch/static/events/2013_ISBI/testing_data.html},
	urldate = {2019-04-25}
}

@article{descoteaux_regularized_2007,
	title = {Regularized, fast, and robust analytical Q-ball imaging},
	volume = {58},
	issn = {1522-2594},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.21277},
	doi = {10.1002/mrm.21277},
	abstract = {We propose a regularized, fast, and robust analytical solution for the Q-ball imaging ({QBI}) reconstruction of the orientation distribution function ({ODF}) together with its detailed validation and a discussion on its benefits over the state-of-the-art. Our analytical solution is achieved by modeling the raw high angular resolution diffusion imaging signal with a spherical harmonic basis that incorporates a regularization term based on the Laplace–Beltrami operator defined on the unit sphere. This leads to an elegant mathematical simplification of the Funk–Radon transform which approximates the {ODF}. We prove a new corollary of the Funk–Hecke theorem to obtain this simplification. Then, we show that the Laplace–Beltrami regularization is theoretically and practically better than Tikhonov regularization. At the cost of slightly reducing angular resolution, the Laplace–Beltrami regularization reduces {ODF} estimation errors and improves fiber detection while reducing angular error in the {ODF} maxima detected. Finally, a careful quantitative validation is performed against ground truth from synthetic data and against real data from a biological phantom and a human brain dataset. We show that our technique is also able to recover known fiber crossings in the human brain and provides the practical advantage of being up to 15 times faster than original numerical {QBI} method. Magn Reson Med 58:497–510, 2007. © 2007 Wiley-Liss, Inc.},
	pages = {497--510},
	number = {3},
	journaltitle = {Magnetic Resonance in Medicine},
	author = {Descoteaux, Maxime and Angelino, Elaine and Fitzgibbons, Shaun and Deriche, Rachid},
	urldate = {2019-04-25},
	date = {2007},
	langid = {english},
	keywords = {Funk Radon transform, Q-ball imaging ({QBI}), diffusion tensor imaging ({DTI}), fiber tractography, high angular resolution diffusion imaging ({HARDI}), orientation distribution function ({ODF}), regularization, spherical harmonic}
}

@article{mudigonda_segmenting_nodate,
	title = {Segmenting and Tracking Extreme Climate Events using Neural Networks},
	abstract = {Predicting extreme weather events in a warming world is one of the most pressing and challenging problems that humanity faces today. Deep learning and advances in the ﬁeld of computer vision provide a novel and powerful set of tools to tackle this demanding task. However, unlike images employed in computer vision, climate datasets present unique challenges. The channels (or physical variables) in a climate dataset are manifold, and unlike pixel information in computer vision data, these channels have physical properties. We present preliminary work using a convolutional neural network and a recurrent neural network for tracking cyclonic storms. We also show how state-of-the-art segmentation algorithms can be used to segment atmospheric rivers and tropical cyclones in global climate model simulations. We show how the latest advances in machine learning and computer vision can provide solutions to important problems in weather and climate sciences, and we highlight unique challenges and limitations.},
	pages = {5},
	author = {Mudigonda, Mayur and Kim, Sookyung and Mahesh, Ankur and Kahou, Samira and Kashinath, Karthik and Williams, Dean and Michalski, Vincent and O’Brien, Travis and Prabhat, Mr},
	langid = {english}
}

@online{noauthor_shrec_nodate,
	title = {{SHREC} 2017: Large-scale 3D Shape Retrieval from {ShapeNet} Core55},
	url = {https://shapenet.cs.stanford.edu/shrec17/},
	urldate = {2019-04-25},
	keywords = {dataset}
}

@article{armeni_joint_nodate,
	title = {Joint 2D-3D-Semantic Data for Indoor Scene Understanding},
	abstract = {We present a dataset of large-scale indoor spaces that provides a variety of mutually registered modalities from 2D, 2.5D and 3D domains, with instance-level semantic and geometric annotations. The dataset covers over 6,000 m2 and contains over 70,000 {RGB} images, along with the corresponding depths, surface normals, semantic annotations, global {XYZ} images (all in forms of both regular and 360◦ equirectangular images) as well as camera information. It also includes registered raw and semantically annotated 3D meshes and point clouds. The dataset enables development of joint and cross-modal learning models and potentially unsupervised approaches utilizing the regularities present in large-scale indoor spaces.},
	pages = {9},
	author = {Armeni, Iro and Sax, Alexander and Zamir, Amir R and Savarese, Silvio},
	langid = {english}
}

@article{khalid_optimal-dimensionality_2014,
	title = {An Optimal-Dimensionality Sampling Scheme on the Sphere with Fast Spherical Harmonic Transforms},
	volume = {62},
	issn = {1053-587X, 1941-0476},
	url = {http://arxiv.org/abs/1403.4661},
	doi = {10.1109/TSP.2014.2337278},
	abstract = {We develop a sampling scheme on the sphere that permits accurate computation of the spherical harmonic transform and its inverse for signals band-limited at \$L\$ using only \$L{\textasciicircum}2\$ samples. We obtain the optimal number of samples given by the degrees of freedom of the signal in harmonic space. The number of samples required in our scheme is a factor of two or four fewer than existing techniques, which require either \$2L{\textasciicircum}2\$ or \$4L{\textasciicircum}2\$ samples. We note, however, that we do not recover a sampling theorem on the sphere, where spherical harmonic transforms are theoretically exact. Nevertheless, we achieve high accuracy even for very large band-limits. For our optimal-dimensionality sampling scheme, we develop a fast and accurate algorithm to compute the spherical harmonic transform (and inverse), with computational complexity comparable with existing schemes in practice. We conduct numerical experiments to study in detail the stability, accuracy and computational complexity of the proposed transforms. We also highlight the advantages of the proposed sampling scheme and associated transforms in the context of potential applications.},
	pages = {4597--4610},
	number = {17},
	journaltitle = {{IEEE} Transactions on Signal Processing},
	author = {Khalid, Zubair and Kennedy, Rodney A. and {McEwen}, Jason D.},
	urldate = {2019-04-24},
	date = {2014-09},
	eprinttype = {arxiv},
	eprint = {1403.4661},
	keywords = {Computer Science - Information Theory}
}

@article{shuman_distributed_2011,
	title = {Distributed Signal Processing via Chebyshev Polynomial Approximation},
	url = {http://arxiv.org/abs/1111.5239},
	abstract = {Unions of graph multiplier operators are an important class of linear operators for processing signals defined on graphs. We present a novel method to efficiently distribute the application of these operators. The proposed method features approximations of the graph multipliers by shifted Chebyshev polynomials, whose recurrence relations make them readily amenable to distributed computation. We demonstrate how the proposed method can be applied to distributed processing tasks such as smoothing, denoising, inverse filtering, and semi-supervised classification, and show that the communication requirements of the method scale gracefully with the size of the network.},
	journaltitle = {{arXiv}:1111.5239 [cs]},
	author = {Shuman, David I. and Vandergheynst, Pierre and Kressner, Daniel and Frossard, Pascal},
	urldate = {2019-04-17},
	date = {2011-11-22},
	eprinttype = {arxiv},
	eprint = {1111.5239},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing}
}

@article{bruna_spectral_2013,
	title = {Spectral Networks and Locally Connected Networks on Graphs},
	url = {http://arxiv.org/abs/1312.6203},
	abstract = {Convolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of {CNNs} to signals defined on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for low-dimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efficient deep architectures.},
	journaltitle = {{arXiv}:1312.6203 [cs]},
	author = {Bruna, Joan and Zaremba, Wojciech and Szlam, Arthur and {LeCun}, Yann},
	urldate = {2019-04-16},
	date = {2013-12-20},
	eprinttype = {arxiv},
	eprint = {1312.6203},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing}
}

@online{noauthor_matterport3d:_nodate,
	title = {Matterport3D: Learning from {RGB}-D Data in Indoor Environments},
	url = {https://niessner.github.io/Matterport/},
	urldate = {2019-04-16}
}

@online{noauthor_geometric_nodate,
	title = {Geometric Deep Learning},
	url = {http://geometricdeeplearning.com/},
	urldate = {2019-04-16},
	langid = {english}
}

@article{cohen_convolutional_2017,
	title = {Convolutional Networks for Spherical Signals},
	url = {http://arxiv.org/abs/1709.04893},
	abstract = {The success of convolutional networks in learning problems involving planar signals such as images is due to their ability to exploit the translation symmetry of the data distribution through weight sharing. Many areas of science and egineering deal with signals with other symmetries, such as rotation invariant data on the sphere. Examples include climate and weather science, astrophysics, and chemistry. In this paper we present spherical convolutional networks. These networks use convolutions on the sphere and rotation group, which results in rotational weight sharing and rotation equivariance. Using a synthetic spherical {MNIST} dataset, we show that spherical convolutional networks are very effective at dealing with rotationally invariant classification problems.},
	journaltitle = {{arXiv}:1709.04893 [cs]},
	author = {Cohen, Taco and Geiger, Mario and Köhler, Jonas and Welling, Max},
	urldate = {2019-04-12},
	date = {2017-09-14},
	eprinttype = {arxiv},
	eprint = {1709.04893},
	keywords = {Computer Science - Machine Learning}
}

@article{ran_convolutional_2017,
	title = {Convolutional Neural Network-Based Robot Navigation Using Uncalibrated Spherical Images},
	volume = {17},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/17/6/1341},
	doi = {10.3390/s17061341},
	abstract = {Vision-based mobile robot navigation is a vibrant area of research with numerous algorithms having been developed, the vast majority of which either belong to the scene-oriented simultaneous localization and mapping ({SLAM}) or fall into the category of robot-oriented lane-detection/trajectory tracking. These methods suffer from high computational cost and require stringent labelling and calibration efforts. To address these challenges, this paper proposes a lightweight robot navigation framework based purely on uncalibrated spherical images. To simplify the orientation estimation, path prediction and improve computational efficiency, the navigation problem is decomposed into a series of classification tasks. To mitigate the adverse effects of insufficient negative samples in the “navigation via classification” task, we introduce the spherical camera for scene capturing, which enables 360° fisheye panorama as training samples and generation of sufficient positive and negative heading directions. The classification is implemented as an end-to-end Convolutional Neural Network ({CNN}), trained on our proposed Spherical-Navi image dataset, whose category labels can be efficiently collected. This {CNN} is capable of predicting potential path directions with high confidence levels based on a single, uncalibrated spherical image. Experimental results demonstrate that the proposed framework outperforms competing ones in realistic applications.},
	pages = {1341},
	number = {6},
	journaltitle = {Sensors},
	author = {Ran, Lingyan and Zhang, Yanning and Zhang, Qilin and Yang, Tao},
	urldate = {2019-04-12},
	date = {2017-06},
	langid = {english},
	keywords = {convolutional neural networks, navigation via learning, spherical camera, vision-based robot navigation}
}

@inproceedings{sinha_deep_2016,
	title = {Deep Learning 3D Shape Surfaces Using Geometry Images},
	isbn = {978-3-319-46466-4},
	series = {Lecture Notes in Computer Science},
	abstract = {Surfaces serve as a natural parametrization to 3D shapes. Learning surfaces using convolutional neural networks ({CNNs}) is a challenging task. Current paradigms to tackle this challenge are to either adapt the convolutional filters to operate on surfaces, learn spectral descriptors defined by the Laplace-Beltrami operator, or to drop surfaces altogether in lieu of voxelized inputs. Here we adopt an approach of converting the 3D shape into a ‘geometry image’ so that standard {CNNs} can directly be used to learn 3D shapes. We qualitatively and quantitatively validate that creating geometry images using authalic parametrization on a spherical domain is suitable for robust learning of 3D shape surfaces. This spherically parameterized shape is then projected and cut to convert the original 3D shape into a flat and regular geometry image. We propose a way to implicitly learn the topology and structure of 3D shapes using geometry images encoded with suitable features. We show the efficacy of our approach to learn 3D shape surfaces for classification and retrieval tasks on non-rigid and rigid shape datasets.},
	pages = {223--240},
	booktitle = {Computer Vision – {ECCV} 2016},
	publisher = {Springer International Publishing},
	author = {Sinha, Ayan and Bai, Jing and Ramani, Karthik},
	editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
	date = {2016},
	langid = {english},
	keywords = {3D Shape, {CNN}, Deep learning, Geometry images, Surfaces}
}

@incollection{boomsma_spherical_2017,
	title = {Spherical convolutions and their application in molecular modelling},
	url = {http://papers.nips.cc/paper/6935-spherical-convolutions-and-their-application-in-molecular-modelling.pdf},
	pages = {3433--3443},
	booktitle = {Advances in Neural Information Processing Systems 30},
	publisher = {Curran Associates, Inc.},
	author = {Boomsma, Wouter and Frellsen, Jes},
	editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	urldate = {2019-04-12},
	date = {2017}
}

@inproceedings{frossard_graph-based_2017,
	location = {Venice, Italy},
	title = {Graph-Based Classification of Omnidirectional Images},
	isbn = {978-1-5386-1034-3},
	url = {http://ieeexplore.ieee.org/document/8265315/},
	doi = {10.1109/ICCVW.2017.106},
	abstract = {Omnidirectional cameras are widely used in such areas as robotics and virtual reality as they provide a wide ﬁeld of view. Their images are often processed with classical methods, which might unfortunately lead to non-optimal solutions as these methods are designed for planar images that have different geometrical properties than omnidirectional ones. In this paper we study image classiﬁcation task by taking into account the speciﬁc geometry of omnidirectional cameras with graph-based representations. In particular, we extend deep learning architectures to data on graphs; we propose a principled way of graph construction such that convolutional ﬁlters respond similarly for the same pattern on different positions of the image regardless of lens distortions. Our experiments show that the proposed method outperforms current techniques for the omnidirectional image classiﬁcation problem.},
	eventtitle = {2017 {IEEE} International Conference on Computer Vision Workshop ({ICCVW})},
	pages = {860--869},
	booktitle = {2017 {IEEE} International Conference on Computer Vision Workshops ({ICCVW})},
	publisher = {{IEEE}},
	author = {Frossard, Pascal and Khasanova, Renata},
	urldate = {2019-04-12},
	date = {2017-10},
	langid = {english}
}

@online{ramasinghe_spherical_2018,
	title = {Spherical Convolution — A Theoretical Walk-Through.},
	url = {https://medium.com/@samramasinghe/spherical-convolution-a-theoretical-walk-through-98e98ee64655},
	abstract = {Convolution is an extremely effective technique that can capture useful features from data distributions. Specifically, convolution based…},
	titleaddon = {Medium},
	author = {Ramasinghe, Sameera},
	urldate = {2019-04-12},
	date = {2018-12-14}
}

@book{noauthor_proceedings_2014,
	location = {New York, {NY}},
	title = {Proceedings of {ELM}-2014 volume 1: algorithms and theories},
	isbn = {978-3-319-14062-9},
	series = {Proceedings in adaptation, learning and optimization},
	shorttitle = {Proceedings of {ELM}-2014 volume 1},
	number = {3},
	publisher = {Springer Berlin Heidelberg},
	date = {2014},
	langid = {english}
}

@online{noauthor_data_nodate,
	title = {Data Input Pipeline Performance {\textbar} {TensorFlow} Core},
	url = {https://www.tensorflow.org/guide/performance/datasets},
	titleaddon = {{TensorFlow}},
	urldate = {2019-04-10},
	langid = {english}
}

@online{noauthor_importing_nodate,
	title = {Importing Data {\textbar} {TensorFlow} Core},
	url = {https://www.tensorflow.org/guide/datasets},
	titleaddon = {{TensorFlow}},
	urldate = {2019-04-10},
	langid = {english}
}

@inproceedings{su_multi-view_2015,
	location = {Santiago, Chile},
	title = {Multi-view Convolutional Neural Networks for 3D Shape Recognition},
	isbn = {978-1-4673-8391-2},
	url = {http://ieeexplore.ieee.org/document/7410471/},
	doi = {10.1109/ICCV.2015.114},
	abstract = {A longstanding question in computer vision concerns the representation of 3D shapes for recognition: should 3D shapes be represented with descriptors operating on their native 3D formats, such as voxel grid or polygon mesh, or can they be effectively represented with view-based descriptors? We address this question in the context of learning to recognize 3D shapes from a collection of their rendered views on 2D images. We ﬁrst present a standard {CNN} architecture trained to recognize the shapes’ rendered views independently of each other, and show that a 3D shape can be recognized even from a single view at an accuracy far higher than using state-of-the-art 3D shape descriptors. Recognition rates further increase when multiple views of the shapes are provided. In addition, we present a novel {CNN} architecture that combines information from multiple views of a 3D shape into a single and compact shape descriptor offering even better recognition performance. The same architecture can be applied to accurately recognize human hand-drawn sketches of shapes. We conclude that a collection of 2D views can be highly informative for 3D shape recognition and is amenable to emerging {CNN} architectures and their derivatives.},
	eventtitle = {2015 {IEEE} International Conference on Computer Vision ({ICCV})},
	pages = {945--953},
	booktitle = {2015 {IEEE} International Conference on Computer Vision ({ICCV})},
	publisher = {{IEEE}},
	author = {Su, Hang and Maji, Subhransu and Kalogerakis, Evangelos and Learned-Miller, Erik},
	urldate = {2019-04-09},
	date = {2015-12},
	langid = {english}
}

@online{noauthor_classification_nodate,
	title = {Classification of finite subgroups of {SO}(3,R) - Groupprops},
	url = {https://groupprops.subwiki.org/wiki/Classification_of_finite_subgroups_of_SO(3,R)},
	urldate = {2019-04-05}
}

@inreference{noauthor_symmetry_2019,
	title = {Symmetry group},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Symmetry_group&oldid=888198642},
	abstract = {In group theory, the symmetry group of a geometric object is the group of all transformations under which the object is invariant, endowed with the group operation of composition. Such a transformation is an invertible mapping of the ambient space which takes the object to itself, and which preserves all the relevant structure of the object. A frequent notation for the symmetry group of an object X is G = Sym(X).
For an object in a metric space, its symmetries form a subgroup of the isometry group of the ambient space. This article mainly considers symmetry groups in Euclidean geometry, but the concept may also be studied for more general types of geometric structure.},
	booktitle = {Wikipedia},
	urldate = {2019-04-03},
	date = {2019-03-17},
	langid = {english},
	note = {Page Version {ID}: 888198642}
}

@inreference{noauthor_lie_2019,
	title = {Lie group},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Lie_group&oldid=888309204},
	abstract = {In mathematics, a Lie group (pronounced  "Lee") is a group that is also a differentiable manifold, with the property that the group operations are smooth. Lie groups are named after Norwegian mathematician Sophus Lie, who laid the foundations of the theory of continuous transformation groups.
In rough terms, a Lie group is a continuous group, that is, one whose elements are described by several real parameters. As such, Lie groups provide a natural model for the concept of continuous symmetry, such as rotational symmetry in three dimensions. Lie groups are widely used in many parts of modern mathematics and physics. Lie's original motivation for introducing Lie groups was to model the continuous symmetries of differential equations, in much the same way that finite groups are used in Galois theory to model the discrete symmetries of algebraic equations.},
	booktitle = {Wikipedia},
	urldate = {2019-04-03},
	date = {2019-03-18},
	langid = {english},
	note = {Page Version {ID}: 888309204}
}

@inreference{noauthor_gauge_2019,
	title = {Gauge theory},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Gauge_theory&oldid=887279263},
	abstract = {In physics, a gauge theory is a type of field theory in which the Lagrangian is invariant under certain Lie groups of local transformations.
The term gauge refers to any specific mathematical formalism to regulate redundant degrees of freedom in the Lagrangian. The transformations between possible gauges, called gauge transformations, form a Lie group—referred to as the symmetry group or the gauge group of the theory. Associated with any Lie group is the Lie algebra of group generators. For each group generator there necessarily arises a corresponding field (usually a vector field) called the gauge field. Gauge fields are included in the Lagrangian to ensure its invariance under the local group transformations (called gauge invariance). When such a theory is quantized, the quanta of the gauge fields are called gauge bosons. If the symmetry group is non-commutative, then the gauge theory is referred to as non-abelian gauge theory, the usual example being the Yang–Mills theory.
Many powerful theories in physics are described by Lagrangians that are invariant under some symmetry transformation groups. When they are invariant under a transformation identically performed at every point in the spacetime in which the physical processes occur, they are said to have a global symmetry. Local symmetry, the cornerstone of gauge theories, is a stronger constraint. In fact, a global symmetry is just a local symmetry whose group's parameters are fixed in spacetime (the same way a constant value can be understood as a function of a certain parameter, the output of which is always the same).
Gauge theories are important as the successful field theories explaining the dynamics of elementary particles.  Quantum electrodynamics is an abelian gauge theory with the symmetry group U(1) and has one gauge field, the electromagnetic four-potential, with the photon being the gauge boson. The Standard Model is a non-abelian gauge theory with the symmetry group U(1) × {SU}(2) × {SU}(3) and has a total of twelve gauge bosons: the photon, three weak bosons and eight gluons.
Gauge theories are also important in explaining gravitation in the theory of general relativity.  Its case is somewhat unusual in that the gauge field is a tensor, the Lanczos tensor.  Theories of quantum gravity, beginning with gauge gravitation theory, also postulate the existence of a gauge boson known as the graviton.  Gauge symmetries can be viewed as analogues of the principle of general covariance of general relativity in which the coordinate system can be chosen freely under arbitrary diffeomorphisms of spacetime.  Both gauge invariance and diffeomorphism invariance reflect a redundancy in the description of the system.  An alternative theory of gravitation, gauge theory gravity, replaces the principle of general covariance with a true gauge principle with new gauge fields.
Historically, these ideas were first stated in the context of classical electromagnetism and later in general relativity.  However, the modern importance of gauge symmetries appeared first in the relativistic quantum mechanics of electrons – quantum electrodynamics, elaborated on below. Today, gauge theories are useful in condensed matter, nuclear and high energy physics among other subfields.},
	booktitle = {Wikipedia},
	urldate = {2019-04-03},
	date = {2019-03-11},
	langid = {english},
	note = {Page Version {ID}: 887279263}
}

@article{cohen_gauge_2019,
	title = {Gauge Equivariant Convolutional Networks and the Icosahedral {CNN}},
	url = {http://arxiv.org/abs/1902.04615},
	abstract = {The idea of equivariance to symmetry transformations provides one of the first theoretically grounded principles for neural network architecture design. Equivariant networks have shown excellent performance and data efficiency on vision and medical imaging problems that exhibit symmetries. Here we show how this principle can be extended beyond global symmetries to local gauge transformations, thereby enabling the development of equivariant convolutional networks on general manifolds. We implement gauge equivariant {CNNs} for signals defined on the icosahedron, which provides a reasonable approximation of spherical signals. By choosing to work with this very regular manifold, we are able to implement the gauge equivariant convolution using a single conv2d call, making it a highly scalable and practical alternative to Spherical {CNNs}. We evaluate the Icosahedral {CNN} on omnidirectional image segmentation and climate pattern segmentation, and find that it outperforms previous methods.},
	journaltitle = {{arXiv}:1902.04615 [cs, stat]},
	author = {Cohen, Taco S. and Weiler, Maurice and Kicanaoglu, Berkay and Welling, Max},
	urldate = {2019-04-03},
	date = {2019-02-11},
	eprinttype = {arxiv},
	eprint = {1902.04615},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning}
}

@article{esteves_equivariant_2019,
	title = {Equivariant Multi-View Networks},
	url = {http://arxiv.org/abs/1904.00993},
	abstract = {Several approaches to 3D vision tasks process multiple views of the input independently with deep neural networks pre-trained on natural images, achieving view permutation invariance through a single round of pooling over all views. We argue that this operation discards important information and leads to subpar global descriptors. In this paper, we propose a group convolutional approach to multiple view aggregation where convolutions are performed over a discrete subgroup of the rotation group, enabling, thus, joint reasoning over all views in an equivariant (instead of invariant) fashion, up to the very last layer. We further develop this idea to operate on smaller discrete homogeneous spaces of the rotation group, where a polar view representation is used to maintain equivariance with only a fraction of the number of input views. We set the new state of the art in several large scale 3D shape retrieval tasks, and show additional applications to panoramic scene classification.},
	journaltitle = {{arXiv}:1904.00993 [cs]},
	author = {Esteves, Carlos and Xu, Yinshuang and Allen-Blanchette, Christine and Daniilidis, Kostas},
	urldate = {2019-04-03},
	date = {2019-04-01},
	eprinttype = {arxiv},
	eprint = {1904.00993},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{healy_ffts_2003,
	title = {{FFTs} for the 2-Sphere-Improvements and Variations},
	volume = {9},
	issn = {1069-5869, 1531-5851},
	url = {http://link.springer.com/10.1007/s00041-003-0018-9},
	doi = {10.1007/s00041-003-0018-9},
	abstract = {Earlier work by Driscoll and Healy [18] has produced an efﬁcient algorithm for computing the Fourier transform of band-limited functions on the 2-sphere. In this article we present a reformulation and variation of the original algorithm which results in a greatly improved inverse transform, and consequent improved convolution algorithm for such functions. All require at most O(N log2 N ) operations where N is the number of sample points. We also address implementation considerations and give heuristics for allowing reliable and computationally efﬁcient ﬂoating point implementations of slightly modiﬁed algorithms. These claims are supported by extensive numerical experiments from our implementation in C on {DEC}, {HP}, {SGI} and Linux Pentium platforms. These results indicate that variations of the algorithm are both reliable and efﬁcient for a large range of useful problem sizes. Performance appears to be architecture-dependent. The article concludes with a brief discussion of a few potential applications.},
	pages = {341--385},
	number = {4},
	journaltitle = {Journal of Fourier Analysis and Applications},
	author = {Healy, D.M. and Rockmore, D.N. and Kostelec, P.J. and Moore, S.},
	urldate = {2019-03-27},
	date = {2003-07-01},
	langid = {english}
}

@article{kostelec_soft:_nodate,
	title = {{SOFT}: {SO}(3) Fourier Transforms},
	pages = {21},
	author = {Kostelec, Peter J},
	langid = {english}
}
@article{zhu_negative_2018,
	title = {Negative Log Likelihood Ratio Loss for Deep Neural Network Classification},
	url = {http://arxiv.org/abs/1804.10690},
	abstract = {In deep neural network, the cross-entropy loss function is commonly used for classification. Minimizing cross-entropy is equivalent to maximizing likelihood under assumptions of uniform feature and class distributions. It belongs to generative training criteria which does not directly discriminate correct class from competing classes. We propose a discriminative loss function with negative log likelihood ratio between correct and competing classes. It significantly outperforms the cross-entropy loss on the {CIFAR}-10 image classification task.},
	journaltitle = {{arXiv}:1804.10690 [cs, stat]},
	author = {Zhu, Donglai and Yao, Hengshuai and Jiang, Bei and Yu, Peng},
	urldate = {2019-03-13},
	date = {2018-04-27},
	eprinttype = {arxiv},
	eprint = {1804.10690},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{janocha_loss_2017,
	title = {On Loss Functions for Deep Neural Networks in Classification},
	url = {http://arxiv.org/abs/1702.05659},
	abstract = {Deep neural networks are currently among the most commonly used classifiers. Despite easily achieving very good performance, one of the best selling points of these models is their modular design - one can conveniently adapt their architecture to specific needs, change connectivity patterns, attach specialised layers, experiment with a large amount of activation functions, normalisation schemes and many others. While one can find impressively wide spread of various configurations of almost every aspect of the deep nets, one element is, in authors' opinion, underrepresented - while solving classification problems, vast majority of papers and applications simply use log loss. In this paper we try to investigate how particular choices of loss functions affect deep models and their learning dynamics, as well as resulting classifiers robustness to various effects. We perform experiments on classical datasets, as well as provide some additional, theoretical insights into the problem. In particular we show that L1 and L2 losses are, quite surprisingly, justified classification objectives for deep nets, by providing probabilistic interpretation in terms of expected misclassification. We also introduce two losses which are not typically used as deep nets objectives and show that they are viable alternatives to the existing ones.},
	journaltitle = {{arXiv}:1702.05659 [cs]},
	author = {Janocha, Katarzyna and Czarnecki, Wojciech Marian},
	urldate = {2019-03-13},
	date = {2017-02-18},
	eprinttype = {arxiv},
	eprint = {1702.05659},
	keywords = {Computer Science - Machine Learning}
}

@article{weiler_3d_2018,
	title = {3D Steerable {CNNs}: Learning Rotationally Equivariant Features in Volumetric Data},
	url = {http://arxiv.org/abs/1807.02547},
	shorttitle = {3D Steerable {CNNs}},
	abstract = {We present a convolutional network that is equivariant to rigid body motions. The model uses scalar-, vector-, and tensor fields over 3D Euclidean space to represent data, and equivariant convolutions to map between such representations. These {SE}(3)-equivariant convolutions utilize kernels which are parameterized as a linear combination of a complete steerable kernel basis, which is derived analytically in this paper. We prove that equivariant convolutions are the most general equivariant linear maps between fields over R{\textasciicircum}3. Our experimental results confirm the effectiveness of 3D Steerable {CNNs} for the problem of amino acid propensity prediction and protein structure classification, both of which have inherent {SE}(3) symmetry.},
	journaltitle = {{arXiv}:1807.02547 [cs, stat]},
	author = {Weiler, Maurice and Geiger, Mario and Welling, Max and Boomsma, Wouter and Cohen, Taco},
	urldate = {2019-02-25},
	date = {2018-07-06},
	eprinttype = {arxiv},
	eprint = {1807.02547},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@inreference{noauthor_list_2019,
	title = {List of map projections},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=List_of_map_projections&oldid=883860417},
	abstract = {This list provides an overview of some of the significant or common map projections. Because there is no limit to the number of possible map projections, there is no definitive list that includes all of them.},
	booktitle = {Wikipedia},
	urldate = {2019-02-22},
	date = {2019-02-18},
	langid = {english},
	note = {Page Version {ID}: 883860417}
}

@inproceedings{elahi_comparative_2016,
	title = {Comparative analysis of geometrical properties of sampling schemes on the sphere},
	doi = {10.1109/ICSPCS.2016.7843316},
	abstract = {In this work, we carry out the comparative analysis of the geometrical properties of the sampling schemes on the sphere. Among the sampling schemes devised on the sphere, we focus on equiangular sampling, Gauss-Legendre ({GL}) quadrature based sampling, optimal-dimensionality sampling, sampling points of extremal systems and spherical design as these schemes support the accurate representation of the band-limited signals. We analyse sampling efficiency, minimum geodesic distance, mesh norm, mesh ratio and Riesz s-energy for these sampling schemes. Since these sampling schemes require different number of samples for the accurate representation of a band-limited signal and therefore have different sampling efficiency, we formulate these geometrical properties to take into account the sampling efficiency for a meaningful comparison. We illustrate that the optimal dimensionality, extremal system and spherical design sampling schemes exhibit desirable geometrical properties. Among these schemes, extremal system sampling scheme has superior geometrical properties. However, the accuracy of the representation of a band-limited signal degrades with the increase in band-limit for extremal system sampling scheme, due to which we propose to use extremal point sampling scheme for small band-limits. We also propose to use optimal dimensional sampling scheme for moderate to large band-limits as it exhibits desirable geometrical properties and has the capability to accurately represent the band-limited signal.},
	eventtitle = {2016 10th International Conference on Signal Processing and Communication Systems ({ICSPCS})},
	pages = {1--7},
	booktitle = {2016 10th International Conference on Signal Processing and Communication Systems ({ICSPCS})},
	author = {Elahi, U. and Khalid, Z. and Kennedy, R. A.},
	date = {2016-12},
	keywords = {2-sphere (unit sphere), Australia, Computer science, Electronic mail, Gauss-Legendre quadrature based sampling, Geodesy, Harmonic analysis, Indexes, Riesz s-energy, Sampling, Transforms, band-limited signal, band-limited signals, bandlimited signals, comparative analysis, equiangular sampling, extremal systems sampling point, geometrical properties, mesh norm, mesh ratio, minimum geodesic distance, optimal dimensionality, optimal-dimensionality sampling, sampling efficiency, sampling scheme, signal sampling, spherical design sampling scheme, spherical harmonic transform, spherical harmonics}
}

@online{noauthor_pdf_nodate,
	title = {({PDF}) Fast evaluation of quadrature formulae on the sphere},
	url = {https://www.researchgate.net/publication/220577103_Fast_evaluation_of_quadrature_formulae_on_the_sphere},
	abstract = {{PDF} {\textbar} Recently, a fast approximate algorithm for the evaluation of expansions in terms of standard L2 (double-struck S sign2 )-orthonormal spherical harmonics at arbitrary nodes on the sphere double-struck S sign 2 has been proposed in [S. Kunis and D. Potts. Fast spherical Fourier...},
	titleaddon = {{ResearchGate}},
	urldate = {2019-02-19},
	langid = {english},
	doi = {http://dx.doi.org/10.1090/S0025-5718-07-02029-7}
}

@article{cohen_intertwiners_2018,
	title = {Intertwiners between Induced Representations (with Applications to the Theory of Equivariant Neural Networks)},
	url = {http://arxiv.org/abs/1803.10743},
	abstract = {Group equivariant and steerable convolutional neural networks (regular and steerable G-{CNNs}) have recently emerged as a very effective model class for learning from signal data such as 2D and 3D images, video, and other data where symmetries are present. In geometrical terms, regular G-{CNNs} represent data in terms of scalar fields ("feature channels"), whereas the steerable G-{CNN} can also use vector or tensor fields ("capsules") to represent data. In algebraic terms, the feature spaces in regular G-{CNNs} transform according to a regular representation of the group G, whereas the feature spaces in Steerable G-{CNNs} transform according to the more general induced representations of G. In order to make the network equivariant, each layer in a G-{CNN} is required to intertwine between the induced representations associated with its input and output space. In this paper we present a general mathematical framework for G-{CNNs} on homogeneous spaces like Euclidean space or the sphere. We show, using elementary methods, that the layers of an equivariant network are convolutional if and only if the input and output feature spaces transform according to an induced representation. This result, which follows from G.W. Mackey's abstract theory on induced representations, establishes G-{CNNs} as a universal class of equivariant network architectures, and generalizes the important recent work of Kondor \& Trivedi on the intertwiners between regular representations.},
	journaltitle = {{arXiv}:1803.10743 [cs, stat]},
	author = {Cohen, Taco S. and Geiger, Mario and Weiler, Maurice},
	urldate = {2019-02-19},
	date = {2018-03-28},
	eprinttype = {arxiv},
	eprint = {1803.10743},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{esteves_learning_2017,
	title = {Learning {SO}(3) Equivariant Representations with Spherical {CNNs}},
	url = {http://arxiv.org/abs/1711.06721},
	abstract = {We address the problem of 3D rotation equivariance in convolutional neural networks. 3D rotations have been a challenging nuisance in 3D classification tasks requiring higher capacity and extended data augmentation in order to tackle it. We model 3D data with multi-valued spherical functions and we propose a novel spherical convolutional network that implements exact convolutions on the sphere by realizing them in the spherical harmonic domain. Resulting filters have local symmetry and are localized by enforcing smooth spectra. We apply a novel pooling on the spectral domain and our operations are independent of the underlying spherical resolution throughout the network. We show that networks with much lower capacity and without requiring data augmentation can exhibit performance comparable to the state of the art in standard retrieval and classification benchmarks.},
	journaltitle = {{arXiv}:1711.06721 [cs]},
	author = {Esteves, Carlos and Allen-Blanchette, Christine and Makadia, Ameesh and Daniilidis, Kostas},
	urldate = {2019-02-19},
	date = {2017-11-17},
	eprinttype = {arxiv},
	eprint = {1711.06721},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{defferrard_convolutional_2016,
	title = {Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering},
	url = {http://arxiv.org/abs/1606.09375},
	abstract = {In this work, we are interested in generalizing convolutional neural networks ({CNNs}) from low-dimensional regular grids, where image, video and speech are represented, to high-dimensional irregular domains, such as social networks, brain connectomes or words' embedding, represented by graphs. We present a formulation of {CNNs} in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs. Importantly, the proposed technique offers the same linear computational complexity and constant learning complexity as classical {CNNs}, while being universal to any graph structure. Experiments on {MNIST} and 20NEWS demonstrate the ability of this novel deep learning system to learn local, stationary, and compositional features on graphs.},
	journaltitle = {{arXiv}:1606.09375 [cs, stat]},
	author = {Defferrard, Michaël and Bresson, Xavier and Vandergheynst, Pierre},
	urldate = {2019-02-19},
	date = {2016-06-30},
	eprinttype = {arxiv},
	eprint = {1606.09375},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{shuman_emerging_2013,
	title = {The Emerging Field of Signal Processing on Graphs: Extending High-Dimensional Data Analysis to Networks and Other Irregular Domains},
	volume = {30},
	issn = {1053-5888},
	url = {http://arxiv.org/abs/1211.0053},
	doi = {10.1109/MSP.2012.2235192},
	shorttitle = {The Emerging Field of Signal Processing on Graphs},
	abstract = {In applications such as social, energy, transportation, sensor, and neuronal networks, high-dimensional data naturally reside on the vertices of weighted graphs. The emerging field of signal processing on graphs merges algebraic and spectral graph theoretic concepts with computational harmonic analysis to process such signals on graphs. In this tutorial overview, we outline the main challenges of the area, discuss different ways to define graph spectral domains, which are the analogues to the classical frequency domain, and highlight the importance of incorporating the irregular structures of graph data domains when processing signals on graphs. We then review methods to generalize fundamental operations such as filtering, translation, modulation, dilation, and downsampling to the graph setting, and survey the localized, multiscale transforms that have been proposed to efficiently extract information from high-dimensional data on graphs. We conclude with a brief discussion of open issues and possible extensions.},
	pages = {83--98},
	number = {3},
	journaltitle = {{IEEE} Signal Processing Magazine},
	author = {Shuman, David I. and Narang, Sunil K. and Frossard, Pascal and Ortega, Antonio and Vandergheynst, Pierre},
	urldate = {2019-02-19},
	date = {2013-05},
	eprinttype = {arxiv},
	eprint = {1211.0053},
	keywords = {Computer Science - Discrete Mathematics, Computer Science - Machine Learning, Computer Science - Social and Information Networks}
}

@online{noauthor_princeton_nodate,
	title = {Princeton {ModelNet}},
	url = {http://modelnet.cs.princeton.edu/},
	urldate = {2019-02-13}
}

@software{noauthor_demo_2019,
	title = {Demo code for the paper "Learning {SO}(3) Equivariant Representations with Spherical {CNNs}": daniilidis-group/spherical-cnn},
	rights = {{MIT}},
	url = {https://github.com/daniilidis-group/spherical-cnn},
	shorttitle = {Demo code for the paper "Learning {SO}(3) Equivariant Representations with Spherical {CNNs}"},
	publisher = {Daniilidis Group University of Pennsylvania},
	urldate = {2019-02-13},
	date = {2019-02-02},
	note = {original-date: 2017-11-17T20:10:00Z}
}

@software{kohler_spherical_2019,
	title = {Spherical {CNNs}. Contribute to jonas-koehler/s2cnn development by creating an account on {GitHub}},
	rights = {{MIT}},
	url = {https://github.com/jonas-koehler/s2cnn},
	author = {Köhler, Jonas},
	urldate = {2019-02-13},
	date = {2019-02-07},
	note = {original-date: 2017-09-23T16:49:11Z}
}

@article{cohen_spherical_2018,
	title = {Spherical {CNNs}},
	url = {http://arxiv.org/abs/1801.10130},
	abstract = {Convolutional Neural Networks ({CNNs}) have become the method of choice for learning problems involving 2D planar images. However, a number of problems of recent interest have created a demand for models that can analyze spherical images. Examples include omnidirectional vision for drones, robots, and autonomous cars, molecular regression problems, and global weather and climate modelling. A naive application of convolutional networks to a planar projection of the spherical signal is destined to fail, because the space-varying distortions introduced by such a projection will make translational weight sharing ineffective. In this paper we introduce the building blocks for constructing spherical {CNNs}. We propose a definition for the spherical cross-correlation that is both expressive and rotation-equivariant. The spherical correlation satisfies a generalized Fourier theorem, which allows us to compute it efficiently using a generalized (non-commutative) Fast Fourier Transform ({FFT}) algorithm. We demonstrate the computational efficiency, numerical accuracy, and effectiveness of spherical {CNNs} applied to 3D model recognition and atomization energy regression.},
	journaltitle = {{arXiv}:1801.10130 [cs, stat]},
	author = {Cohen, Taco S. and Geiger, Mario and Koehler, Jonas and Welling, Max},
	urldate = {2019-02-13},
	date = {2018-01-30},
	eprinttype = {arxiv},
	eprint = {1801.10130},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@software{noauthor_spherical_2019,
	title = {A spherical convolutional neural network (for cosmological applications): {SwissDataScienceCenter}/{DeepSphere}},
	rights = {{MIT}},
	url = {https://github.com/SwissDataScienceCenter/DeepSphere},
	shorttitle = {A spherical convolutional neural network (for cosmological applications)},
	publisher = {Swiss Data Science Center},
	urldate = {2019-02-13},
	date = {2019-01-30},
	note = {original-date: 2017-12-18T16:42:24Z}
}

@article{perraudin_deepsphere:_2018,
	title = {{DeepSphere}: Efficient spherical Convolutional Neural Network with {HEALPix} sampling for cosmological applications},
	url = {http://arxiv.org/abs/1810.12186},
	shorttitle = {{DeepSphere}},
	abstract = {Convolutional Neural Networks ({CNNs}) are a cornerstone of the Deep Learning toolbox and have led to many breakthroughs in Artificial Intelligence. These networks have mostly been developed for regular Euclidean domains such as those supporting images, audio, or video. Because of their success, {CNN}-based methods are becoming increasingly popular in Cosmology. Cosmological data often comes as spherical maps, which make the use of the traditional {CNNs} more complicated. The commonly used pixelization scheme for spherical maps is the Hierarchical Equal Area {isoLatitude} Pixelisation ({HEALPix}). We present a spherical {CNN} for analysis of full and partial {HEALPix} maps, which we call {DeepSphere}. The spherical {CNN} is constructed by representing the sphere as a graph. Graphs are versatile data structures that can act as a discrete representation of a continuous manifold. Using the graph-based representation, we define many of the standard {CNN} operations, such as convolution and pooling. With filters restricted to being radial, our convolutions are equivariant to rotation on the sphere, and {DeepSphere} can be made invariant or equivariant to rotation. This way, {DeepSphere} is a special case of a graph {CNN}, tailored to the {HEALPix} sampling of the sphere. This approach is computationally more efficient than using spherical harmonics to perform convolutions. We demonstrate the method on a classification problem of weak lensing mass maps from two cosmological models and compare the performance of the {CNN} with that of two baseline classifiers. The results show that the performance of {DeepSphere} is always superior or equal to both of these baselines. For high noise levels and for data covering only a smaller fraction of the sphere, {DeepSphere} achieves typically 10\% better classification accuracy than those baselines. Finally, we show how learned filters can be visualized to introspect the neural network.},
	journaltitle = {{arXiv}:1810.12186 [astro-ph]},
	author = {Perraudin, Nathanaël and Defferrard, Michaël and Kacprzak, Tomasz and Sgier, Raphael},
	urldate = {2019-02-13},
	date = {2018-10-29},
	eprinttype = {arxiv},
	eprint = {1810.12186},
	keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics, Astrophysics - Instrumentation and Methods for Astrophysics, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning}
}