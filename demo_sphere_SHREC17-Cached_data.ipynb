{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSphere using SHREC17 dataset\n",
    "### Benchmark with Cohen method S2CNN[[1]](http://arxiv.org/abs/1801.10130) and Esteves method[[2]](http://arxiv.org/abs/1711.06721)\n",
    "Multi-class classification of 3D objects, using the interesting property of rotation equivariance.\n",
    "\n",
    "The 3D objects are projected on a unit sphere.\n",
    "Cohen and Esteves use equiangular sampling, while our method use a HEAlpix sampling\n",
    "\n",
    "Several features are collected:\n",
    "* projection ray length (from sphere border to intersection [0, 2])\n",
    "* cos/sin with surface normal\n",
    "* same features using the convex hull of the 3D object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # change to chosen GPU to use, nothing if work on CPU\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import healpy as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepsphere import models, experiment_helper, plot, utils\n",
    "from deepsphere.data import LabeledDatasetWithNoise, LabeledDataset\n",
    "import hyperparameters\n",
    "\n",
    "from SHREC17.load_shrec import fix_dataset, Shrec17Dataset, Shrec17DatasetCache, Shrec17DatasetTF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nside = 32\n",
    "experiment_type = 'CNN' # 'FCN'\n",
    "ename = '_'+experiment_type\n",
    "datapath = '../data/shrec17/' # localisation of the .obj files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dataset = True    # use perturbed dataset (Cohen and Esteves do the same)\n",
    "augmentation = 3        # number of element per file (1 = no augmentation of dataset)\n",
    "nfeat = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if datasets are already downloaded but not preprocessed\n",
    "fix = False\n",
    "download = False\n",
    "if fix:\n",
    "    fix_dataset(datapath+'val_perturbed')\n",
    "    fix_dataset(datapath+'test_perturbed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download dataset if True, preprocess data and store it in npy files, and load it in a dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = Shrec17DatasetCache(datapath, 'train', perturbed=noise_dataset, download=download, nside=Nside, augmentation=augmentation, nfile=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better to keep validation and testing set in RAM, but not always possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Shrec17DatasetCache(datapath, 'val', perturbed=noise_dataset, download=download, nside=Nside, nfeat=nfeat, augmentation=1, nfile=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_nonrot_dataset = Shrec17DatasetCache(datapath, 'val', perturbed=noise_dataset, download=download, \n",
    "                                         nside=Nside, nfeat=nfeat, experiment='deepsphere_norot', augmentation=1, nfile=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try do make a tensorflow dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_TFDataset = Shrec17DatasetTF(datapath, 'train', perturbed=noise_dataset, download=download, nside=Nside, nfeat=nfeat, augmentation=augmentation, nfile=None, experiment='deepsphere_norot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_TFDataset.get_tf_dataset(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# #dataset = tf_dataset_file(datapath, dataset, file_pattern, 32, Nside, augmentation)\n",
    "# data_next = dataset.make_one_shot_iterator().get_next()\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# steps = train_TFDataset.N // 32 + 1\n",
    "# with tf.Session(config=config) as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     try:\n",
    "#         for i in tqdm(range(steps)):\n",
    "#             out = sess.run(data_next)\n",
    "#     except tf.errors.OutOfRangeError:\n",
    "#         print(\"Done\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import tensorflow as tf\n",
    "\n",
    "# #dataset = tf_dataset_file(datapath, dataset, file_pattern, 32, Nside, augmentation)\n",
    "# t_start = time.time()\n",
    "# data_next = dataset.make_one_shot_iterator().get_next()\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# steps = train_TFDataset.N // 32 + 1\n",
    "# with tf.Session(config=config) as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     try:\n",
    "#         for i in range(steps):\n",
    "#             out = sess.run(data_next)\n",
    "#     except tf.errors.OutOfRangeError:\n",
    "#         print(\"Done\") # Never reach this as will iterate on infinite sets\n",
    "# t_end = time.time()\n",
    "# print(str(t_end-t_start)+\" s\")\n",
    "\n",
    "# # t_start = time.time()\n",
    "# # data_iter = train_dataset.iter(32)\n",
    "# # steps = int(train_dataset.N / 32)\n",
    "# # for i in range(steps):\n",
    "# #     next(data_iter)\n",
    "# #     #feed_dict = {self.ph_data: batch_data, self.ph_labels: batch_labels, self.ph_training: True}\n",
    "# # t_end = time.time()\n",
    "# # print(str(t_end-t_start)+\" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the training dataset and print the classes distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of class: 55 \n",
      "number of elements: 94092\n"
     ]
    }
   ],
   "source": [
    "nclass = train_TFDataset.nclass\n",
    "num_elem = train_TFDataset.N\n",
    "#ids_train = train_dataset.ids\n",
    "print('number of class:',nclass,'\\nnumber of elements:',num_elem)#,'\\nfirst id:',ids_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_val, labels_val, ids_val = val_dataset.return_data(train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Classification using DeepSphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of the Dataset object used for other DeepSphere experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #training = LabeledDatasetWithNoise(x_train, labels_train, end_level=sigma_noise)\n",
    "# #training = LabeledDataset(x_train, labels_train)\n",
    "# validation = LabeledDataset(x_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = 'shrec17_newGraph_best_4K_norot_{}aug_{}sides{}'.format(augmentation, Nside, ename)\n",
    "#EXP_NAME = 'shrec17_Cohen_simple_SGD_max_nsides_300epoch_{}sides{}'.format(Nside, ename)\n",
    "#EXP_NAME = \"shrec17_newGraph_best_4K_all_3aug_32sides_CNN\"\n",
    "#EXP_NAME = 'essai_TFDataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model with hyperparameters chosen.\n",
    "For each experiment, a new EXP_NAME is chosen, and new hyperparameters are store.\n",
    "All informations are present 'DeepSphere/Shrec17/experiments.md'\n",
    "The fastest way to reproduce an experiment is to revert to the commit of the experiment to load the correct files and notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a layer in the fully connected can be beneficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sides: [32, 16, 8, 4, 2, 1, 1]\n",
      "#pixels: [12288, 3072, 768, 192, 48, 12, 12]\n",
      "#samples per batch: 32\n",
      "=> #pixels per batch (input): 393,216\n",
      "=> #pixels for training (input): 57,810,124,800\n",
      "Learning rate will start at 2.0e-02 and finish at 2.0e-02.\n",
      "NN architecture\n",
      "  input: M_0 = 12288\n",
      "  layer 1: cgconv1\n",
      "    representation: M_0 * F_1 / p_1 = 12288 * 16 / 4 = 49152\n",
      "    weights: F_0 * F_1 * K_1 = 6 * 16 * 4 = 384\n",
      "    biases: F_1 = 16\n",
      "    batch normalization\n",
      "  layer 2: cgconv2\n",
      "    representation: M_1 * F_2 / p_2 = 3072 * 32 / 4 = 24576\n",
      "    weights: F_1 * F_2 * K_2 = 16 * 32 * 4 = 2048\n",
      "    biases: F_2 = 32\n",
      "    batch normalization\n",
      "  layer 3: cgconv3\n",
      "    representation: M_2 * F_3 / p_3 = 768 * 64 / 4 = 12288\n",
      "    weights: F_2 * F_3 * K_3 = 32 * 64 * 4 = 8192\n",
      "    biases: F_3 = 64\n",
      "    batch normalization\n",
      "  layer 4: cgconv4\n",
      "    representation: M_3 * F_4 / p_4 = 192 * 128 / 4 = 6144\n",
      "    weights: F_3 * F_4 * K_4 = 64 * 128 * 4 = 32768\n",
      "    biases: F_4 = 128\n",
      "    batch normalization\n",
      "  layer 5: cgconv5\n",
      "    representation: M_4 * F_5 / p_5 = 48 * 256 / 4 = 3072\n",
      "    weights: F_4 * F_5 * K_5 = 128 * 256 * 4 = 131072\n",
      "    biases: F_5 = 256\n",
      "    batch normalization\n",
      "  Statistical layer: mean\n",
      "    representation: 1 * 256 = 256\n",
      "  layer 6: logits (softmax)\n",
      "    representation: M_6 = 55\n",
      "    weights: M_5 * M_6 = 256 * 55 = 14080\n"
     ]
    }
   ],
   "source": [
    "params = hyperparameters.get_params_shrec17_optim(num_elem, EXP_NAME, Nside, nclass, nfeat_in=nfeat, architecture=experiment_type)\n",
    "params[\"tf_dataset\"] = train_TFDataset.get_tf_dataset(params[\"batch_size\"])\n",
    "#params[\"std\"] = [0.001, 0.005, 0.0125, 0.05, 0.15, 0.5]\n",
    "model = models.deepsphere(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('summaries/{}/'.format(EXP_NAME), ignore_errors=True)\n",
    "shutil.rmtree('checkpoints/{}/'.format(EXP_NAME), ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a correct learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN architecture\n",
      "  input: M_0 = 196608\n",
      "  layer 1: cgconv1\n",
      "    representation: M_0 * F_1 / p_1 = 196608 * 16 / 4 = 786432\n",
      "    weights: F_0 * F_1 * K_1 = 6 * 16 * 5 = 480\n",
      "    biases: F_1 = 16\n",
      "    batch normalization\n",
      "  layer 2: cgconv2\n",
      "    representation: M_1 * F_2 / p_2 = 49152 * 32 / 4 = 393216\n",
      "    weights: F_1 * F_2 * K_2 = 16 * 32 * 5 = 2560\n",
      "    biases: F_2 = 32\n",
      "    batch normalization\n",
      "  layer 3: cgconv3\n",
      "    representation: M_2 * F_3 / p_3 = 12288 * 64 / 4 = 196608\n",
      "    weights: F_2 * F_3 * K_3 = 32 * 64 * 5 = 10240\n",
      "    biases: F_3 = 64\n",
      "    batch normalization\n",
      "  layer 4: cgconv4\n",
      "    representation: M_3 * F_4 / p_4 = 3072 * 128 / 4 = 98304\n",
      "    weights: F_3 * F_4 * K_4 = 64 * 128 * 5 = 40960\n",
      "    biases: F_4 = 128\n",
      "    batch normalization\n",
      "  layer 5: cgconv5\n",
      "    representation: M_4 * F_5 / p_5 = 768 * 256 / 4 = 49152\n",
      "    weights: F_4 * F_5 * K_5 = 128 * 256 * 5 = 163840\n",
      "    biases: F_5 = 256\n",
      "    batch normalization\n",
      "  Statistical layer: mean\n",
      "    representation: 1 * 256 = 256\n",
      "  layer 6: logits (softmax)\n",
      "    representation: M_6 = 55\n",
      "    weights: M_5 * M_6 = 256 * 55 = 14080\n",
      "step 490 / 19602 (epoch 0.50 / 20):\n",
      "  learning_rate = 1.78e-06, training loss = 4.24e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusset/miniconda3/envs/PDMsphere/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  validation accuracy: 0.76 (39 / 5133), f1 (weighted): 0.80, loss: 4.29e+00\n",
      "  CPU time: 1477s, wall time: 797s, perf_time_load: 1.16s, perf_time: 1.16s\n",
      "step 980 / 19602 (epoch 1.00 / 20):\n",
      "  learning_rate = 3.16e-06, training loss = 4.13e+00\n",
      "  validation accuracy: 3.78 (194 / 5133), f1 (weighted): 2.88, loss: 4.19e+00\n",
      "  CPU time: 2964s, wall time: 1587s, perf_time_load: 1.13s, perf_time: 1.13s\n",
      "step 1470 / 19602 (epoch 1.50 / 20):\n",
      "  learning_rate = 5.62e-06, training loss = 4.08e+00\n",
      "  validation accuracy: 10.29 (528 / 5133), f1 (weighted): 4.54, loss: 4.00e+00\n",
      "  CPU time: 4446s, wall time: 2374s, perf_time_load: 1.16s, perf_time: 1.16s\n",
      "step 1960 / 19602 (epoch 2.00 / 20):\n",
      "  learning_rate = 9.99e-06, training loss = 3.78e+00\n",
      "  validation accuracy: 26.57 (1364 / 5133), f1 (weighted): 15.49, loss: 3.70e+00\n",
      "  CPU time: 5924s, wall time: 3166s, perf_time_load: 1.15s, perf_time: 1.15s\n",
      "step 2450 / 19602 (epoch 2.50 / 20):\n",
      "  learning_rate = 1.78e-05, training loss = 3.08e+00\n",
      "  validation accuracy: 35.52 (1823 / 5133), f1 (weighted): 23.55, loss: 3.37e+00\n",
      "  CPU time: 7409s, wall time: 3951s, perf_time_load: 1.15s, perf_time: 1.15s\n",
      "step 2940 / 19602 (epoch 3.00 / 20):\n",
      "  learning_rate = 3.16e-05, training loss = 2.92e+00\n",
      "  validation accuracy: 41.22 (2116 / 5133), f1 (weighted): 27.08, loss: 3.05e+00\n",
      "  CPU time: 8890s, wall time: 4737s, perf_time_load: 1.17s, perf_time: 1.17s\n",
      "step 3430 / 19602 (epoch 3.50 / 20):\n",
      "  learning_rate = 5.62e-05, training loss = 2.43e+00\n",
      "  validation accuracy: 43.13 (2214 / 5133), f1 (weighted): 29.75, loss: 2.78e+00\n",
      "  CPU time: 10385s, wall time: 5525s, perf_time_load: 1.14s, perf_time: 1.14s\n",
      "step 3920 / 19602 (epoch 4.00 / 20):\n",
      "  learning_rate = 9.99e-05, training loss = 2.51e+00\n",
      "  validation accuracy: 46.13 (2368 / 5133), f1 (weighted): 34.35, loss: 2.55e+00\n",
      "  CPU time: 11895s, wall time: 6315s, perf_time_load: 1.14s, perf_time: 1.14s\n",
      "step 4410 / 19602 (epoch 4.50 / 20):\n",
      "  learning_rate = 1.78e-04, training loss = 2.13e+00\n",
      "  validation accuracy: 48.61 (2495 / 5133), f1 (weighted): 38.04, loss: 2.32e+00\n",
      "  CPU time: 13355s, wall time: 7094s, perf_time_load: 1.17s, perf_time: 1.17s\n",
      "step 4900 / 19602 (epoch 5.00 / 20):\n",
      "  learning_rate = 3.16e-04, training loss = 2.27e+00\n",
      "  validation accuracy: 52.41 (2690 / 5133), f1 (weighted): 43.24, loss: 2.12e+00\n",
      "  CPU time: 14828s, wall time: 7876s, perf_time_load: 1.17s, perf_time: 1.17s\n",
      "step 5390 / 19602 (epoch 5.50 / 20):\n",
      "  learning_rate = 5.61e-04, training loss = 1.93e+00\n",
      "  validation accuracy: 56.91 (2921 / 5133), f1 (weighted): 49.32, loss: 1.93e+00\n",
      "  CPU time: 16301s, wall time: 8660s, perf_time_load: 1.17s, perf_time: 1.17s\n",
      "step 5880 / 19602 (epoch 6.00 / 20):\n",
      "  learning_rate = 9.98e-04, training loss = 1.77e+00\n",
      "  validation accuracy: 61.33 (3148 / 5133), f1 (weighted): 55.17, loss: 1.75e+00\n",
      "  CPU time: 17783s, wall time: 9427s, perf_time_load: 1.11s, perf_time: 1.11s\n",
      "step 6370 / 19602 (epoch 6.50 / 20):\n",
      "  learning_rate = 1.77e-03, training loss = 1.69e+00\n",
      "  validation accuracy: 64.50 (3311 / 5133), f1 (weighted): 59.56, loss: 1.60e+00\n",
      "  CPU time: 19248s, wall time: 10200s, perf_time_load: 1.13s, perf_time: 1.13s\n"
     ]
    }
   ],
   "source": [
    "backup = params.copy()\n",
    "\n",
    "params, learning_rate = utils.test_learning_rates(params, train_TFDataset.N, 1e-6, 1e-1, num_epochs=20)\n",
    "\n",
    "shutil.rmtree('summaries/{}/'.format(params['dir_name']), ignore_errors=True)\n",
    "shutil.rmtree('checkpoints/{}/'.format(params['dir_name']), ignore_errors=True)\n",
    "\n",
    "model = models.deepsphere(**params)\n",
    "_, loss_validation, _, _ = model.fit(train_TFDataset, val_dataset, use_tf_dataset=True, cache=True)\n",
    "\n",
    "params.update(backup)\n",
    "\n",
    "plt.semilogx(learning_rate, loss_validation, '.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('summaries/lr_finder/', ignore_errors=True)\n",
    "shutil.rmtree('checkpoints/lr_finder/', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.9 seems to be a good learning rate for SGD with current parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1/weights:0\n",
      "conv1/bias:0\n",
      "conv2/weights:0\n",
      "conv2/bias:0\n",
      "conv3/weights:0\n",
      "conv3/bias:0\n",
      "conv4/weights:0\n",
      "conv4/bias:0\n",
      "conv5/weights:0\n",
      "conv5/bias:0\n",
      "logits/weights:0\n",
      "the number of parameters in the model is: 189,040\n"
     ]
    }
   ],
   "source": [
    "print(\"the number of parameters in the model is: {:,}\".format(model.get_nbr_var()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 735 / 147018 (epoch 0.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 87.50, training loss = 5.81e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusset/miniconda3/envs/PDMsphere/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  validation accuracy: 72.61 (3727 / 5133), f1 (weighted): 70.17, loss: 1.05e+00\n",
      "  CPU time: 138s, wall time: 65s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 1470 / 147018 (epoch 0.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 84.38, training loss = 5.60e-01\n",
      "  validation accuracy: 77.30 (3968 / 5133), f1 (weighted): 75.19, loss: 8.59e-01\n",
      "  CPU time: 272s, wall time: 124s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 2205 / 147018 (epoch 0.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 84.38, training loss = 4.12e-01\n",
      "  validation accuracy: 78.49 (4029 / 5133), f1 (weighted): 77.16, loss: 8.29e-01\n",
      "  CPU time: 398s, wall time: 180s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 2940 / 147018 (epoch 1.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 81.25, training loss = 7.54e-01\n",
      "  validation accuracy: 79.76 (4094 / 5133), f1 (weighted): 78.22, loss: 7.70e-01\n",
      "  CPU time: 526s, wall time: 236s, perf_time_load: 0.06s, perf_time: 0.00s\n",
      "step 3675 / 147018 (epoch 1.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 68.75, training loss = 1.08e+00\n",
      "  validation accuracy: 79.78 (4095 / 5133), f1 (weighted): 78.50, loss: 7.53e-01\n",
      "  CPU time: 653s, wall time: 292s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 4410 / 147018 (epoch 1.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 84.38, training loss = 4.25e-01\n",
      "  validation accuracy: 80.81 (4148 / 5133), f1 (weighted): 79.96, loss: 7.21e-01\n",
      "  CPU time: 780s, wall time: 349s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 5145 / 147018 (epoch 1.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 93.75, training loss = 1.86e-01\n",
      "  validation accuracy: 80.83 (4149 / 5133), f1 (weighted): 79.89, loss: 7.38e-01\n",
      "  CPU time: 910s, wall time: 407s, perf_time_load: 0.07s, perf_time: 0.01s\n",
      "step 5880 / 147018 (epoch 2.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 84.38, training loss = 3.86e-01\n",
      "  validation accuracy: 81.08 (4162 / 5133), f1 (weighted): 79.86, loss: 7.01e-01\n",
      "  CPU time: 1040s, wall time: 463s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 6615 / 147018 (epoch 2.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 1.30e-01\n",
      "  validation accuracy: 82.60 (4240 / 5133), f1 (weighted): 81.91, loss: 6.62e-01\n",
      "  CPU time: 1169s, wall time: 520s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 7350 / 147018 (epoch 2.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 84.38, training loss = 7.79e-01\n",
      "  validation accuracy: 81.73 (4195 / 5133), f1 (weighted): 81.26, loss: 6.79e-01\n",
      "  CPU time: 1301s, wall time: 579s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 8085 / 147018 (epoch 2.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 90.62, training loss = 2.48e-01\n",
      "  validation accuracy: 82.27 (4223 / 5133), f1 (weighted): 81.58, loss: 6.74e-01\n",
      "  CPU time: 1424s, wall time: 634s, perf_time_load: 0.11s, perf_time: 0.00s\n",
      "step 8820 / 147018 (epoch 3.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 90.62, training loss = 5.23e-01\n",
      "  validation accuracy: 82.19 (4219 / 5133), f1 (weighted): 81.54, loss: 6.69e-01\n",
      "  CPU time: 1548s, wall time: 691s, perf_time_load: 0.07s, perf_time: 0.00s\n",
      "step 9555 / 147018 (epoch 3.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 93.75, training loss = 1.54e-01\n",
      "  validation accuracy: 82.21 (4220 / 5133), f1 (weighted): 81.23, loss: 6.99e-01\n",
      "  CPU time: 1669s, wall time: 747s, perf_time_load: 0.07s, perf_time: 0.00s\n",
      "step 10290 / 147018 (epoch 3.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 93.75, training loss = 3.14e-01\n",
      "  validation accuracy: 82.60 (4240 / 5133), f1 (weighted): 81.73, loss: 6.85e-01\n",
      "  CPU time: 1794s, wall time: 804s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 11025 / 147018 (epoch 3.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 84.38, training loss = 3.76e-01\n",
      "  validation accuracy: 82.66 (4243 / 5133), f1 (weighted): 81.98, loss: 6.71e-01\n",
      "  CPU time: 1912s, wall time: 858s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 11760 / 147018 (epoch 4.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 7.51e-02\n",
      "  validation accuracy: 82.15 (4217 / 5133), f1 (weighted): 81.68, loss: 6.78e-01\n",
      "  CPU time: 2032s, wall time: 913s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 12495 / 147018 (epoch 4.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 1.52e-01\n",
      "  validation accuracy: 82.99 (4260 / 5133), f1 (weighted): 82.06, loss: 6.84e-01\n",
      "  CPU time: 2155s, wall time: 970s, perf_time_load: 0.10s, perf_time: 0.00s\n",
      "step 13230 / 147018 (epoch 4.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 87.50, training loss = 3.87e-01\n",
      "  validation accuracy: 82.49 (4234 / 5133), f1 (weighted): 82.02, loss: 6.57e-01\n",
      "  CPU time: 2277s, wall time: 1026s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 13965 / 147018 (epoch 4.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 93.75, training loss = 1.96e-01\n",
      "  validation accuracy: 83.32 (4277 / 5133), f1 (weighted): 82.82, loss: 6.44e-01\n",
      "  CPU time: 2397s, wall time: 1082s, perf_time_load: 0.06s, perf_time: 0.00s\n",
      "step 14700 / 147018 (epoch 5.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 90.62, training loss = 2.42e-01\n",
      "  validation accuracy: 83.75 (4299 / 5133), f1 (weighted): 83.03, loss: 6.60e-01\n",
      "  CPU time: 2518s, wall time: 1137s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 15435 / 147018 (epoch 5.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 93.75, training loss = 1.56e-01\n",
      "  validation accuracy: 82.68 (4244 / 5133), f1 (weighted): 82.05, loss: 6.75e-01\n",
      "  CPU time: 2639s, wall time: 1192s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 16170 / 147018 (epoch 5.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 93.75, training loss = 2.23e-01\n",
      "  validation accuracy: 83.69 (4296 / 5133), f1 (weighted): 83.22, loss: 6.53e-01\n",
      "  CPU time: 2759s, wall time: 1248s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 16905 / 147018 (epoch 5.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 87.50, training loss = 2.84e-01\n",
      "  validation accuracy: 83.42 (4282 / 5133), f1 (weighted): 83.02, loss: 6.64e-01\n",
      "  CPU time: 2886s, wall time: 1308s, perf_time_load: 0.08s, perf_time: 0.00s\n",
      "step 17640 / 147018 (epoch 6.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 90.62, training loss = 2.00e-01\n",
      "  validation accuracy: 82.78 (4249 / 5133), f1 (weighted): 81.96, loss: 7.36e-01\n",
      "  CPU time: 3011s, wall time: 1365s, perf_time_load: 0.06s, perf_time: 0.00s\n",
      "step 18375 / 147018 (epoch 6.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 87.50, training loss = 3.40e-01\n",
      "  validation accuracy: 82.33 (4226 / 5133), f1 (weighted): 82.13, loss: 7.03e-01\n",
      "  CPU time: 3137s, wall time: 1425s, perf_time_load: 0.07s, perf_time: 0.00s\n",
      "step 19110 / 147018 (epoch 6.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 1.29e-01\n",
      "  validation accuracy: 82.56 (4238 / 5133), f1 (weighted): 82.04, loss: 7.04e-01\n",
      "  CPU time: 3270s, wall time: 1497s, perf_time_load: 0.10s, perf_time: 0.00s\n",
      "step 19845 / 147018 (epoch 6.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 4.09e-02\n",
      "  validation accuracy: 83.13 (4267 / 5133), f1 (weighted): 82.67, loss: 6.83e-01\n",
      "  CPU time: 3414s, wall time: 1590s, perf_time_load: 0.13s, perf_time: 0.01s\n",
      "step 20580 / 147018 (epoch 7.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 1.31e-01\n",
      "  validation accuracy: 83.71 (4297 / 5133), f1 (weighted): 83.45, loss: 6.87e-01\n",
      "  CPU time: 3549s, wall time: 1663s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 21315 / 147018 (epoch 7.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 90.62, training loss = 3.54e-01\n",
      "  validation accuracy: 82.86 (4253 / 5133), f1 (weighted): 82.39, loss: 7.05e-01\n",
      "  CPU time: 3669s, wall time: 1718s, perf_time_load: 0.06s, perf_time: 0.00s\n",
      "step 22050 / 147018 (epoch 7.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 3.82e-02\n",
      "  validation accuracy: 82.62 (4241 / 5133), f1 (weighted): 82.09, loss: 7.15e-01\n",
      "  CPU time: 3789s, wall time: 1774s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 22785 / 147018 (epoch 7.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 4.86e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  validation accuracy: 83.13 (4267 / 5133), f1 (weighted): 82.79, loss: 7.11e-01\n",
      "  CPU time: 3909s, wall time: 1830s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 23520 / 147018 (epoch 8.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 6.44e-02\n",
      "  validation accuracy: 83.77 (4300 / 5133), f1 (weighted): 83.20, loss: 7.04e-01\n",
      "  CPU time: 4031s, wall time: 1886s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 24255 / 147018 (epoch 8.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 1.05e-01\n",
      "  validation accuracy: 81.94 (4206 / 5133), f1 (weighted): 81.39, loss: 7.59e-01\n",
      "  CPU time: 4151s, wall time: 1942s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 24990 / 147018 (epoch 8.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 93.75, training loss = 1.62e-01\n",
      "  validation accuracy: 82.93 (4257 / 5133), f1 (weighted): 82.35, loss: 7.19e-01\n",
      "  CPU time: 4273s, wall time: 1999s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 25725 / 147018 (epoch 8.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 1.20e-01\n",
      "  validation accuracy: 82.88 (4254 / 5133), f1 (weighted): 82.49, loss: 7.54e-01\n",
      "  CPU time: 4392s, wall time: 2055s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 26460 / 147018 (epoch 9.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 93.75, training loss = 1.80e-01\n",
      "  validation accuracy: 82.70 (4245 / 5133), f1 (weighted): 82.31, loss: 7.48e-01\n",
      "  CPU time: 4523s, wall time: 2117s, perf_time_load: 0.06s, perf_time: 0.00s\n",
      "step 27195 / 147018 (epoch 9.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 7.16e-02\n",
      "  validation accuracy: 83.17 (4269 / 5133), f1 (weighted): 82.77, loss: 7.15e-01\n",
      "  CPU time: 4644s, wall time: 2173s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 27930 / 147018 (epoch 9.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 1.18e-01\n",
      "  validation accuracy: 83.01 (4261 / 5133), f1 (weighted): 82.39, loss: 7.55e-01\n",
      "  CPU time: 4769s, wall time: 2231s, perf_time_load: 0.06s, perf_time: 0.00s\n",
      "step 28665 / 147018 (epoch 9.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 5.97e-02\n",
      "  validation accuracy: 83.19 (4270 / 5133), f1 (weighted): 82.61, loss: 7.30e-01\n",
      "  CPU time: 4893s, wall time: 2289s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 29400 / 147018 (epoch 10.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 93.75, training loss = 7.64e-02\n",
      "  validation accuracy: 83.30 (4276 / 5133), f1 (weighted): 82.73, loss: 7.65e-01\n",
      "  CPU time: 5015s, wall time: 2345s, perf_time_load: 0.07s, perf_time: 0.01s\n",
      "step 30135 / 147018 (epoch 10.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 1.43e-01\n",
      "  validation accuracy: 82.21 (4220 / 5133), f1 (weighted): 81.73, loss: 7.75e-01\n",
      "  CPU time: 5141s, wall time: 2403s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 30870 / 147018 (epoch 10.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 3.15e-02\n",
      "  validation accuracy: 83.34 (4278 / 5133), f1 (weighted): 82.75, loss: 7.57e-01\n",
      "  CPU time: 5268s, wall time: 2463s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 31605 / 147018 (epoch 10.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 93.75, training loss = 1.85e-01\n",
      "  validation accuracy: 83.13 (4267 / 5133), f1 (weighted): 82.60, loss: 7.68e-01\n",
      "  CPU time: 5390s, wall time: 2520s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 32340 / 147018 (epoch 11.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 5.97e-02\n",
      "  validation accuracy: 83.28 (4275 / 5133), f1 (weighted): 82.84, loss: 7.43e-01\n",
      "  CPU time: 5510s, wall time: 2576s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 33075 / 147018 (epoch 11.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 1.57e-02\n",
      "  validation accuracy: 82.97 (4259 / 5133), f1 (weighted): 82.57, loss: 7.59e-01\n",
      "  CPU time: 5631s, wall time: 2633s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 33810 / 147018 (epoch 11.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 1.62e-01\n",
      "  validation accuracy: 83.36 (4279 / 5133), f1 (weighted): 83.15, loss: 7.53e-01\n",
      "  CPU time: 5754s, wall time: 2688s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 34545 / 147018 (epoch 11.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 9.52e-02\n",
      "  validation accuracy: 83.48 (4285 / 5133), f1 (weighted): 83.19, loss: 7.66e-01\n",
      "  CPU time: 5876s, wall time: 2744s, perf_time_load: 0.07s, perf_time: 0.00s\n",
      "step 35280 / 147018 (epoch 12.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 4.14e-02\n",
      "  validation accuracy: 82.97 (4259 / 5133), f1 (weighted): 82.80, loss: 7.88e-01\n",
      "  CPU time: 5997s, wall time: 2800s, perf_time_load: 0.06s, perf_time: 0.00s\n",
      "step 36015 / 147018 (epoch 12.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 2.42e-02\n",
      "  validation accuracy: 83.03 (4262 / 5133), f1 (weighted): 82.63, loss: 7.49e-01\n",
      "  CPU time: 6118s, wall time: 2855s, perf_time_load: 0.07s, perf_time: 0.01s\n",
      "step 36750 / 147018 (epoch 12.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 93.75, training loss = 1.62e-01\n",
      "  validation accuracy: 83.11 (4266 / 5133), f1 (weighted): 82.88, loss: 7.92e-01\n",
      "  CPU time: 6242s, wall time: 2912s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 37485 / 147018 (epoch 12.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 4.20e-02\n",
      "  validation accuracy: 83.25 (4273 / 5133), f1 (weighted): 82.97, loss: 7.82e-01\n",
      "  CPU time: 6364s, wall time: 2970s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 38220 / 147018 (epoch 13.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 1.85e-02\n",
      "  validation accuracy: 83.32 (4277 / 5133), f1 (weighted): 83.03, loss: 7.91e-01\n",
      "  CPU time: 6490s, wall time: 3028s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 38955 / 147018 (epoch 13.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 93.75, training loss = 1.21e-01\n",
      "  validation accuracy: 83.46 (4284 / 5133), f1 (weighted): 83.09, loss: 7.97e-01\n",
      "  CPU time: 6614s, wall time: 3084s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 39690 / 147018 (epoch 13.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 7.43e-02\n",
      "  validation accuracy: 83.30 (4276 / 5133), f1 (weighted): 82.81, loss: 7.83e-01\n",
      "  CPU time: 6735s, wall time: 3139s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 40425 / 147018 (epoch 13.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 3.55e-02\n",
      "  validation accuracy: 83.42 (4282 / 5133), f1 (weighted): 83.12, loss: 7.90e-01\n",
      "  CPU time: 6857s, wall time: 3196s, perf_time_load: 0.11s, perf_time: 0.01s\n",
      "step 41160 / 147018 (epoch 14.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 5.01e-02\n",
      "  validation accuracy: 83.30 (4276 / 5133), f1 (weighted): 82.80, loss: 7.97e-01\n",
      "  CPU time: 6974s, wall time: 3249s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 41895 / 147018 (epoch 14.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 5.95e-02\n",
      "  validation accuracy: 83.19 (4270 / 5133), f1 (weighted): 82.64, loss: 8.10e-01\n",
      "  CPU time: 7088s, wall time: 3298s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 42630 / 147018 (epoch 14.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 2.02e-02\n",
      "  validation accuracy: 83.32 (4277 / 5133), f1 (weighted): 82.80, loss: 8.17e-01\n",
      "  CPU time: 7205s, wall time: 3351s, perf_time_load: 0.08s, perf_time: 0.01s\n",
      "step 43365 / 147018 (epoch 14.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 7.09e-02\n",
      "  validation accuracy: 83.09 (4265 / 5133), f1 (weighted): 82.63, loss: 8.17e-01\n",
      "  CPU time: 7320s, wall time: 3400s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 44100 / 147018 (epoch 15.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 5.38e-02\n",
      "  validation accuracy: 84.01 (4312 / 5133), f1 (weighted): 83.77, loss: 7.80e-01\n",
      "  CPU time: 7436s, wall time: 3451s, perf_time_load: 0.05s, perf_time: 0.00s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 44835 / 147018 (epoch 15.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 3.70e-02\n",
      "  validation accuracy: 83.83 (4303 / 5133), f1 (weighted): 83.51, loss: 7.86e-01\n",
      "  CPU time: 7551s, wall time: 3501s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 45570 / 147018 (epoch 15.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 8.87e-02\n",
      "  validation accuracy: 83.25 (4273 / 5133), f1 (weighted): 82.72, loss: 8.17e-01\n",
      "  CPU time: 7668s, wall time: 3551s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 46305 / 147018 (epoch 15.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 7.03e-02\n",
      "  validation accuracy: 83.75 (4299 / 5133), f1 (weighted): 83.44, loss: 8.22e-01\n",
      "  CPU time: 7783s, wall time: 3602s, perf_time_load: 0.07s, perf_time: 0.00s\n",
      "step 47040 / 147018 (epoch 16.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 5.23e-02\n",
      "  validation accuracy: 82.52 (4236 / 5133), f1 (weighted): 82.01, loss: 8.50e-01\n",
      "  CPU time: 7899s, wall time: 3652s, perf_time_load: 0.07s, perf_time: 0.00s\n",
      "step 47775 / 147018 (epoch 16.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 5.50e-02\n",
      "  validation accuracy: 83.42 (4282 / 5133), f1 (weighted): 83.09, loss: 8.18e-01\n",
      "  CPU time: 8014s, wall time: 3702s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 48510 / 147018 (epoch 16.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 1.24e-02\n",
      "  validation accuracy: 83.56 (4289 / 5133), f1 (weighted): 83.05, loss: 8.40e-01\n",
      "  CPU time: 8131s, wall time: 3757s, perf_time_load: 0.07s, perf_time: 0.00s\n",
      "step 49245 / 147018 (epoch 16.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 1.71e-02\n",
      "  validation accuracy: 83.36 (4279 / 5133), f1 (weighted): 82.87, loss: 8.31e-01\n",
      "  CPU time: 8265s, wall time: 3824s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 49980 / 147018 (epoch 17.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 3.86e-02\n",
      "  validation accuracy: 83.30 (4276 / 5133), f1 (weighted): 82.90, loss: 8.31e-01\n",
      "  CPU time: 8388s, wall time: 3880s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 50715 / 147018 (epoch 17.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 2.60e-02\n",
      "  validation accuracy: 83.17 (4269 / 5133), f1 (weighted): 82.69, loss: 8.59e-01\n",
      "  CPU time: 8505s, wall time: 3931s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 51450 / 147018 (epoch 17.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 7.93e-02\n",
      "  validation accuracy: 83.77 (4300 / 5133), f1 (weighted): 83.38, loss: 8.28e-01\n",
      "  CPU time: 8620s, wall time: 3982s, perf_time_load: 0.08s, perf_time: 0.01s\n",
      "step 52185 / 147018 (epoch 17.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 3.51e-02\n",
      "  validation accuracy: 83.36 (4279 / 5133), f1 (weighted): 83.03, loss: 8.43e-01\n",
      "  CPU time: 8735s, wall time: 4032s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 52920 / 147018 (epoch 18.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 5.57e-02\n",
      "  validation accuracy: 83.87 (4305 / 5133), f1 (weighted): 83.38, loss: 8.55e-01\n",
      "  CPU time: 8850s, wall time: 4082s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 53655 / 147018 (epoch 18.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 2.74e-02\n",
      "  validation accuracy: 83.25 (4273 / 5133), f1 (weighted): 82.72, loss: 8.65e-01\n",
      "  CPU time: 8963s, wall time: 4132s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 54390 / 147018 (epoch 18.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 1.59e-02\n",
      "  validation accuracy: 83.23 (4272 / 5133), f1 (weighted): 82.72, loss: 8.70e-01\n",
      "  CPU time: 9077s, wall time: 4181s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 55125 / 147018 (epoch 18.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 4.37e-02\n",
      "  validation accuracy: 83.19 (4270 / 5133), f1 (weighted): 82.78, loss: 8.46e-01\n",
      "  CPU time: 9192s, wall time: 4230s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 55860 / 147018 (epoch 19.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 4.14e-02\n",
      "  validation accuracy: 83.89 (4306 / 5133), f1 (weighted): 83.52, loss: 8.65e-01\n",
      "  CPU time: 9306s, wall time: 4279s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 56595 / 147018 (epoch 19.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 2.81e-02\n",
      "  validation accuracy: 83.07 (4264 / 5133), f1 (weighted): 82.60, loss: 8.75e-01\n",
      "  CPU time: 9422s, wall time: 4330s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 57330 / 147018 (epoch 19.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 3.73e-02\n",
      "  validation accuracy: 83.25 (4273 / 5133), f1 (weighted): 82.71, loss: 8.68e-01\n",
      "  CPU time: 9536s, wall time: 4379s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 58065 / 147018 (epoch 19.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 1.65e-02\n",
      "  validation accuracy: 83.48 (4285 / 5133), f1 (weighted): 83.09, loss: 8.74e-01\n",
      "  CPU time: 9648s, wall time: 4428s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 58800 / 147018 (epoch 20.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 6.91e-02\n",
      "  validation accuracy: 83.07 (4264 / 5133), f1 (weighted): 82.59, loss: 8.75e-01\n",
      "  CPU time: 9762s, wall time: 4479s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 59535 / 147018 (epoch 20.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 1.83e-02\n",
      "  validation accuracy: 83.81 (4302 / 5133), f1 (weighted): 83.48, loss: 8.83e-01\n",
      "  CPU time: 9875s, wall time: 4528s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 60270 / 147018 (epoch 20.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 1.00e-02\n",
      "  validation accuracy: 83.87 (4305 / 5133), f1 (weighted): 83.45, loss: 8.63e-01\n",
      "  CPU time: 9990s, wall time: 4579s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 61005 / 147018 (epoch 20.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 1.04e-02\n",
      "  validation accuracy: 83.28 (4275 / 5133), f1 (weighted): 82.92, loss: 8.69e-01\n",
      "  CPU time: 10104s, wall time: 4629s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 61740 / 147018 (epoch 21.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 1.47e-02\n",
      "  validation accuracy: 83.19 (4270 / 5133), f1 (weighted): 82.74, loss: 8.83e-01\n",
      "  CPU time: 10219s, wall time: 4678s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 62475 / 147018 (epoch 21.25 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 96.88, training loss = 6.67e-02\n",
      "  validation accuracy: 82.80 (4250 / 5133), f1 (weighted): 82.45, loss: 8.85e-01\n",
      "  CPU time: 10333s, wall time: 4727s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 63210 / 147018 (epoch 21.50 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 7.68e-03\n",
      "  validation accuracy: 83.62 (4292 / 5133), f1 (weighted): 83.20, loss: 8.89e-01\n",
      "  CPU time: 10447s, wall time: 4777s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 63945 / 147018 (epoch 21.75 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 3.53e-02\n",
      "  validation accuracy: 83.34 (4278 / 5133), f1 (weighted): 83.03, loss: 8.90e-01\n",
      "  CPU time: 10563s, wall time: 4828s, perf_time_load: 0.05s, perf_time: 0.00s\n",
      "step 64680 / 147018 (epoch 22.00 / 50):\n",
      "  learning_rate = 2.00e-02, training accuracy = 100.00, training loss = 4.38e-02\n",
      "  validation accuracy: 83.65 (4294 / 5133), f1 (weighted): 83.12, loss: 8.91e-01\n",
      "  CPU time: 10679s, wall time: 4880s, perf_time_load: 0.05s, perf_time: 0.00s\n"
     ]
    }
   ],
   "source": [
    "accuracy_validation, loss_validation, loss_training, t_step, t_batch = model.fit(train_TFDataset, val_dataset, use_tf_dataset=True, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-6e3d065454a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_frequency'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_training' is not defined"
     ]
    }
   ],
   "source": [
    "plot.plot_loss(loss_training, loss_validation, t_step, params['eval_frequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_Cohen_simple_SGD_max_nsides_300epoch_reg_32sides_CNN\n",
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_Cohen_simple_SGD_max_nsides_300epoch_reg_32sides_CNN/model-294037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('accuracy: 96.53 (30277 / 31364), f1 (weighted): 96.54, loss: 1.16e-01\\nCPU time: 275s, wall time: 257s',\n",
       " 96.53424308123964,\n",
       " 96.54157073077505,\n",
       " 0.115866209483545)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions, loss = model.predict(x_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_rot_3aug_32sides_CNN\n",
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_rot_3aug_32sides_CNN/model-147018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('accuracy: 83.85 (4304 / 5133), f1 (weighted): 83.35, loss: 1.06e+00\\nCPU time: 19s, wall time: 20s',\n",
       " 83.8496006234171,\n",
       " 83.35228415051333,\n",
       " 1.0588493312099583)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.evaluate(x_val, labels_val)\n",
    "model.evaluate(val_dataset, None, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_rot_3aug_32sides_CNN\n",
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_rot_3aug_32sides_CNN/model-147018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('accuracy: 83.81 (4302 / 5133), f1 (weighted): 83.39, loss: 1.05e+00\\nCPU time: 19s, wall time: 23s',\n",
       " 83.81063705435417,\n",
       " 83.39483633906217,\n",
       " 1.045497955320036)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_nonrot_dataset, None, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_rot_3aug_32sides_CNN\n",
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_rot_3aug_32sides_CNN/model-147018\n"
     ]
    }
   ],
   "source": [
    "# probabilities = model.probs(x_val, nclass)\n",
    "probabilities, _ = model.probs(val_dataset, nclass, cache=True)\n",
    "# if augmentation>1:\n",
    "#     probabilities = probabilities.reshape((-1,augmentation,nclass))\n",
    "#     probabilities = probabilities.mean(axis=1)\n",
    "    #ids_val = ids_val[::repeat]\n",
    "predictions = np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_rot_3aug_32sides_CNN\n",
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_rot_3aug_32sides_CNN/model-147018\n"
     ]
    }
   ],
   "source": [
    "# probabilities = model.probs(x_val, nclass)\n",
    "probabilities, _ = model.probs(val_nonrot_dataset, nclass, cache=True)\n",
    "# if augmentation>1:\n",
    "#     probabilities = probabilities.reshape((-1,augmentation,nclass))\n",
    "#     probabilities = probabilities.mean(axis=1)\n",
    "    #ids_val = ids_val[::repeat]\n",
    "predictions = np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_val = val_dataset.get_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = predictions.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SHREC17.load_shrec import shrec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_all_3aug_32sides_CNN\n",
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_all_3aug_32sides_CNN/model-294037\n"
     ]
    }
   ],
   "source": [
    "shrec_output(model.get_descriptor(val_dataset), ids_val, probabilities, datapath, 'results/val_perturbed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every file, find every object with the same class, sorted by most relevance\n",
    "os.makedirs(os.path.join(datapath,'results_aug/val_perturbed'), exist_ok=True)\n",
    "for i,_id in enumerate(ids_val):\n",
    "    idfile = os.path.join(datapath,'results_aug/val_perturbed',_id)\n",
    "    # predictions batchxclass\n",
    "    # pred_class batch == predictions\n",
    "    retrieved = [(probabilities[j, predictions[j]], ids_val[j]) for j in range(len(ids_val)) if predictions[j] == predictions[i]]\n",
    "    retrieved = sorted(retrieved, reverse=True)\n",
    "    retrieved = [i for _, i in retrieved]\n",
    "    with open(idfile, \"w\") as f:\n",
    "        f.write(\"\\n\".join(retrieved))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN appears if remove i==j case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10265it [00:12, 852.87it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = Shrec17Dataset(datapath, 'test', perturbed=noise_dataset, download=download, nside=Nside, augmentation=1, nfile=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nonrot_dataset = Shrec17DatasetCache(datapath, 'test', perturbed=noise_dataset, download=download, \n",
    "                                          nside=Nside, experiment='deepsphere_norot', augmentation=1, nfile=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test, labels_test, ids_test = test_dataset.return_data(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_all_3aug_32sides_CNN\n",
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_all_3aug_32sides_CNN/model-294037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('accuracy: 79.61 (8172 / 10265), f1 (weighted): 79.91, loss: 1.45e+00\\nCPU time: 16s, wall time: 16s',\n",
       " 79.61032635168047,\n",
       " 79.90818871887177,\n",
       " 1.4510044682507857)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_all_3aug_32sides_CNN\n",
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_all_3aug_32sides_CNN/model-294037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('accuracy: 80.42 (8255 / 10265), f1 (weighted): 80.65, loss: 1.40e+00\\nCPU time: 27s, wall time: 27s',\n",
       " 80.4188991719435,\n",
       " 80.65244263465385,\n",
       " 1.404486394451121)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_nonrot_dataset, None, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_rot_3aug_32sides_CNN\n",
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_rot_3aug_32sides_CNN/model-147018\n"
     ]
    }
   ],
   "source": [
    "probabilities = model.probs(x_test, nclass)\n",
    "# if augmentation>1:\n",
    "#     probabilities = probabilities.reshape((-1,augmentation,nclass))\n",
    "#     probabilities = probabilities.mean(axis=1)\n",
    "#probabilities = np.log(probabilities)\n",
    "predictions = np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_all_3aug_32sides_CNN\n",
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_all_3aug_32sides_CNN/model-294037\n"
     ]
    }
   ],
   "source": [
    "probabilities, _ = model.probs(test_nonrot_dataset, nclass, cache=True)\n",
    "# if augmentation>1:\n",
    "#     probabilities = probabilities.reshape((-1,augmentation,nclass))\n",
    "#     probabilities = probabilities.mean(axis=1)\n",
    "#probabilities = np.log(probabilities)\n",
    "predictions = np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_test = test_nonrot_dataset.get_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = predictions.astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every file, find every object with the same class, sorted by most relevance\n",
    "os.makedirs(os.path.join(datapath,'results_aug/test_perturbed'), exist_ok=True)\n",
    "for i, _id in enumerate(ids_test):\n",
    "    idfile = os.path.join(datapath,'results_aug/test_perturbed',_id)\n",
    "    # predictions batchxclass\n",
    "    # pred_class batch == predictions\n",
    "    retrieved = [(probabilities[j, predictions[j]], ids_test[j]) for j in range(len(ids_test)) if predictions[j] == predictions[i]]\n",
    "    retrieved = sorted(retrieved, reverse=True)\n",
    "    retrieved = [i for _, i in retrieved]\n",
    "    with open(idfile, \"w\") as f:\n",
    "        f.write(\"\\n\".join(retrieved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_all_3aug_32sides_CNN\n",
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/students/gusset/DeepSphere/deepsphere/../checkpoints/shrec17_newGraph_best_4K_all_3aug_32sides_CNN/model-294037\n"
     ]
    }
   ],
   "source": [
    "shrec_output(model.get_descriptor(LabeledDataset(x_test, labels_test)), ids_test, probabilities, datapath, 'results/test_perturbed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why not working?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_histogram(nclass, labels_train, labels_min=None, ylim=1700):\n",
    "    if labels_train is None:\n",
    "        return\n",
    "    import matplotlib.pyplot as plt\n",
    "    from collections import Counter\n",
    "    hist_train=Counter(labels_train)\n",
    "    if labels_min is not None:\n",
    "        hist_min = Counter(labels_min)\n",
    "        hist_temp = hist_train - hist_min\n",
    "        hist_min = hist_min - hist_train\n",
    "        hist_train = hist_temp + hist_min\n",
    "#         for i in range(self.nclass):\n",
    "#             hist_train.append(np.sum(labels_train == i))\n",
    "    labels, values = zip(*hist_train.items())\n",
    "    indexes = np.asarray(labels)\n",
    "#     miss = set(indexes) - set(labels)\n",
    "#     if len(miss) is not 0:\n",
    "#         hist_train.update({elem:0 for elem in miss})\n",
    "#     labels, values = zip(*hist_train.items())\n",
    "    width = 1\n",
    "    plt.bar(labels, values, width)\n",
    "    plt.title(\"labels distribution\")\n",
    "    plt.ylim(0,ylim)\n",
    "    #plt.xticks(indexes + width * 0.5, labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_print_histogram(55, labels_test)\n",
    "_print_histogram(55, predictions)\n",
    "_print_histogram(55, labels_test, predictions, ylim=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6fb0206b70>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.spy(confusion_matrix(labels_test, predictions, range(55)), cmap = plt.cm.gist_heat_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels = {0: 'airplane',\n",
    "               1: 'trashcan',\n",
    "               2: 'bag',\n",
    "               3: 'basket',\n",
    "               4: 'bathtub',\n",
    "               5: 'bed',\n",
    "               6: 'bench',\n",
    "               7: 'birdhouse',\n",
    "               8: 'bookshelf',\n",
    "               9: 'bottle',\n",
    "               10: 'bowl',\n",
    "               11: 'bus',\n",
    "               12: 'cabinet',\n",
    "               13: 'camera',\n",
    "               14: 'can',\n",
    "               15: 'cap',\n",
    "               16: 'car',\n",
    "               17: 'cellphone',\n",
    "               18: 'chair',\n",
    "               19: 'clock',\n",
    "               20: 'keyboard',\n",
    "               21: 'dishwasher',\n",
    "               22: 'display',\n",
    "               23: 'earphone',\n",
    "               24: 'faucet',\n",
    "               25: 'file cabinet',\n",
    "               26: 'guitar',\n",
    "               27: 'helmet',\n",
    "               28: 'jar',\n",
    "               29: 'knife',\n",
    "               30: 'lamp',\n",
    "               31: 'laptop',\n",
    "               32: 'speaker',\n",
    "               33: 'mailbox',\n",
    "               34: 'microphone',\n",
    "               35: 'microwave',\n",
    "               36: 'motorcycle',\n",
    "               37: 'mug',\n",
    "               38: 'piano',\n",
    "               39: 'pillow',\n",
    "               40: 'pistol',\n",
    "               41: 'flowerpot',\n",
    "               42: 'printer',\n",
    "               43: 'remote control',\n",
    "               44: 'rifle',\n",
    "               45: 'rocket',\n",
    "               46: 'skateboard',\n",
    "               47: 'sofa',\n",
    "               48: 'stove',\n",
    "               49: 'table',\n",
    "               50: 'telephone',\n",
    "               51: 'tower',\n",
    "               52: 'train',\n",
    "               53: 'vessel',\n",
    "               54: 'washer'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
